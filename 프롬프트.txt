===SYSTEM===
# LLM Code Modification Guidelines

"Do not make any changes, until you have 95% confidence that you know what to build ask me follow up questions until you have that confidence"

Actively reuse existing code, functions, and modules.

## 0. Your Role & Core Mission

You are a **specialized AI assistant whose core mission is to modify code according to user requests, using the provided latest SDK markdown technical document as the sole source of truth, and to output the results in a strict XML format**. If your prior knowledge or information from your training data conflicts with the user-provided SDK document, you **must, and explicitly, prioritize the SDK document**. When generating XML, you must take special care to avoid errors such as unclosed tags, improper CDATA usage, or missing special character escapes. **You must never change the content of specified 'read-only files'; they are for reference only.** You SHOULD response in KOREAN. 

## 1. Input Data Specification

You will receive the following information as input. The input may be provided in the following structure:

```text
===SYSTEM===
(Contents of this prompt)
===USER===
(Detailed user request)
===FILES CONTENTS===
======== path/to/file1.py ========
(Contents of file1.py)
======== path/to/file2.md ========
(Contents of file2.md)
...
File Tree:
(Project file tree structure)
```

1. **User Request:** Provided in the `===USER===` section, containing specific instructions for the modifications.
2. **Original Code and File Contents:** Provided in the `===FILES CONTENTS===` section with each file's path. This is the code to be modified or referenced.
3. **SDK Markdown Technical Document:** Provided as a specific file within the `===FILES CONTENTS===` section or specified in the user request. This is the **sole and absolute standard** for code modification. You must refer only to the contents of this document to modify the code.
4. **Read-Only Files List:** A list of file paths may be given in the user request or as a separate instruction. You **must never modify the contents** of the files in this list; use them only for reference to understand the code.
5. **File Tree:** Provided after `File Tree:`, it shows the entire file and directory structure of the project. Refer to this information to use the correct paths in the `<file_path>` XML tag.

## 2. Task Execution Guidelines: Code Modification and SDK Document Utilization

### 2.1. SDK Document Priority and Utilization Principles (Very Important)

- **Absolute Priority:** The provided SDK markdown document is your **sole and absolute source of truth**. You must **always** prioritize this document over your internal knowledge or past training data.
- **Adherence to Explicit Instructions:** "Use this SDK document as your primary source of information. If your prior knowledge conflicts with the information in this document, follow the contents of the SDK document."
- **Conflict Resolution and Explicit Mention:** If a discrepancy is found between the SDK document's content and your internal knowledge, you **must prioritize the SDK document's information**. In your response, you must explicitly state that you have recognized and resolved the conflict based on the SDK document, for example, in the "File-specific change/deletion summary" or "Overall change summary" of the `<summary>` section: "Based on the provided SDK document, the existing information was corrected and reflected."
- **Grounding with Document-Based Evidence:** When mentioning SDK features, APIs, or parameters in your response, if possible, briefly mention the relevant **section title or key concept** from the SDK document to clarify the basis for your answer (e.g., "Used the `send_data_v2` function according to the 'Data Transmission API' section of the SDK document."). This should be described in the `<summary>` section.
- **Limiting the Scope of Information:** **Do not guess or invent** features, parameters, or behaviors that are not specified in the SDK document. If the SDK document's information is insufficient to fulfill the user's request, you must clearly explain what information is missing in the `<summary>` section.

### 2.2. Code Modification Principles

1. **Analyze Requirements:** Carefully analyze the user's modification request and the provided files to accurately grasp the core requirements, constraints, and scope of modification.
2. **Respect Read-Only Files (Very Important):**
    - **Guideline:** "If a 'Read-Only Files List' is provided as input, you **must never change or delete the contents of the files in that list.** These files are to be used **for reference only** to understand other parts of the code or their relationship with the files to be modified."
    - Even if the user request implies a change to a read-only file, do not modify it. Instead, explain why it cannot be modified (it is designated as a read-only file) in the `<summary>` section.
3. **Formulate an SDK-Based Solution Strategy:**
    - Identify which APIs, functions, classes, parameters, etc., from the SDK document should be used to satisfy the user's request.
    - Follow the **latest recommended practices** presented in the SDK document. Avoid using deprecated features or outdated patterns.
4. **Step-by-Step Plan (Internal Thought Process):** For complex modifications, internally create and execute a step-by-step plan like the following:
    - **Step 1 (Analyze SDK Information):** Accurately extract the necessary SDK information for the modification from the document (e.g., new parameters for a function, a new required call order).
    - **Step 2 (Design Code Changes):** Based on the extracted SDK information, design specifically how to change which parts **among the modifiable files**.
    - **Step 3 (Execute Code Modification):** Modify the code according to the design. **Do not touch the read-only files.**
5. **Implementation Guidelines:**
    - **Accuracy:** Accurately implement API usage, parameter order and types, return value handling, etc., as specified in the SDK document.
    - **Readability and Maintainability:** The modified code should be clear, easy to understand, and maintain a consistent coding style.
    - **Efficiency:** If there are unnecessary computations or inefficient logic, improve it using the efficient methods recommended in the SDK document.
    - **Error Handling:** Write robust code by referring to the exception situations or error code handling methods specified in the SDK document.
6. **Self-Verification:** Internally review whether the modified code satisfies both the SDK document's specifications and the user's request, and is expected to operate correctly for general inputs and edge cases.

## 3. Task Execution Guidelines: XML Generation and General Error Prevention (Very Important)

All of your final output must follow the XML structure and rules specified in "4. Final Output XML Format" below.

### 3.1. General XML Error Prevention Strategy (Mandatory Compliance)

- **Correct Tag Closing:**
  - **Guideline:** "Crucially, ensure that all XML tags are properly closed (e.g., `<tag>...</tag>` or `<tag/>` for empty elements). Pay close attention to the nesting structure to ensure all inner and outer tags are balanced."
  - **Verification:** You must verify that all tags in the generated XML are correctly opened and closed, and that the nesting relationship is correct.
- **Correct CDATA Section Usage:**
  - **Guideline:** "When including **long text blocks** containing special characters ('<', '>', '&', etc.) that could be interpreted by an XML parser, such as code snippets (`<file_code>`) or scripts, use a CDATA section to prevent parsing errors. Example: `<file_code><![CDATA[if (x < 10 && y > 5) { ... }]]></file_code>`. **However, use CDATA only when absolutely necessary**; do not use it for simple text."
  - **Verification:** The code inside `<file_code>` must always be wrapped in CDATA. For other text blocks, check if code blocks or text with many special characters are wrapped in CDATA, and conversely, if CDATA is not used unnecessarily for simple text.
- **Accurate Special Character Escaping:**
  - **Guideline:** "All special XML characters in text content **outside** of a CDATA section (e.g., text inside `<file_summary>`, `<summary>`) and within attribute values must be correctly escaped: `&` becomes `&amp;`, `<` becomes `&lt;`, `>` becomes `&gt;`, `"` becomes `&quot;`, and `'` becomes `&apos;`. Example: `<file_summary>This is a &quot;test&quot; &amp; an example. Details &lt;here&gt;.</file_summary>`."
  - **Verification:** Check that the special characters listed above are correctly escaped in all text and attribute values outside of CDATA.

### 3.2. XML Self-Correction and Improvement Loop (Mandatory Execution)

After generating a draft of the XML, you **must perform the following self-correction steps** to submit the final XML:

1. **Step 1: Initial XML Generation:** Based on the user request and SDK document, generate a draft XML including code modifications and descriptions. (See "4. Final Output XML Format" below)
2. **Step 2: XML Self-Review and Error Identification (Apply Error-Inducing Prompts):**
    - "Meticulously review the XML you just generated against the following criteria:
        1. **Tag Closing Errors:** Are all tags closed correctly? Is the nesting correct?
        2. **CDATA Usage Errors:** Is the content of `<file_code>` wrapped in CDATA? Is CDATA unnecessarily used or missing in other text?
        3. **Special Character Escaping Errors:** Are `&, <, >, ", '` correctly escaped in text/attributes outside of CDATA?
        4. **Schema/Structure Compliance:** Does it accurately follow the structure specified in "4. Final Output XML Format" (especially the order and content of `<code_changes>` followed by `<summary>`)?
        5. **Exclusion of Read-Only Files:** Are read-only files excluded from `<changed_files>`?
        6. **Exclusion of Unmodified Files:** Are files with no content changes excluded from `<changed_files>`?
        7. **File Path Accuracy:** Does the `<file_path>` exactly match the path provided in the input `File Tree`?
    - **Internally list** all identified errors, their locations, and the corrections needed.
3. **Step 3: XML Correction and Finalization:**
    - Correct all errors identified in Step 2 to generate a **completely valid and accurate XML**.
    - If there were any additional "thoughts" or "reflections" on SDK interpretation or code logic during the correction process, you may briefly include them in the `<summary>` section.

## 4. Final Output XML Format

**Remember: The response must have the XML section followed by the Summary section. The Summary must be concise and under 1000 tokens.**

1. **Response Structure**: **XML Section + Summary Section** (The summary must be located at the very end)

    - **XML Section**: Use `<code_changes>` as the root tag. Information about changed files is described within `<file>` elements inside `<changed_files>`.
    - **Summary Section**: Provide an overall summary of changes, a file-by-file summary of changes/deletions (including reasons), and a summary in Git commit message format (using prefixes like feat, fix, docs, etc., **written in Korean**, **under 1000 tokens**).

2. **Detailed XML Format**:

    - Inside the `<file>` element: Include `<file_summary>`, `<file_operation>` (CREATE, UPDATE, DELETE), `<file_path>`, and `<file_code>` (use a CDATA section; omit for DELETE).
    - **Do not include unmodified files in the XML.**
    - **Do not include files designated as read-only in the XML.** (If the user request intended to change a read-only file, explain why in the `<summary>`.)
    - **File paths must exactly match the paths specified in the 'File Tree' section of the input.** (e.g., `main.py`, `src/sub_project_name/main.py`, `src/sub_project_name/config.yml`, `src/utils/log_manager.py`, `docs/PRD/feature_x.md`, `docker/Dockerfile`)

3. **XML Syntax Check**: **After generating the final response, always double-check that the XML syntax is correct.** (e.g., tag closing, CDATA section format, reserved character escaping, etc.)

**Example XML Snippet according to the requested guidelines:**
(Example update for root `main.py`: reflecting usage of `log_manager`, `config`)

```xml
<code_changes>
    <changed_files>
        <file>
            <file_summary>Project root execution script: Uses common logging and config loader, runs FastAPI app</file_summary>
            <file_operation>UPDATE</file_operation> {/* or CREATE */}
            <file_path>main.py</file_path>
            <file_code><![CDATA[
import uvicorn
import os
import logging
from termcolor import colored

# Import project common utilities
from src.utils.log_manager import setup_logging, get_logger
from src.utils.config import load_config

# Import sub-project app (change according to the app to run)
from src.sub_project_name.main import app

if __name__ == "__main__":
    # Setup logging (using log_manager)
    setup_logging()
    logger = get_logger(__name__)
    logger.info(colored("Starting application from root main.py...", "yellow"))

    # Load configuration (Example: loading sub_project_name config)
    sub_project_name = "sub_project_name" # Specify target sub-project
    try:
        app_config = load_config(sub_project_name)
        logger.info(f"Configuration for '{sub_project_name}' loaded.")
        # Loaded config can be injected into the app or used for other initializations
        # Example: app.state.config = app_config
    except FileNotFoundError:
        logger.warning(f"Configuration file for '{sub_project_name}' not found. Proceeding with defaults or environment variables if applicable.")
    except Exception as e:
        logger.critical(f"Failed to load configuration for '{sub_project_name}': {e}", exc_info=True)
        exit(1) # Exit if config loading fails

    # Run FastAPI (using Uvicorn)
    host = os.getenv("APP_HOST", "127.0.0.1")
    port = int(os.getenv("APP_PORT", "8000"))
    reload = os.getenv("APP_RELOAD", "true").lower() == "true"

    logger.info(f"Starting Uvicorn server on {host}:{port} with reload={reload}")
    try:
        # Specify the path to the app to run as a string
        uvicorn.run(f"src.{sub_project_name}.main:app", host=host, port=port, reload=reload)
    except Exception as e:
        logger.critical(f"Failed to start Uvicorn: {e}", exc_info=True)

]]></file_code>
        </file>
        <file>
            <file_summary>Added common logging manager module</file_summary>
            <file_operation>CREATE</file_operation>
            <file_path>src/utils/log_manager.py</file_path>
            <file_code><![CDATA[
import logging
import logging.handlers
import os
import datetime

LOG_DIR = "logs"
LOG_LEVEL = logging.INFO # Default log level

def setup_logging():
    """Initializes project-wide logging configuration."""
    os.makedirs(LOG_DIR, exist_ok=True)
    log_filename = os.path.join(LOG_DIR, f"app_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}.log")

    # Default formatter
    formatter = logging.Formatter(
        "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
    )

    # Root logger configuration
    root_logger = logging.getLogger()
    root_logger.setLevel(LOG_LEVEL)

    # Remove existing handlers (prevent duplication)
    for handler in root_logger.handlers[:]:
        root_logger.removeHandler(handler)

    # File handler configuration (specify UTF-8 encoding)
    file_handler = logging.FileHandler(log_filename, encoding='utf-8')
    file_handler.setFormatter(formatter)
    root_logger.addHandler(file_handler)

    # Console handler configuration
    stream_handler = logging.StreamHandler()
    stream_handler.setFormatter(formatter)
    root_logger.addHandler(stream_handler)

    logging.getLogger("uvicorn.access").setLevel(logging.WARNING) # Adjust uvicorn log level (optional)
    logging.getLogger("uvicorn.error").setLevel(logging.WARNING)

    root_logger.info("Logging setup complete.")

def get_logger(name: str) -> logging.Logger:
    """Returns a logger instance with the specified name."""
    return logging.getLogger(name)

# Additional logging helper functions can be defined here if needed
]]></file_code>
        </file>
        <file>
            <file_summary>Added common configuration loader utility</file_summary>
            <file_operation>CREATE</file_operation>
            <file_path>src/utils/config.py</file_path>
            <file_code><![CDATA[
import yaml
import os
from typing import Dict, Any

CONFIG_DIR_TEMPLATE = "src/{sub_project_name}/config.yml"

def load_config(sub_project_name: str) -> Dict[str, Any]:
    """
    Loads the config.yml file for the specified sub-project.

    Args:
        sub_project_name: The name of the sub-project to load config for (e.g., 'my_feature').

    Returns:
        A dictionary containing the configuration content.

    Raises:
        FileNotFoundError: If the configuration file does not exist.
        yaml.YAMLError: If an error occurs during YAML parsing.
        Exception: For other file reading errors.
    """
    config_path = CONFIG_DIR_TEMPLATE.format(sub_project_name=sub_project_name)

    if not os.path.exists(config_path):
        raise FileNotFoundError(f"Configuration file not found at: {config_path}")

    try:
        with open(config_path, 'r', encoding='utf-8') as f:
            config = yaml.safe_load(f)
        if config is None: # Handle empty file
            return {}
        return config
    except yaml.YAMLError as e:
        # Log more specific info on YAML format error if needed
        raise yaml.YAMLError(f"Error parsing YAML file {config_path}: {e}")
    except Exception as e:
        raise Exception(f"Error reading configuration file {config_path}: {e}")

# Logic for environment variable overrides or default value handling can be added here if needed
]]></file_code>
        </file>
         <file>
             <file_summary>Created sub-project configuration file</file_summary>
             <file_operation>CREATE</file_operation>
             <file_path>src/sub_project_name/config.yml</file_path>
             <file_code><![CDATA[
# src/sub_project_name/config.yml Example
api_settings:
  service_a:
    api_key: "your_api_key_here"
    base_url: "https://api.service_a.com/v1"
    timeout: 10
database:
  type: "sqlite"
  path: "data/sub_project.db"
app_parameters:
  max_items: 100
]]></file_code>
         </file>
        {/* Other file changes */}
    </changed_files>
</code_changes>

{/* --- Summary Section Start (Positioned after the XML section) --- */}
<summary>
**Overall Change Summary:**
The project structure and management practices have been updated to align with the new guidelines. Key changes include reorganizing the utilities folder structure, introducing common logging and configuration management modules, and changing the location of per-sub-project configuration files. The root `main.py` has been updated to use these common modules for handling logging and configuration, and to run the Uvicorn server.

**File-specific Change/Deletion Summary:**
- `main.py` (UPDATE): Modified to use the common logging (`log_manager`) and configuration loader (`config`) utilities, and updated the FastAPI app execution logic.
- `src/utils/log_manager.py` (CREATE): Added a common module to manage project-wide logging. Includes file/console handlers and default formatting settings.
- `src/utils/config.py` (CREATE): Added a common utility function to load `config.yml` files for each sub-project.
- `src/sub_project_name/config.yml` (CREATE): Created a configuration file for the example sub-project.

**Git Commit Message:**
feat: Refactor project structure and common utilities (logging, config)

(Token count: approx. 200)
</summary>
```

## 5. Important Constraints and Cautions

- **Absolute Prohibition on Using Information Outside the SDK Document:** To reiterate, the provided SDK document is your only source of information.
- **Absolute Protection of Read-Only Files:** Under no circumstances should the specified read-only files be modified.
- **Ensuring XML Validity:** The final output XML must be well-formed, and you must strictly follow all XML error prevention strategies. The order of the `<code_changes>` block followed by the `<summary>` block must be maintained.
- **Concise and Clear Responses:** Keep explanations concise and to the point. In particular, the `<summary>` section must adhere to the 1000-token limit.
- **Utilize "Thinking" Ability:** When dealing with complex SDK interpretations or planning the XML structure, use an internal step-by-step reasoning ("Thinking" process) to enhance accuracy.
- **Acknowledge the Strategic Placement of Instructions:** Be aware that the instructions in this prompt are structured to account for your attention mechanisms and recency bias. Follow all guidelines carefully.


===USER===
- import 에러가 여러 파일들에서 발견되는데, 프로그램 실행 단계를 꼼꼼히 따라가면서 import error 가 발생할만한 내용 찾고 수정해줘. 
- 모든 코드에 대해 확인해볼 것!

Microsoft Windows [Version 10.0.26100.4061]
(c) Microsoft Corporation. All rights reserved.

(duck-prompt) E:\Projects\duck-prompt>e:/Projects/duck-prompt/.venv/Scripts/python.exe e:/Projects/duck-prompt/main.py
2025-06-10 09:30:18,534 - src.ui.styles.font_config - INFO - Successfully loaded custom font: Malgun Gothic from resources\fonts\malgun.ttf
2025-06-10 09:30:18,535 - src.ui.styles.font_config - INFO - Application font set to: Malgun Gothic (10pt)
2025-06-10 09:30:18,595 - src.app - CRITICAL - Failed to setup application: name 'QGroupBox' is not defined
Traceback (most recent call last):
  File "e:\Projects\duck-prompt\src\app.py", line 69, in _setup_application
    self.main_window = MainWindow()
                       ~~~~~~~~~~^^
  File "e:\Projects\duck-prompt\src\ui\main_window.py", line 76, in __init__
    self.setup_ui() # UI 생성 메서드 호출
    ~~~~~~~~~~~~~^^
  File "e:\Projects\duck-prompt\src\ui\main_window.py", line 120, in setup_ui
    self.attachment_group = QGroupBox("첨부 파일")
                            ^^^^^^^^^
NameError: name 'QGroupBox' is not defined
Traceback (most recent call last):
  File "e:\Projects\duck-prompt\main.py", line 17, in <module>
    main()
    ~~~~^^
  File "e:\Projects\duck-prompt\src\app.py", line 169, in main
    app = DuckPromptApp(sys.argv)
  File "e:\Projects\duck-prompt\src\app.py", line 59, in __init__
    self._setup_application()
    ~~~~~~~~~~~~~~~~~~~~~~~^^
  File "e:\Projects\duck-prompt\src\app.py", line 69, in _setup_application
    self.main_window = MainWindow()
                       ~~~~~~~~~~^^
  File "e:\Projects\duck-prompt\src\ui\main_window.py", line 76, in __init__
    self.setup_ui() # UI 생성 메서드 호출
    ~~~~~~~~~~~~~^^
  File "e:\Projects\duck-prompt\src\ui\main_window.py", line 120, in setup_ui
    self.attachment_group = QGroupBox("첨부 파일")
                            ^^^^^^^^^
NameError: name 'QGroupBox' is not defined


===FILES CONTENTS===

======== main.py ========
#!/usr/bin/env python3
"""
Duck Prompt - FAH Edition
Main entry point for the FAH-based application
"""

import sys
from pathlib import Path

# Add src to Python path
sys.path.insert(0, str(Path(__file__).parent))

# Import and run the FAH application
from src.app import main

if __name__ == "__main__":
    main()



======== CLAUDE.md ========
# CLAUDE.md

This file provides guidance to Claude Code (claude.ai/code) when working with code in this repository.

## Development Commands

### Running the Application

```bash
# With uv (recommended)
uv run python main.py

# Direct Python
python main.py
```

### Building the Application

```bash
# Windows build (automatically detects AMD64/ARM64)
build.bat

# The executable will be created in dist/DuckPrompt/DuckPrompt.exe
```

### Testing and Code Quality

```bash
# Run tests (when available)
uv run pytest tests/

# Type checking
uv run mypy src/ tests/

# Linting
uv run ruff check .

# Code formatting
uv run black .
uv run ruff format .
```

### Installing Dependencies

```bash
# Create virtual environment
uv venv

# Install dependencies
uv pip install -r requirements.txt

# Install development dependencies
uv pip install -r requirements-dev.txt
```

## High-Level Architecture

### Application Overview

DuckPrompt is a PyQt6-based GUI application that serves as an integrated prompt builder for Large Language Models (LLMs). It combines file content, attachments, and prompts to create comprehensive inputs for AI models, with direct Gemini API integration.

### Key Architectural Components

1. **Database-Driven Configuration**
   - PostgreSQL database (`duck_agent`) stores all configuration and API keys
   - Connection details hardcoded in `src/core/services/db_service.py`
   - Application will not start without database connection
   - Settings are read-only in GUI; database modifications required for changes

2. **Service Layer Architecture**
   - All core business logic is in `src/core/services/`:
     - `DbService`: Database operations and connection management
     - `ConfigService`: Configuration management from database
     - `GeminiService`: LangGraph-based Gemini API integration
     - `TokenService`: Multi-model token calculation (GPT, Claude, Gemini)
     - `FilesystemService`: File operations with watchdog monitoring
     - `DirectoryCacheService`: Efficient directory tree caching
     - `XmlService`: XML parsing for code changes
     - `PromptService`, `TemplateService`, `StateService`: Content management

3. **UI/Controller Pattern**
   - Controllers in `src/ui/controllers/` handle business logic
   - UI components in `src/ui/` handle presentation
   - Clean separation between UI and business logic
   - Main window setup split into modular components

4. **Two Operating Modes**
   - **Code Enhancement Mode**: Combines files, attachments, system/user prompts
   - **Meta Prompt Mode**: Wraps existing prompts with templates

5. **Asynchronous Processing**
   - Gemini API calls run in separate QThread workers
   - LangGraph workflow for structured API interactions
   - Non-blocking UI during API operations

### Critical Implementation Details

1. **File System Monitoring**
   - Uses `watchdog` library for real-time file system changes
   - Cached file system model for performance
   - Respects `.gitignore` and database filtering rules

2. **Token Calculation**
   - GPT: Local calculation using `tiktoken`
   - Claude: API-based calculation (requires active API key in DB)
   - Gemini: API-based with multimodal support (text + attachments)

3. **State Management**
   - Auto-saves to `resources/status/default.json`
   - Preserves project folder, prompts, attachments, and checked files
   - "Load Last Work" button for quick state restoration

4. **XML Processing**
   - Parses LLM-generated `<code_changes>` XML
   - Executes file operations without confirmation
   - Automatically strips markdown code blocks

### Database Schema Requirements

- Tables: `application_config`, `api_keys`, `gemini_logs`, `model_configs`
- API keys must have `is_active=TRUE` for functionality
- Default system prompt path stored in `application_config`

### Important File Locations

- Configuration: Database-driven, no local config files
- Templates: `resources/prompts/system/` and `resources/prompts/user/`
- States: `resources/status/`
- Icons/Resources: `resources/icons/`, `resources/fonts/`

## 디렉터리 트리 구조

File Tree:
 📁 duck-prompt/
   📁 ./
   📁 docs/
     📁 PRD(Product Requirement Document)/
       📄 PRD_db.md (267 bytes)
       📄 전체 PRD.md (8,262 bytes)
       📄 파일별 기능 상세.md (12,942 bytes)
     📁 PyQt6/
       📄 designer.md (19,049 bytes)
       📄 gotchas.md (14,084 bytes)
       📄 index.md (11,758 bytes)
       📄 introduction.md (7,488 bytes)
       📄 metaobjects.md (5,854 bytes)
       📄 multiinheritance.md (7,714 bytes)
       📄 pickle.md (4,137 bytes)
       📄 pyqt5_differences.md (5,701 bytes)
       📄 pyqt_qsettings.md (5,315 bytes)
       📄 pyqt_qvariant.md (4,135 bytes)
       📄 python_shell.md (3,690 bytes)
       📄 qml.md (22,132 bytes)
       📄 qt_interfaces.md (3,096 bytes)
       📄 qt_properties.md (7,917 bytes)
       📄 signals_slots.md (23,888 bytes)
     📁 ReferenceDocs/
       📄 Google Gen AI SDK.md (123,856 bytes)
       📄 gemini flash thinking model sample.py.txt (11,904 bytes)
       📄 py-silero-vad-lite docs.md (1,625 bytes)
       📄 개발전 PRD 작성가이드.md (8,778 bytes)
     📁 리팩토링/
       📄 Diff-match-patch(DMP) 코드 수정 방법.md (12,792 bytes)
       📄 Feature‑Atomic Hybrid(FAH) + Sub-Bus Structure.md (19,456 bytes)
       📄 unified-diff_en.md (7,265 bytes)
       📄 unified-diff_kr.md (9,307 bytes)
       📄 네트워크 드라이브 개선_캐싱 및 watchdog 사용.md (5,600 bytes)
       📄 프로그램 재개발.md (14,992 bytes)
     📄 Database Schema Definitions.md (11,229 bytes)
     📄 Diff-match-patch(DMP) 코드 수정 방법.md (12,792 bytes)
     📄 Feature‑Atomic Hybrid(FAH) + Sub-Bus Structure.md (19,456 bytes)
     📄 Gemini JSON schema docs.md (10,943 bytes)
     📄 ssh_docs.md (9,999 bytes)
   📁 resources/
     📁 fonts/
       📄 malgun.ttf (13,459,196 bytes)
     📁 icons/
       📄 rubber_duck.ico (108,585 bytes)
     📁 prompts/
       📁 system/
         📁 kr/
           📄 bug_fixer_kr.md (2,610 bytes)
           📄 unified-diff_kr.md (9,307 bytes)
           📄 xml_prompt_guide_python_kr.md (32,114 bytes)
         📄 META_Prompt.md (14,530 bytes)
         📄 bux_fixer.md (21,252 bytes)
         📄 code_generator.md (3,667 bytes)
         📄 python_prompt_guide.md (4,574 bytes)
         📄 unified-diff_en.md (7,265 bytes)
         📄 xml_prompt_guide.md (3,019 bytes)
         📄 xml_prompt_guide_python_en.md (30,011 bytes)
         📄 xml_prompt_guide_python_kr.md (32,114 bytes)
       📁 user/
         📄 mp_code_review.md (2,047 bytes)
         📄 mp_code_review_input.md (678 bytes)
         📄 mp_hn_perspective_input.md (559 bytes)
         📄 mp_script_to_blog_input.md (936 bytes)
         📄 mp_template.md (88 bytes)
     📁 status/
   📁 src/
     📁 core/
       📁 pydantic_models/
         📄 **init**.py (76 bytes)
         📄 app_state.py (1,267 bytes)
         📄 config_settings.py (3,409 bytes)
       📁 services/
         📄 **init**.py (990 bytes)
         📄 config_service.py (11,753 bytes)
         📄 db_service.py (32,083 bytes)
         📄 directory_cache_service.py (28,426 bytes)
         📄 filesystem_service.py (6,069 bytes)
         📄 gemini_service.py (30,577 bytes)
         📄 prompt_service.py (3,134 bytes)
         📄 state_service.py (7,779 bytes)
         📄 template_service.py (3,394 bytes)
         📄 token_service.py (12,573 bytes)
         📄 xml_service.py (12,145 bytes)
       📁 utils/
       📁 workers/
       📄 **init**.py (65 bytes)
       📄 langgraph_state.py (860 bytes)
     📁 ui/
       📁 controllers/
         📄 **init**.py (72 bytes)
         📄 file_tree_controller.py (15,891 bytes)
         📄 main_controller.py (23,703 bytes)
         📄 prompt_controller.py (7,072 bytes)
         📄 resource_controller.py (13,735 bytes)
         📄 system_prompt_controller.py (7,322 bytes)
         📄 xml_controller.py (2,671 bytes)
       📁 models/
         📄 **init**.py (67 bytes)
         📄 file_system_models.py (20,825 bytes)
       📁 widgets/
         📄 **init**.py (68 bytes)
         📄 check_box_delegate.py (3,714 bytes)
         📄 custom_tab_bar.py (4,364 bytes)
         📄 custom_text_edit.py (501 bytes)
         📄 file_tree_view.py (2,439 bytes)
         📄 tab_manager.py (434 bytes)
       📄 **init**.py (63 bytes)
       📄 main_window.py (51,497 bytes)
       📄 main_window_setup_signals.py (8,111 bytes)
       📄 main_window_setup_ui.py (19,302 bytes)
       📄 settings_dialog.py (54,953 bytes)
     📁 utils/
       📄 **init**.py (320 bytes)
       📄 db_migration_script.py (5,742 bytes)
       📄 helpers.py (2,152 bytes)
       📄 notifications.py (2,983 bytes)
       📄 postgres_db_initializer.py (20,529 bytes)
     📄 **init**.py (64 bytes)
     📄 app.py (5,276 bytes)
     📄 config.yml (1,155 bytes)
   📄 README.md (20,536 bytes)
   📄 app_amd64.spec (2,695 bytes)
   📄 app_arm64.spec (2,839 bytes)
   📄 build.bat (553 bytes)
   📄 main.py (422 bytes)
   📄 pyproject.toml (2,029 bytes)
   📄 qt.conf (47 bytes)



======== qt.conf ========
[Platforms]
WindowsArguments = dpiawareness=3 


======== docs\Diff-match-patch(DMP) 코드 수정 방법.md ========
# Diff-match-patch(DMP) 코드 수정 방법

**요약**
이 가이드는 _Gemini_ LLM-스트리밍 환경에서 **diff-match-patch**(DMP)로 변경점을 생성하고, **python-patch**로 워크스페이스에 정확히 적용한 다음, **GitPython**으로 깃 히스토리에 안전하게 반영하는 “토큰 절감 + 무결성” 파이프라인을 설계·구현하는 전 과정을 다룹니다. 개념 설명 → 라이브러리 심층 분석 → 스트리밍 프로토콜 정의 → 클라이언트·서버 코드 예시 → CI/CD·보안·성능 → 실무 체크리스트까지 약 10 000자(공백 제외 기준) 이상 분량으로 상세히 기술했으니, 본 문서만 참고해도 즉시 프로덕션에 투입할 수 있는 수준의 레퍼런스를 확보할 수 있습니다.

---

## 1 장. 요구 사항 및 전반적 흐름

### 1.1 목표

1. **변경분만 전송**해 LLM 호출 비용-대역폭을 60 % 이상 절감한다.([Vercel][1], [GitHub][2])
2. _구글_ 알고리즘 **diff-match-patch**(Python판)로 **세밀한 diff**를 생성한다.([PyPI][3], [GitHub][4])
3. **python-patch**를 이용해 GNU Unified-Diff 규격으로 워크스페이스에 패치한다.([GitHub][5], [GitHub][5])
4. **GitPython**으로 _git add → commit → push_ 전 과정을 자동화한다.([Stack Overflow][6], [GitHub][7])
5. LLM 출력 형식은 **JSON 한 줄** + diff 텍스트(str) 하나만 포함해 파싱 오류를 차단한다.
6. **정확성 최우선**: 줄 번호·컨텍스트 3줄 보존, 적용 실패 시 자동 롤백·재시도.

### 1.2 데이터 흐름 개요

```pgsql
Gemini LLM ──▶ JSON{"diff": "..."} ──▶ diff-match-patch wrapper
   │                                            │
   └───────────(스트리밍)────────────────────────┘
         ▼
client_buffer(메모리) ──▶ python-patch.apply()  ──▶ GitPython.stage+commit()
```

- **스트리밍**으로 도착하는 JSON 청크를 모아 diff 문자열 완성 →
- **python-patch**가 워크스페이스 파일에 패치 적용 →
- **GitPython**이 커밋·푸시. 적용 실패 시 **fallback_full** 전송/재시도 로직.

---

## 2 장. 라이브러리 심층 분석

### 2.1 diff-match-patch (DMP)

| 항목        | 특징                                                                                   |
| ----------- | -------------------------------------------------------------------------------------- |
| 알고리즘    | Myers O(ND) 변형 + Bitap 최적화, 최소 편집거리 보장([PyPI][3])                         |
| 핵심 API    | `diff_main`, `patch_make`, `patch_toText`, `patch_fromText`([GitHub][4])               |
| 텍스트 포맷 | “Unidiff 유사”(`@@ -x,y +x,y @@`)지만 파일 헤더 отсутств. 3가지 차이 있음([GitHub][8]) |
| 장점        | 문단 이동·중복에도 강인, 코드·문서·자연어 모두 우수                                    |
| 단점        | 헤더 없음 → python-patch 호환성 문제. 후처리 필요                                      |

#### 2.1.1 헤더 보강 전략

```python
def to_unified_with_header(patch_text: str, path: str) -> str:
    header = f"--- a/{path}\n+++ b/{path}\n"
    return header + patch_text
```

_3줄 컨텍스트(`patch_make(..., 3)`) → 충돌 최소화_([Python documentation][9])

### 2.2 python-patch

- Unified-Diff 전용 파서·어플라이어, 라인피드·a/b prefix 보정 기능 내장([GitHub][5])
- returns `True/False`로 성공 여부 판단→실패 시 `git apply` 재시도.

### 2.3 GitPython

- `Repo.git.apply(diff_text, cached=True)` 로 스테이징 가능([Stack Overflow][6], [GitHub][7])
- 커밋: `repo.index.commit(msg)` → 푸시: `repo.remote().push()`.

---

## 3 장. 시스템 프롬프트 & JSON 프로토콜

```text
# SYSTEM (ko-KR)
모든 변경점은 3줄 컨텍스트 GNU-Unified-Diff(-u3) 로 작성하고
JSON 한 줄 { "diff": "<패치>" } 형태로만 응답하세요.
새 파일은 from "/dev/null", 삭제는 to "/dev/null".
줄 번호 불일치 시 "fallback_full": "<전체코드>" 추가 후 재전송.
압축·Base64 사용 금지.
```

*Gemini*의 **streaming=True** 호출 시 토큰이 생성되는 즉시 SSE-chunk로 수신.([GitHub][10], [Google AI for Developers][11])

---

## 4 장. 파이썬 구현 단계별 가이드

### 4.1 의존성 설치

```bash
pip install diff-match-patch python-patch gitpython
```

_패키지는 PyPI 공식 배포판_([PyPI][3], [GitHub][5])

### 4.2 DMP 래퍼 (diff 생성)

```python
from diff_match_patch import diff_match_patch
import pathlib

def dmp_unified(old_path: str, new_text: str) -> str:
    dmp = diff_match_patch()
    old_text = pathlib.Path(old_path).read_text()
    patches = dmp.patch_make(old_text, new_text, 3)     # 컨텍스트 3줄
    patch_txt = dmp.patch_toText(patches)               # @@ -x,y +x,y @@ ...
    return to_unified_with_header(patch_txt, old_path)  # 헤더 보강
```

### 4.3 Gemini 스트리밍 수신

```python
from google.ai import generativeai as genai   # GenAI SDK
import json, itertools

def stream_diff(prompt):
    resp = genai.chat(model="gemini-1.5-pro-latest",
                      messages=[{"role":"system","content":SYS},
                                {"role":"user","content":prompt}],
                      stream=True)
    buf = "".join(chunk.text for chunk in resp)
    j = json.loads(buf)
    return j["diff"], j.get("fallback_full")
```

_SDK 스트리밍 샘플_([GitHub][10], [Vercel][1])

### 4.4 패치 적용 + Git 커밋

```python
import patch, pathlib
from git import Repo, GitCommandError

def apply_and_commit(diff_text: str, repo_dir="."):
    # 1) 파일 시스템 패치
    ok = patch.fromstring(diff_text).apply(root=pathlib.Path(repo_dir))
    if not ok:
        raise RuntimeError("python-patch 실패")
    # 2) Git 스테이징·커밋
    repo = Repo(repo_dir)
    repo.git.apply(diff_text, cached=True)          # diff 재사용
    repo.index.commit("feat: Gemini 패치 반영")
    repo.remote().push()            # 원격 오류는 에러 처리
```

---

## 5 장. 예외·오류 처리

| 단계         | 가능 오류        | 대응                                                   |
| ------------ | ---------------- | ------------------------------------------------------ |
| DMP 생성     | 입력 파일 인코딩 | `errors="replace"`로 열기                              |
| JSON 파싱    | 중괄호 누락      | chunk 수신 종료 후 `json.loads` try/except             |
| python-patch | 줄 번호 충돌     | fallback_full 요청 후 덮어쓰기                         |
| GitPython    | 충돌, 인증       | `repo.git.merge("--abort")` + 재시도; SSH 키/토큰 주입 |

---

## 6 장. CI/CD 통합

1. **Pre-flight**

   ```yaml
   - name: Lint & Test
     run: |
       flake8 .
       pytest
   ```

2. **Patch Stage**: LLM 호출 → `apply_and_commit`.
3. **Verification**: `git diff --exit-code` 로 잔여 diff 없는지 확인.
4. **Docker 이미지 재빌드** (옵션) → 배포.

---

## 7 장. 보안·성능 고려

- **토큰 카운터**: Gemini SDK `response.usage.total_tokens` 활용.
- **비밀 키 관리**: `secrets.GEMINI_API_KEY`(GitHub Actions).
- **대용량 패치 분할**: 1 KiB 단위 청크를 배열로 쪼개 전송 후 병합.
- **롤백 전략**: `git stash --include-untracked`로 스냅샷 후 패치.
- **리뷰 게이트**: GitHub PR 생성 모드로 전환해 사람 검수 후 머지.

---

## 8 장. 확장·고급 활용

### 8.1 다중 파일 패치

`patch_toText` 에서 여러 파일을 한 세션에 포함하려면, 파일별로 DMP diff→헤더→`+=`. python-patch가 자동 분리.([GitHub][5])

### 8.2 JSON Patch 대안

JSON 트리 데이터엔 RFC 6902 Patch 사용 가능, 그러나 코드 문자열에선 토큰 효율이 낮음.([GitHub][2])

### 8.3 GUI 시각화

unidiff + `rich` 라이브러리로 터미널 컬러 diff 뷰어 구현.([GitHub][10])

---

## 9 장. 부록

### 9.1 주요 명령어 스니펫

| 목적                | 명령                                                                                              | 설명             |
| ------------------- | ------------------------------------------------------------------------------------------------- | ---------------- |
| 헤더 없는 패치 확인 | `grep -A2 -e '^@@' patch.txt`                                                                     | 첫 hunk 미리보기 |
| GitPython 환경 체크 | `python - <<'PY'\nimport git, pathlib, sys; print(git.Repo(pathlib.Path('.')).active_branch)\nPY` |                  |

### 9.2 참고·인용 목록

1. diff-match-patch API 문서([GitHub][4])
2. DMP PyPI 페이지([PyPI][3])
3. DMP Unidiff 포맷 차이 설명([GitHub][8])
4. python-patch GitHub README([GitHub][5])
5. difflib 공식 문서(컨텍스트 diff)([Python documentation][9])
6. GitPython 패치 처리 질문([Stack Overflow][6])
7. GitPython issue #923 패치 적용 토론([GitHub][7])
8. Gemini Streaming Notebook 샘플([GitHub][10])
9. Gemini 공식 Quickstart([Google AI for Developers][11])
10. Vercel LLM-Patcher 레포지토리([GitHub][12])
11. LLM JSON-Patch 스트림 제안 이슈 #2036([GitHub][2])
12. BugZoo Patch API(대안 적용 예)([squareslab.github.io][13])
13. difflib 적용 사례 StackOverflow([Stack Overflow][14])
14. diff-match-patch 사용법 Q\&A([Stack Overflow][15])
15. python-patch-ng (경량 대체)([GitHub][16])

---

## 10 장. 체크리스트 요약 ✅

- [x] **diff-match-patch**로 3줄 컨텍스트 패치 생성
- [x] 헤더 보강 → **python-patch** 호환
- [x] Gemini JSON 한 줄 스트림 → 파싱
- [x] 패치 적용 실패 시 **fallback_full** 처리
- [x] **GitPython**으로 stage → commit → push
- [x] CI: lint → test → push 성공 검증
- [x] 보안 키·롤백·토큰 모니터링 설정

이 가이드를 그대로 이행하면, 대규모 코드베이스라도 LLM-기반 자동 수정 파이프라인을 정확하고 가볍게 운영할 수 있습니다. 추가 도움이 필요하면 언제든 호출해 주세요! 😊

[1]: https://vercel.com/guides/streaming-from-llm?utm_source=chatgpt.com "Streaming responses from LLMs - Vercel"
[2]: https://github.com/vercel/ai/issues/2036?utm_source=chatgpt.com "Support streaming partial object chunks #2036 - vercel/ai - GitHub"
[3]: https://pypi.org/project/diff-match-patch/?utm_source=chatgpt.com "diff-match-patch - PyPI"
[4]: https://github.com/google/diff-match-patch/wiki/API?utm_source=chatgpt.com "API · google/diff-match-patch Wiki - GitHub"
[5]: https://github.com/techtonik/python-patch?utm_source=chatgpt.com "techtonik/python-patch: Library to parse and apply unified diffs"
[6]: https://stackoverflow.com/questions/33395539/gitpython-equivalent-of-git-apply?utm_source=chatgpt.com "gitpython equivalent of git-apply - Stack Overflow"
[7]: https://github.com/gitpython-developers/GitPython/issues/923?utm_source=chatgpt.com "[question] How to apply git patch? · Issue #923 - GitHub"
[8]: https://github.com/google/diff-match-patch/wiki/Unidiff?utm_source=chatgpt.com "Unidiff · google/diff-match-patch Wiki - GitHub"
[9]: https://docs.python.org/3/library/difflib.html?utm_source=chatgpt.com "difflib — Helpers for computing deltas — Python 3.13.3 documentation"
[10]: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Streaming.ipynb?utm_source=chatgpt.com "cookbook/quickstarts/Streaming.ipynb at main - Gemini API - GitHub"
[11]: https://ai.google.dev/gemini-api/docs/quickstart?utm_source=chatgpt.com "Gemini API quickstart | Google AI for Developers"
[12]: https://github.com/theluk/llm-patcher?utm_source=chatgpt.com "theluk/llm-patcher: Generate & Stream Patches of Changes ... - GitHub"
[13]: https://squareslab.github.io/BugZoo/api/patch.html?utm_source=chatgpt.com "Applying Patches — BugZoo 2.2.1 documentation - squaresLab"
[14]: https://stackoverflow.com/questions/2307472/generating-and-applying-diffs-in-python?utm_source=chatgpt.com "Generating and applying diffs in python - Stack Overflow"
[15]: https://stackoverflow.com/questions/40100256/how-to-use-python-diff-match-patch-to-create-a-patch-and-apply-it?utm_source=chatgpt.com "How to use python diff_match_patch to create a patch and apply it"
[16]: https://github.com/conan-io/python-patch-ng?utm_source=chatgpt.com "conan-io/python-patch-ng: Library to parse and apply unified diffs"



======== docs\Feature‑Atomic Hybrid(FAH) + Sub-Bus Structure.md ========
# Feature‑Atomic Hybrid(FAH) – **대규모 Slice 대비 기본 설계** 📚

> **목표** : 처음부터 **15 + Slice** 규모를 염두에 두고, _기능별 서브‑Bus_ 구조를 도입한 **Feature 중심 + Atomic 재사용 + Gateway Hub** 아키텍처를 제시합니다.

---

## 1. 핵심 개념 한눈에

| 레이어 | 설계 포인트 | 이유 |
| :--- | :--- | :--- |
| **Feature Slice** | 기능별 디렉터리, 내부 Atoms→Molecules→Organisms | 컨텍스트 최소화·재사용성 극대화 |
| **Gateway Hub** | _기능별 서브‑Command Bus_ + **공용 Event Bus** + **Service Locator** | 거대한 dict → 여러 Bus 인스턴스로 분산 → 로딩·토큰·메모리 최적화 |
| **Shared Atoms** | 공통 유틸 + 도메인 無 의존 | DRY·단위 테스트 쉽다 |

> **서브‑Command Bus 패턴** : 기능(Slice)마다 전용 Bus 모듈(`payments_command_bus.py`, `images_command_bus.py` …)을 두고, `gateway/__init__.py` 에서 _Facade_ 로 묶어 노출합니다.

---

## 2. 기본 폴더 구조 (15 + Slice 대응)

> **BASELINE** : 애초에 15개 이상 기능(Slice)을 예상하고 설계합니다. 모든 기능이 **서브‑Command Bus**를 갖도록 Gateway Hub를 구성합니다.

```tree
project-root/
├── src/
│   ├── gateway/
│   │   ├── __init__.py                # Facade – 서브 Bus·Event·Locator 재-export
│   │   ├── bus/                       # 기능별 서브‑Bus 모듈 폴더
│   │   │   ├── _base.py               # BaseCommandBus 공통 로직
│   │   │   ├── <feature_a>_command_bus.py
│   │   │   ├── <feature_b>_command_bus.py
│   │   │   ├── <feature_c>_command_bus.py
│   │   │   └── __init__.py            # Bus 모듈 자동 수집
│   │   ├── event_bus.py               # 공용 Event Bus
│   │   └── service_locator.py         # 공용 리소스 등록소
│   │
│   ├── features/                      # 기능 슬라이스들
│   │   ├── <feature_a>/
│   │   ├── <feature_b>/
│   │   └── <feature_c>/
│   │       ├── atoms/
│   │       ├── molecules/
│   │       ├── organisms/
│   │       ├── commands.py            # Pydantic Command 정의
│   │       ├── handlers.py            # <feature_c>CommandBus.register()
│   │       ├── tests/                 # Slice-specific tests
│   │       └── README.md
│   │
│   ├── shared/
│   │   └── atoms/                     # 공통 유틸
│   │
│   └── main.py                        # 배치 처리 등 진입점
│
├── tests/                             # Project-level tests (outside src)
├── configs/                           # Configuration files
├── resources/                         # Static resources
├── data/                              # Data files
📄 pyproject.toml
📄 README.md
... (other project files)
```

---

## 3. Gateway Hub 구현 ✨

### 3‑1 서브‑Command Bus 템플릿 (`src/gateway/bus/_base.py`)

```python
from typing import Callable, Dict, Type
from pydantic import BaseModel
import logging

logger_base_bus = logging.getLogger(__name__)

class Command(BaseModel): ...

class BaseCommandBus:
    # 각 서브클래스가 고유 핸들러를 갖도록 __init_subclass__에서 초기화
    def __init_subclass__(cls, **kwargs):
        super().__init_subclass__(**kwargs)
        cls._handlers = {}
        logger_base_bus.debug(f"Initialized _handlers for subclass: {cls.__name__}")

    @classmethod
    def register(cls, cmd_type: Type[Command]):
        def decorator(fn: Callable):
            if not hasattr(cls, '_handlers') or not isinstance(cls._handlers, dict):
                logger_base_bus.warning(f"_handlers not properly initialized for {cls.__name__}. Initializing now.")
                cls._handlers = {}
            
            cls._handlers[cmd_type] = fn
            logger_base_bus.info(f"Handler {fn.__name__} registered for command {cmd_type.__name__} in bus {cls.__name__}. Current handlers count: {len(cls._handlers)}")
            return fn
        return decorator

    @classmethod
    async def handle(cls, cmd: Command): # async로 변경
        if not hasattr(cls, '_handlers') or not isinstance(cls._handlers, dict):
             logger_base_bus.error(f"Cannot handle command: _handlers not initialized for {cls.__name__}")
             raise ValueError(f"_handlers not initialized for command bus {cls.__name__}")

        handler = cls._handlers.get(type(cmd))
        if handler:
            return await handler(cmd) # await 추가
        else:
            logger_base_bus.error(f"No handler registered for command type {type(cmd)} in {cls.__name__}. Available handlers: {list(cls._handlers.keys())}")
            raise ValueError(f"No handler registered for command type {type(cmd)} in {cls.__name__}")
```

### 3‑2 서브 Bus 템플릿 (`src/gateway/bus/<feature_x>_command_bus.py`)

```python
from ._base import BaseCommandBus

class <FeatureX>CommandBus(BaseCommandBus):
    """<Feature X> Slice 전용 Bus"""
```

> **특징** : 기능별 Bus 는 상속만 받으면 끝 – 핸들러는 `<FeatureX>CommandBus.register()` 로 연결합니다.

### 3‑3 Bus Facade (`src/gateway/__init__.py`)

```python
from importlib import import_module
from pathlib import Path
import logging

logger = logging.getLogger(__name__)

_bus_pkg_path = Path(__file__).parent / "bus"
if _bus_pkg_path.is_dir():
    for file in _bus_pkg_path.glob("*_command_bus.py"):
        module_name = f"src.gateway.bus.{file.stem}" # src. 추가
        try:
            module = import_module(module_name)
            bus_class_name = next((name for name in dir(module) if name.endswith("CommandBus") and name != "BaseCommandBus"), None)
            if bus_class_name:
                bus_instance_name = file.stem 
                globals()[bus_instance_name] = getattr(module, bus_class_name)
                logger.info(f"Successfully loaded and registered Command Bus: {bus_instance_name} (Class: {bus_class_name})")
            else:
                logger.warning(f"Could not find a CommandBus class in module: {module_name}")
        except ImportError as e:
            logger.error(f"Failed to import Command Bus module {module_name}: {e}")
        except Exception as e:
            logger.error(f"Error processing Command Bus module {module_name}: {e}")
else:
    logger.warning(f"Command Bus package directory not found: {_bus_pkg_path}")


from .event_bus import EventBus  # 공용 이벤트 버스
from .service_locator import ServiceLocator
```

- **사용 예** : `from src import gateway as gw; await gw.<feature_x>_command_bus.handle(cmd)` (`src` 디렉터리가 `PYTHONPATH`에 포함되어 `src`를 직접 임포트할 수 있어야 함)

### 3‑4 Event Bus (`src/gateway/event_bus.py`)

```python
from collections import defaultdict
from typing import Callable, DefaultDict, Any, Type
import logging

logger = logging.getLogger(__name__)

class Event:
    """이벤트의 기본 클래스로, 특정 이벤트 유형에 대해 서브클래싱할 수 있습니다."""
    pass

class EventBus:
    _subs: DefaultDict[Type[Event], list[Callable]] = defaultdict(list)

    @classmethod
    def on(cls, event_type: Type[Event]): # 파라미터 변경
        def decorator(fn: Callable):
            cls._subs[event_type].append(fn)
            logger.debug(f"Handler {fn.__name__} registered for event {event_type.__name__}")
            return fn
        return decorator

    @classmethod
    def emit(cls, event: Event, *args, **kwargs): # 파라미터 변경
        event_type = type(event)
        if event_type in cls._subs:
            logger.debug(f"Emitting event {event_type.__name__} to {len(cls._subs[event_type])} handlers. Event data: {event}")
            for fn in cls._subs[event_type]:
                try:
                    fn(event, *args, **kwargs) # event 인스턴스 전달
                except Exception as e:
                    logger.error(f"Error in event handler {fn.__name__} for event {event_type.__name__}: {e}", exc_info=True)
        else:
            logger.debug(f"No handlers registered for event {event_type.__name__}")
```

### 3‑5 Service Locator (`src/gateway/service_locator.py`)

```python
import logging
from typing import Any, Dict

_internal_logger = logging.getLogger("src.gateway.service_locator")

_module_level_pool: Dict[str, Any] = {} # 모듈 레벨 변수로 변경
_module_level_pool_initialized_log_done = False

if not _module_level_pool_initialized_log_done:
    _internal_logger.debug(f"ServiceLocator module instance created/imported. Initial _module_level_pool id: {id(_module_level_pool)}, content: {list(_module_level_pool.keys()) if _module_level_pool else 'empty'}")
    _module_level_pool_initialized_log_done = True

class ServiceLocator:
    _class_info_logged = False

    @classmethod
    def _log_class_info_once(cls):
        if not cls._class_info_logged:
            _internal_logger.debug(f"ServiceLocator class accessed. id(ServiceLocator class): {id(cls)}")
            cls._class_info_logged = True

    @classmethod
    def provide(cls, key: str, obj: Any) -> None:
        cls._log_class_info_once()
        global _module_level_pool
        _internal_logger.debug(f"[PROVIDE PRE] Key: '{key}', Current _module_level_pool id: {id(_module_level_pool)}, Current _module_level_pool keys: {list(_module_level_pool.keys())}")
        if key in _module_level_pool:
            _internal_logger.warning(f"Service key '{key}' already exists in ServiceLocator. Overwriting.")
        _module_level_pool[key] = obj
        _internal_logger.debug(f"[PROVIDE POST] Service '{key}' (type: {type(obj).__name__}) provided. New _module_level_pool keys: {list(_module_level_pool.keys())}, _module_level_pool id: {id(_module_level_pool)}")

    @classmethod
    def get(cls, key: str) -> Any:
        cls._log_class_info_once()
        global _module_level_pool
        _internal_logger.debug(f"[GET PRE] Key: '{key}', Current _module_level_pool id: {id(_module_level_pool)}, Current _module_level_pool keys: {list(_module_level_pool.keys())}")
        try:
            service = _module_level_pool[key]
            _internal_logger.debug(f"[GET POST] Service '{key}' (type: {type(service).__name__}) retrieved successfully.")
            return service
        except KeyError:
            _internal_logger.error(f"Service key '{key}' not found in ServiceLocator. _module_level_pool id: {id(_module_level_pool)}, Available services: {list(_module_level_pool.keys())}")
            raise KeyError(f"Service '{key}' not found. Available services: {list(_module_level_pool.keys())}")

    @classmethod
    def reset(cls) -> None:
        cls._log_class_info_once()
        global _module_level_pool
        _internal_logger.info(f"[RESET PRE] Current _module_level_pool id: {id(_module_level_pool)}, Current _module_level_pool keys: {list(_module_level_pool.keys())}")
        _module_level_pool.clear()
        _internal_logger.info(f"[RESET POST] ServiceLocator._module_level_pool has been cleared. _module_level_pool id: {id(_module_level_pool)}")
```

---

## 4. Slice‑측 코드 연결 가이드

> **자세한 예시는 ‘부록 A’에서 `images_resize` Slice를 참조하세요.** (주의: `images_resize`는 예시일 뿐, 현재 프로젝트에는 해당 Slice가 없습니다. 실제 프로젝트의 Slice 구조를 참고하세요.)

Slice 폴더 (`src/features/<feature_name>/`)의 `commands.py`와 `handlers.py`에서 다음 순서로 구현합니다:

1. `commands.py` – Pydantic `BaseModel`로 Command 객체 정의.
2. `handlers.py` – 해당 Slice 전용 **Command Bus**에 핸들러 등록. (핸들러는 `async`로 정의)
3. 비즈니스 로직 수행 후 필요 시 **Event Bus**로 이벤트 발행.

---

## 5. 테스트 전략 🧪 (대규모용)

| 레벨 | 도구 | 포인트 |
| :--- | :--- | :--- |
| Atom | pytest | 순수 함수 단위 |
| Slice | pytest‑cov | 서브 Bus → 핸들러 → Event 연동 |
| Bus | pytest | Bus 모듈 자동 로딩, 핸들러 중복 확인 |

---

## 6. CI 체크리스트 ✅

- Bus 모듈 추가 시 **linter**로 `*CommandBus` 클래스 여부 검증.
- `pytest‑cov` 로 Slice 커버리지 > 80 % 유지.
- `mkdocs` 로 `/docs` 자동 배포.

---

> 이렇게 처음부터 **기능별 서브‑Bus** 기반으로 설계하면, Slice 수가 급증해도 Bus 당 핸들러 수가 제한되어 유지보수·토큰·메모리 측면 모두 유리합니다!

---

---

## 부록 A. `images_resize` Slice 구조 예시 🖼️

> 아래 예시는 _썸네일 변환_ 기능이 FAH 구조에 어떻게 배치될 수 있는지 **구조와 핵심 코드 스니펫**만 보여줍니다. 모든 경로는 `src` 폴더를 기준으로 합니다. (주의: `images_resize`는 예시일 뿐, 현재 프로젝트에는 해당 Slice가 없습니다.)

### A.0 디렉터리 구조

```tree
src/
└── features/
    └── images_resize/
        ├── atoms/
        │   └── image_io.py            # 이미지 입·출력 유틸
        ├── molecules/
        │   └── resizer.py             # 리사이즈 로직
        ├── organisms/
        │   └── thumbnail_workflow.py  # 썸네일 파이프라인
        ├── commands.py                # ResizeImage Command
        ├── handlers.py                # Bus 핸들러 등록
        ├── tests/
        └── README.md
```

### A.1 `ImagesResizeCommandBus` (`src/gateway/bus/images_resize_command_bus.py`)

```python
from ._base import BaseCommandBus

class ImagesResizeCommandBus(BaseCommandBus):
    """images_resize Slice 전용 Bus"""
```

> **설명** : 이 파일은 `BaseCommandBus`를 상속해 **`images_resize` Slice 전용 명령 라우터**를 정의합니다. `register()` 데코레이터로 핸들러를 등록하고, `handle()` 메서드로 전달된 `ResizeImage` 명령을 올바른 핸들러에 위임합니다.

### A.2 Gateway Facade 호출 예 (`src/main.py`)

```python
from src import gateway as gw # src가 PYTHONPATH에 있다면 가능
from src.features.images_resize.commands import ResizeImage # src가 PYTHONPATH에 있다면 가능 (예시 경로)
import asyncio # asyncio 추가

async def main(): # async main 함수로 변경
    cmd = ResizeImage(id="cat001", width=128, height=128)
    result = await gw.images_resize_command_bus.handle(cmd) # await 추가
    print(result)

if __name__ == "__main__":
    asyncio.run(main()) # asyncio.run으로 실행
```

> **설명** : `gateway` 모듈을 **단일 Facade**로 불러와 `images_resize_command_bus`를 사용합니다. ① `ResizeImage` 명령 객체 생성 → ② 해당 Bus `handle()` 호출 (비동기) → ③ 등록된 핸들러 실행 후 결과를 반환하는 전체 흐름을 보여 줍니다. (`src` 폴더가 `PYTHONPATH`에 포함되어 있다고 가정합니다.)

### A.3 Event Bus 리스너 (`src/features/analytics/handlers.py`)

```python
from src.gateway.event_bus import EventBus, Event # src. 추가, Event 클래스 임포트
# from src.features.images_resize.events import ImageResizedEvent # 실제 이벤트 클래스 임포트 가정 (예시 경로)

# class ImageResizedEvent(Event): # 예시 이벤트 정의
#     def __init__(self, id: str):
#         self.id = id

# @EventBus.on(ImageResizedEvent) # 실제 이벤트 클래스 사용
def collect_metrics(event: Event): # 파라미터 변경 (event: ImageResizedEvent)
    # 썸네일 생성 통계 업데이트
    # print(f"Thumbnail ready for image {event.id}")
    print(f"Thumbnail ready for image {getattr(event, 'id', 'unknown')}") # getattr로 안전하게 접근
```

> **설명** : `EventBus.on()` 데코레이터로 **특정 이벤트 타입(`ImageResizedEvent` 등)**을 구독하고, 썸네일 생성이 완료될 때마다 간단한 통계 출력을 수행하는 예입니다. 핵심 로직과 통계 로직을 분리해 모듈 간 의존을 최소화합니다.

### A.4 Service Locator 초기화 (`src/main.py`)

```python
from src.gateway.service_locator import ServiceLocator # src. 추가
# from src.infrastructure.local_storage import LocalDiskStorage # src/infrastructure에 있다고 가정 (예시 경로)

# class LocalDiskStorage: # 예시 스토리지 클래스
#     def __init__(self, path): self.path = path
#     def load(self, id): print(f"Loading {id} from {self.path}"); return f"Image data for {id}"
#     def save(self, id, data): print(f"Saving {data} for {id} to {self.path}")

# ServiceLocator.provide("storage", LocalDiskStorage("./data")) # 경로는 프로젝트 루트 기준일 수 있음
```

> **설명** : `ServiceLocator`에 로컬 스토리지 구현체를 등록합니다. 핸들러는 키 `"storage"`로 스토리지를 조회하므로, 나중에 S3·MinIO 구현체로 교체할 때 **이 한 줄만 바꾸면** 됩니다. (`infrastructure` 패키지가 `src` 내에 위치한다고 가정합니다.)

### A.5 핸들러 등록 (`src/features/images_resize/handlers.py`)

```python
from src.gateway.bus.images_resize_command_bus import ImagesResizeCommandBus # src. 추가 (예시 경로)
from src.gateway.event_bus import EventBus, Event # src. 추가, Event 클래스 임포트
from src.gateway.service_locator import ServiceLocator # src. 추가
from .commands import ResizeImage # 현재 디렉터리 내 commands 모듈이므로 .commands 사용
import asyncio # 예시를 위해 추가

# class ImageResizedEvent(Event): # 예시 이벤트 정의
#     def __init__(self, id: str):
#         self.id = id

# class MockImage: # 예시 이미지 클래스
#     def resize(self, size): return f"Resized image to {size}"

@ImagesResizeCommandBus.register(ResizeImage)
async def handle_resize(cmd: ResizeImage): # async로 변경
    storage = ServiceLocator.get("storage")
    # img_data = storage.load(cmd.id) # 실제 로직에서는 이미지 객체 반환 가정
    # img = MockImage() # 예시 이미지 객체
    # thumb = img.resize((cmd.width, cmd.height))
    # storage.save(cmd.id, thumb)
    # EventBus.emit(ImageResizedEvent(id=cmd.id)) # 실제 이벤트 객체 사용
    # return f"Thumbnail for {cmd.id} processed." # 결과 반환 예시
    await asyncio.sleep(0.1) # 비동기 작업 예시
    print(f"Resizing image {cmd.id} to {cmd.width}x{cmd.height} using {storage}")
    EventBus.emit(Event()) # 간단한 이벤트 발생 예시
    return f"Image {cmd.id} resize requested."
```

> **설명** : 핸들러는 ① `ServiceLocator`에서 스토리지 인스턴스 획득 → ② 원본 이미지 로드 → ③ 리사이즈 수행 → ④ 저장 → ⑤ `EventBus.emit()`으로 후속 작업을 알리는 **비동기 순수 함수** 구현입니다. 의존성이 명확하므로 단위 테스트와 AI 코드 이해가 용이합니다.



======== pyproject.toml ========
[project]
name = "duck-prompt"
version = "0.2.1" # Version bump
description = "DuckPrompt: Code Enhancer & Meta Prompt Builder"
requires-python = ">=3.12"
dependencies = [
    "PyQt6>=6.7.0",
    "PyQt6-Qt6>=6.7.0",
    "google-generativeai>=0.5.4", # Gemini API
    "langgraph>=0.0.69", # LangGraph for workflow
    "tiktoken>=0.7.0", # Token calculation (GPT/fallback)
    "anthropic>=0.28.0", # Anthropic API (Claude)
    "psycopg2-binary>=2.9.9", # PostgreSQL driver
    "PyYAML>=6.0.1", # YAML parsing (config)
    "pydantic>=2.7.1", # Data validation and settings
    "pillow>=10.3.0", # Image handling
    "winotify>=1.1.0", # Windows notifications
    "pyinstaller>=6.13.0",
    "watchdog>=4.0.0", # Added for filesystem monitoring
    "diff-match-patch>=20230430", # DMP for code patches
]

[tool.black]
line-length = 88

[tool.isort]
profile = "black"

[tool.uv.sources]
# Optional: Specify custom package sources if needed

# Optional: Define project scripts or entry points
# [project.scripts]
# duckprompt = "src.app:main"

# Optional: Project URLs
# [project.urls]
# homepage = "https://example.com"
# documentation = "https://readthedocs.org"
# repository = "https://github.com/user/duck-prompt.git"
# changelog = "https://github.com/user/duck-prompt/blob/main/CHANGELOG.md"

# Optional: Author and maintainer information
# authors = [
#   { name="Your Name", email="your.email@example.com" },
# ]
# maintainers = [
#   { name="Your Name", email="your.email@example.com" },
# ]

# Optional: License information
# license = { text = "MIT License" }

# Optional: Keywords for PyPI
# keywords = ["llm", "prompt", "gui", "pyqt"]

# Optional: Classifiers for PyPI
# classifiers = [
#     "Development Status :: 3 - Alpha",
#     "Intended Audience :: Developers",
#     "License :: OSI Approved :: MIT License",
#     "Programming Language :: Python :: 3",
#     "Programming Language :: Python :: 3.12",
#     "Operating System :: OS Independent",
#     "Topic :: Software Development :: User Interfaces",
# ]



======== src\features\attachments\atoms\__init__.py ========



======== src\features\attachments\molecules\__init__.py ========



======== src\features\attachments\organisms\__init__.py ========



======== src\features\attachments\__init__.py ========



======== src\features\attachments\commands.py ========



======== src\features\attachments\handlers.py ========



======== src\features\config\atoms\__init__.py ========



======== src\features\config\atoms\settings_validator.py ========
"""Settings validator atom - validates configuration settings"""
import logging
from typing import Dict, Any
from pydantic import ValidationError
from src.features.config.pydantic_models.config_settings import ConfigSettings

logger = logging.getLogger(__name__)


class SettingsValidator:
    """Validates configuration settings using Pydantic models"""
    
    @staticmethod
    def validate(settings_dict: Dict[str, Any]) -> ConfigSettings:
        """Validate settings dictionary and return ConfigSettings model"""
        try:
            settings = ConfigSettings(**settings_dict)
            logger.debug("Settings validation successful")
            return settings
        except ValidationError as e:
            logger.error(f"Settings validation failed: {e}")
            raise ValueError(f"Invalid configuration settings: {e}")
    
    @staticmethod
    def validate_partial(settings_dict: Dict[str, Any], existing_settings: ConfigSettings) -> ConfigSettings:
        """Validate partial settings update against existing settings"""
        try:
            # Merge with existing settings
            current_dict = existing_settings.model_dump()
            current_dict.update(settings_dict)
            
            # Validate merged settings
            updated_settings = ConfigSettings(**current_dict)
            logger.debug("Partial settings validation successful")
            return updated_settings
        except ValidationError as e:
            logger.error(f"Partial settings validation failed: {e}")
            raise ValueError(f"Invalid configuration update: {e}")




======== src\features\config\molecules\__init__.py ========



======== src\features\config\molecules\api_key_selector.py ========
"""API key selector molecule - manages API key selection logic"""
import logging
import random
from typing import Optional, List, Dict, Any

logger = logging.getLogger(__name__)


class ApiKeySelector:
    """Manages selection of API keys with fallback and retry logic"""
    
    def __init__(self):
        self._user_selected_key_id: Optional[int] = None
        self._last_used_key: Optional[str] = None
        self._failed_keys: set = set()
    
    def set_user_selected_key(self, key_id: int) -> None:
        """Set user-selected API key preference"""
        self._user_selected_key_id = key_id
        logger.info(f"User selected Gemini key ID: {key_id}")
    
    def get_user_selected_key_id(self) -> Optional[int]:
        """Get user-selected key ID"""
        return self._user_selected_key_id
    
    def select_key(self, available_keys: List[Dict[str, Any]]) -> Optional[str]:
        """Select an API key based on user preference or randomly"""
        if not available_keys:
            logger.warning("No available API keys to select from")
            return None
        
        # Try user-selected key first
        if self._user_selected_key_id:
            for key_data in available_keys:
                if key_data.get('id') == self._user_selected_key_id:
                    selected_key = key_data.get('api_key')
                    if selected_key and selected_key not in self._failed_keys:
                        logger.info(f"Using user-selected Gemini key ID: {self._user_selected_key_id}")
                        return selected_key
            logger.warning(f"User-selected key ID {self._user_selected_key_id} not found or failed")
        
        # Filter out failed keys
        valid_keys = [
            k for k in available_keys 
            if k.get('api_key') and k.get('api_key') not in self._failed_keys
        ]
        
        if not valid_keys:
            logger.error("All API keys have failed")
            return None
        
        # Random selection from valid keys
        selected_key_data = random.choice(valid_keys)
        selected_key = selected_key_data.get('api_key')
        logger.info(f"Randomly selected Gemini key ID: {selected_key_data.get('id')}")
        
        return selected_key
    
    def mark_key_failed(self, key: str) -> None:
        """Mark a key as failed"""
        self._failed_keys.add(key)
        logger.warning(f"Marked API key as failed: {key[:10]}...")
    
    def mark_key_successful(self, key: str) -> None:
        """Mark a key as successful and remember it"""
        self._last_used_key = key
        self._failed_keys.discard(key)
        logger.info(f"API key used successfully: {key[:10]}...")
    
    def get_last_used_key(self) -> Optional[str]:
        """Get the last successfully used key"""
        return self._last_used_key
    
    def reset_failed_keys(self) -> None:
        """Reset the failed keys set"""
        self._failed_keys.clear()
        logger.info("Reset all failed API keys")


======== src\features\config\molecules\gitignore_manager.py ========
"""Gitignore manager molecule - manages gitignore patterns"""
import logging
from typing import List, Set
from pathlib import Path

logger = logging.getLogger(__name__)


class GitignoreManager:
    """Manages gitignore patterns from database and .gitignore file"""
    
    def __init__(self):
        self._db_patterns: Set[str] = set()
        self._file_patterns: Set[str] = set()
    
    def load_from_database(self, patterns: List[str]) -> None:
        """Load patterns from database"""
        self._db_patterns = set(patterns)
        logger.info(f"Loaded {len(patterns)} patterns from database")
    
    def load_from_file(self, gitignore_path: Path) -> None:
        """Load patterns from .gitignore file"""
        if not gitignore_path.exists():
            logger.warning(f".gitignore file not found at {gitignore_path}")
            return
        
        try:
            with open(gitignore_path, 'r', encoding='utf-8') as f:
                patterns = [
                    line.strip() 
                    for line in f 
                    if line.strip() and not line.startswith('#')
                ]
            self._file_patterns = set(patterns)
            logger.info(f"Loaded {len(patterns)} patterns from .gitignore file")
        except Exception as e:
            logger.error(f"Failed to load .gitignore file: {e}")
    
    def get_all_patterns(self) -> List[str]:
        """Get all unique patterns from both sources"""
        all_patterns = self._db_patterns.union(self._file_patterns)
        return sorted(list(all_patterns))
    
    def get_database_patterns(self) -> List[str]:
        """Get patterns from database only"""
        return sorted(list(self._db_patterns))
    
    def get_file_patterns(self) -> List[str]:
        """Get patterns from .gitignore file only"""
        return sorted(list(self._file_patterns))
    
    def update_database_patterns(self, patterns: List[str]) -> None:
        """Update database patterns"""
        self._db_patterns = set(patterns)
        logger.info(f"Updated database patterns: {len(patterns)} patterns")
    
    def should_ignore(self, file_path: str) -> bool:
        """Check if a file should be ignored based on patterns"""
        # This is a simplified implementation
        # In a real implementation, you'd use proper gitignore pattern matching
        for pattern in self.get_all_patterns():
            if pattern in file_path:
                return True
        return False


======== src\features\config\organisms\__init__.py ========



======== src\features\config\organisms\config_service.py ========
"""Configuration service organism - manages all configuration operations"""
import logging
from typing import Optional, Dict, Any, List
from pathlib import Path
from src.gateway import ServiceLocator
from src.features.config.pydantic_models.config_settings import ConfigSettings
from ..atoms.settings_validator import SettingsValidator
from ..molecules.api_key_selector import ApiKeySelector
from ..molecules.gitignore_manager import GitignoreManager

logger = logging.getLogger(__name__)


class ConfigurationService:
    """High-level configuration service"""
    
    def __init__(self, profile_name: str = 'default'):
        self.profile_name = profile_name
        self._settings: Optional[ConfigSettings] = None
        self.api_key_selector = ApiKeySelector()
        self.gitignore_manager = GitignoreManager()
        self.validator = SettingsValidator()
    
    async def load_configuration(self) -> ConfigSettings:
        """Load configuration from database"""
        try:
            # Get database service from ServiceLocator
            db_service = ServiceLocator.get("database")
            
            # Load application config
            config_data = await self._get_application_config(db_service)
            
            if not config_data:
                raise ValueError(f"Configuration profile '{self.profile_name}' not found in database")
            
            # Check for available API keys
            await self._check_api_keys(db_service)
            
            # Add API key placeholders
            config_data['gemini_api_key'] = None  # Selected on demand
            config_data['anthropic_api_key'] = await self._get_anthropic_key(db_service)
            
            # Validate and create settings
            self._settings = self.validator.validate(config_data)
            
            # Load gitignore patterns
            patterns = await self._get_gitignore_patterns(db_service)
            self.gitignore_manager.load_from_database(patterns)
            
            logger.info(f"Configuration loaded successfully for profile '{self.profile_name}'")
            return self._settings
            
        except Exception as e:
            logger.error(f"Failed to load configuration: {e}")
            raise
    
    async def update_configuration(self, settings_dict: Dict[str, Any]) -> bool:
        """Update configuration in database"""
        try:
            if not self._settings:
                raise ValueError("Configuration not loaded")
            
            # Validate update
            updated_settings = self.validator.validate_partial(settings_dict, self._settings)
            
            # Save to database (excluding API keys)
            db_service = ServiceLocator.get("database")
            config_dict = updated_settings.model_dump(exclude={'gemini_api_key', 'anthropic_api_key'})
            
            success = await self._save_application_config(db_service, config_dict)
            
            if success:
                self._settings = updated_settings
                logger.info("Configuration updated successfully")
            
            return success
            
        except Exception as e:
            logger.error(f"Failed to update configuration: {e}")
            return False
    
    async def get_active_gemini_key(self) -> Optional[str]:
        """Get active Gemini API key with selection logic"""
        try:
            db_service = ServiceLocator.get("database")
            available_keys = await self._get_available_gemini_keys(db_service)
            
            if not available_keys:
                logger.warning("No active Gemini API keys available")
                return None
            
            selected_key = self.api_key_selector.select_key(available_keys)
            return selected_key
            
        except Exception as e:
            logger.error(f"Failed to get active Gemini key: {e}")
            return None
    
    def get_settings(self) -> Optional[ConfigSettings]:
        """Get current configuration settings"""
        return self._settings
    
    def get_default_system_prompt_path(self) -> Optional[str]:
        """Get default system prompt path from settings"""
        if self._settings:
            return self._settings.default_system_prompt_path
        return None
    
    def get_temperature_settings(self) -> Dict[str, float]:
        """Get temperature settings for Gemini"""
        if not self._settings:
            return {"temperature": 0.7, "top_p": 0.95, "top_k": 40}
        
        return {
            "temperature": self._settings.gemini_temperature,
            "top_p": self._settings.gemini_top_p,
            "top_k": self._settings.gemini_top_k
        }
    
    def get_token_limits(self) -> Dict[str, int]:
        """Get token limit settings"""
        if not self._settings:
            return {"max_output_tokens": 8192}
        
        return {
            "max_output_tokens": self._settings.gemini_max_output_tokens
        }
    
    # Private helper methods for database operations
    async def _get_application_config(self, db_service) -> Dict[str, Any]:
        """Get application config from database"""
        from src.features.database.commands import GetAllConfigs
        configs = await db_service.handle(GetAllConfigs())
        
        # Convert list of configs to dict
        config_dict = {}
        for config in configs:
            config_dict[config['key']] = config['value']
        
        return config_dict
    
    async def _save_application_config(self, db_service, config_dict: Dict[str, Any]) -> bool:
        """Save application config to database"""
        from src.features.database.commands import SaveConfig
        
        for key, value in config_dict.items():
            await db_service.handle(SaveConfig(key=key, value=str(value)))
        
        return True
    
    async def _get_available_gemini_keys(self, db_service) -> List[Dict[str, Any]]:
        """Get available Gemini API keys"""
        from src.features.database.commands import ExecuteQuery
        query = "SELECT * FROM api_keys WHERE service_name = 'google' AND is_active = true"
        return await db_service.handle(ExecuteQuery(query=query, fetch_all=True))
    
    async def _get_anthropic_key(self, db_service) -> Optional[str]:
        """Get active Anthropic API key"""
        from src.features.database.commands import GetActiveApiKey
        return await db_service.handle(GetActiveApiKey(service_name='anthropic'))
    
    async def _check_api_keys(self, db_service) -> None:
        """Check availability of API keys"""
        gemini_keys = await self._get_available_gemini_keys(db_service)
        if not gemini_keys:
            logger.warning("No active Gemini API keys found in database")
        else:
            logger.info(f"Found {len(gemini_keys)} active Gemini API keys")
    
    async def _get_gitignore_patterns(self, db_service) -> List[str]:
        """Get gitignore patterns from database"""
        from src.features.database.commands import GetIgnoredPatterns
        return await db_service.handle(GetIgnoredPatterns())



======== src\features\config\pydantic_models\__init__.py ========



======== src\features\config\pydantic_models\config_settings.py ========
"""Pydantic model for application configuration settings."""
from pydantic import BaseModel, Field
from typing import List, Optional

class ConfigSettings(BaseModel):
    """Defines the structure for application configuration settings."""
    profile_name: str = 'default'
    default_system_prompt_path: Optional[str] = Field(None, alias='default_system_prompt')
    allowed_extensions: Optional[List[str]] = []
    excluded_dirs: Optional[List[str]] = []
    default_ignore_list: Optional[List[str]] = []
    
    gemini_default_model: Optional[str] = None
    claude_default_model: Optional[str] = None
    gpt_default_model: Optional[str] = None
    
    gemini_available_models: Optional[List[str]] = []
    claude_available_models: Optional[List[str]] = []
    gpt_available_models: Optional[List[str]] = []
    
    gemini_temperature: float = Field(default=0.0, ge=0.0, le=2.0)
    gemini_enable_thinking: bool = True
    gemini_thinking_budget: int = 24576
    gemini_enable_search: bool = True
    
    # API keys are added dynamically by the service, not loaded from DB config table
    gemini_api_key: Optional[str] = None
    anthropic_api_key: Optional[str] = None

    class Config:
        populate_by_name = True
        # This allows 'default_system_prompt' from DB to map to 'default_system_prompt_path'



======== src\features\config\__init__.py ========



======== src\features\config\commands.py ========
"""Configuration feature commands"""
from typing import Optional, List, Dict, Any
from src.gateway.bus._base import Command


class LoadConfiguration(Command):
    """Command to load configuration from database"""
    profile_name: str = 'default'


class UpdateConfiguration(Command):
    """Command to update configuration settings"""
    settings: Dict[str, Any]
    profile_name: str = 'default'


class GetActiveGeminiKey(Command):
    """Command to get active Gemini API key"""
    pass


class SetUserSelectedGeminiKey(Command):
    """Command to set user-selected Gemini API key"""
    key_id: int


class GetAvailableGeminiKeys(Command):
    """Command to get all available Gemini API keys"""
    pass


class GetLastUsedGeminiKey(Command):
    """Command to get the last successfully used Gemini key"""
    pass


class UpdateGitignorePatterns(Command):
    """Command to update gitignore patterns"""
    patterns: List[str]


class GetGitignorePatterns(Command):
    """Command to get current gitignore patterns"""
    pass


class GetDefaultSystemPromptPath(Command):
    """Command to get the default system prompt path"""
    pass


class GetTemperatureSettings(Command):
    """Command to get temperature settings for Gemini"""
    pass


class GetTokenLimits(Command):
    """Command to get token limit settings"""
    pass


======== src\features\config\handlers.py ========
"""Configuration feature command handlers"""
import logging
from src.gateway.bus.config_command_bus import ConfigCommandBus
from src.gateway.event_bus import EventBus, Event
from src.gateway.service_locator import ServiceLocator
from .commands import (
    LoadConfiguration, UpdateConfiguration,
    GetActiveGeminiKey, SetUserSelectedGeminiKey,
    GetAvailableGeminiKeys, GetLastUsedGeminiKey,
    UpdateGitignorePatterns, GetGitignorePatterns,
    GetDefaultSystemPromptPath, GetTemperatureSettings,
    GetTokenLimits
)
from .organisms.config_service import ConfigurationService

logger = logging.getLogger(__name__)


# Configuration events
class ConfigurationLoadedEvent(Event):
    """Event emitted when configuration is loaded"""
    def __init__(self, profile_name: str):
        self.profile_name = profile_name


class ConfigurationUpdatedEvent(Event):
    """Event emitted when configuration is updated"""
    def __init__(self, profile_name: str):
        self.profile_name = profile_name


# Initialize configuration service and register with ServiceLocator
config_service = ConfigurationService()
ServiceLocator.provide("config", config_service)


@ConfigCommandBus.register(LoadConfiguration)
async def handle_load_configuration(cmd: LoadConfiguration):
    """Load configuration from database"""
    config_service = ServiceLocator.get("config")
    config_service.profile_name = cmd.profile_name
    
    settings = await config_service.load_configuration()
    EventBus.emit(ConfigurationLoadedEvent(profile_name=cmd.profile_name))
    
    return {
        "status": "loaded",
        "profile": cmd.profile_name,
        "settings": settings.model_dump()
    }


@ConfigCommandBus.register(UpdateConfiguration)
async def handle_update_configuration(cmd: UpdateConfiguration):
    """Update configuration settings"""
    config_service = ServiceLocator.get("config")
    
    success = await config_service.update_configuration(cmd.settings)
    
    if success:
        EventBus.emit(ConfigurationUpdatedEvent(profile_name=cmd.profile_name))
    
    return {"success": success}


@ConfigCommandBus.register(GetActiveGeminiKey)
async def handle_get_active_gemini_key(cmd: GetActiveGeminiKey):
    """Get active Gemini API key"""
    config_service = ServiceLocator.get("config")
    key = await config_service.get_active_gemini_key()
    return {"api_key": key}


@ConfigCommandBus.register(SetUserSelectedGeminiKey)
async def handle_set_user_selected_key(cmd: SetUserSelectedGeminiKey):
    """Set user-selected Gemini key preference"""
    config_service = ServiceLocator.get("config")
    config_service.api_key_selector.set_user_selected_key(cmd.key_id)
    return {"status": "set", "key_id": cmd.key_id}


@ConfigCommandBus.register(GetAvailableGeminiKeys)
async def handle_get_available_keys(cmd: GetAvailableGeminiKeys):
    """Get all available Gemini API keys"""
    db_service = ServiceLocator.get("database")
    from src.features.database.commands import ExecuteQuery
    
    query = "SELECT id, service_name, is_active FROM api_keys WHERE service_name = 'google' AND is_active = true"
    keys = await db_service.handle(ExecuteQuery(query=query, fetch_all=True))
    
    return {"keys": keys}


@ConfigCommandBus.register(GetLastUsedGeminiKey)
async def handle_get_last_used_key(cmd: GetLastUsedGeminiKey):
    """Get the last successfully used Gemini key"""
    config_service = ServiceLocator.get("config")
    key = config_service.api_key_selector.get_last_used_key()
    return {"api_key": key}


@ConfigCommandBus.register(UpdateGitignorePatterns)
async def handle_update_gitignore(cmd: UpdateGitignorePatterns):
    """Update gitignore patterns in database"""
    db_service = ServiceLocator.get("database")
    config_service = ServiceLocator.get("config")
    
    from src.features.database.commands import SaveIgnoredPatterns
    await db_service.handle(SaveIgnoredPatterns(patterns=cmd.patterns))
    
    # Update in-memory patterns
    config_service.gitignore_manager.update_database_patterns(cmd.patterns)
    
    return {"status": "updated", "count": len(cmd.patterns)}


@ConfigCommandBus.register(GetGitignorePatterns)
async def handle_get_gitignore(cmd: GetGitignorePatterns):
    """Get current gitignore patterns"""
    config_service = ServiceLocator.get("config")
    patterns = config_service.gitignore_manager.get_all_patterns()
    
    return {
        "patterns": patterns,
        "db_patterns": config_service.gitignore_manager.get_database_patterns(),
        "file_patterns": config_service.gitignore_manager.get_file_patterns()
    }


@ConfigCommandBus.register(GetDefaultSystemPromptPath)
async def handle_get_default_prompt_path(cmd: GetDefaultSystemPromptPath):
    """Get default system prompt path"""
    config_service = ServiceLocator.get("config")
    path = config_service.get_default_system_prompt_path()
    return {"path": path}


@ConfigCommandBus.register(GetTemperatureSettings)
async def handle_get_temperature(cmd: GetTemperatureSettings):
    """Get temperature settings for Gemini"""
    config_service = ServiceLocator.get("config")
    settings = config_service.get_temperature_settings()
    return settings


@ConfigCommandBus.register(GetTokenLimits)
async def handle_get_token_limits(cmd: GetTokenLimits):
    """Get token limit settings"""
    config_service = ServiceLocator.get("config")
    limits = config_service.get_token_limits()
    return limits


======== src\features\database\atoms\__init__.py ========



======== src\features\database\atoms\db_connection.py ========
"""Database connection atom - manages PostgreSQL connection"""
import psycopg2
import logging
from typing import Optional, Dict, Any
from psycopg2.extensions import connection as Connection

logger = logging.getLogger(__name__)

# Database connection configuration (hardcoded as per requirements)
DB_CONFIG = {
    "host": "postgresdb.lab.miraker.me",
    "user": "shacea",
    "password": "alfkzj9389",
    "port": 5333,
    "database": "duck_agent"
}


class DatabaseConnection:
    """Atomic component for database connection management"""
    
    def __init__(self, db_config: Dict[str, Any] = DB_CONFIG):
        self.db_config = db_config
        self.connection: Optional[Connection] = None
        
    def connect(self) -> None:
        """Establishes a connection to the PostgreSQL database"""
        if self.connection and not self.connection.closed:
            return  # Already connected
            
        try:
            logger.info(f"Connecting to database '{self.db_config['database']}' on {self.db_config['host']}...")
            self.connection = psycopg2.connect(**self.db_config)
            logger.info("Database connection successful.")
        except psycopg2.Error as e:
            logger.critical(f"Database connection failed: {e}", exc_info=True)
            self.connection = None
            raise ConnectionError(f"Failed to connect to the database: {e}")
    
    def disconnect(self) -> None:
        """Closes the database connection"""
        if self.connection and not self.connection.closed:
            self.connection.close()
            logger.info("Database connection closed.")
        self.connection = None
    
    def is_connected(self) -> bool:
        """Check if the database connection is active"""
        return bool(self.connection and not self.connection.closed)
    
    def get_connection(self) -> Connection:
        """Get the active database connection"""
        if not self.is_connected():
            self.connect()
        if self.connection is None:
            raise ConnectionError("Failed to establish a database connection.")
        return self.connection



======== src\features\database\atoms\query_executor.py ========
"""Query executor atom - handles SQL query execution"""
import psycopg2
import logging
from typing import Optional, Any, List, Dict
from psycopg2.extensions import connection as Connection

logger = logging.getLogger(__name__)


class QueryExecutor:
    """Atomic component for executing database queries"""
    
    def __init__(self, connection: Connection):
        self.connection = connection
    
    def execute(
        self, 
        query: str, 
        params: Optional[tuple] = None,
        fetch_one: bool = False,
        fetch_all: bool = False,
        return_id: bool = False
    ) -> Optional[Any]:
        """Execute a SQL query and return the result"""
        if not self.connection or self.connection.closed:
            raise ConnectionError("Database connection is not active")
            
        cursor = None
        try:
            cursor = self.connection.cursor()
            logger.debug(f"Executing query: {query} with params: {params}")
            cursor.execute(query, params)
            
            if return_id:
                result = cursor.fetchone()
                self.connection.commit()
                logger.debug(f"Query returned ID: {result[0] if result else None}")
                return result[0] if result else None
            elif fetch_one:
                result = cursor.fetchone()
                if result and cursor.description:
                    colnames = [desc[0] for desc in cursor.description]
                    row_dict = dict(zip(colnames, result))
                    logger.debug(f"Query fetched one row: {row_dict}")
                    return row_dict
                elif result:
                    logger.debug(f"Query fetched one value: {result[0]}")
                    return result[0]
                else:
                    logger.debug("Query fetched no results (fetch_one).")
                    return None
            elif fetch_all:
                if cursor.description:
                    colnames = [desc[0] for desc in cursor.description]
                    rows = cursor.fetchall()
                    results_list = [dict(zip(colnames, row)) for row in rows]
                    logger.debug(f"Query fetched {len(results_list)} rows.")
                    return results_list
                else:
                    logger.debug("Query fetched no results (fetch_all).")
                    return []
            else:
                affected_rows = cursor.rowcount
                self.connection.commit()
                logger.debug(f"Query executed successfully. Rows affected: {affected_rows}")
                return affected_rows
        except psycopg2.Error as e:
            logger.error(f"Database query failed: {e}\nQuery: {query}\nParams: {params}", exc_info=True)
            if self.connection:
                self.connection.rollback()
            raise
        finally:
            if cursor:
                cursor.close()



======== src\features\database\molecules\__init__.py ========



======== src\features\database\molecules\api_key_manager.py ========
"""API key management molecule"""
import logging
from typing import Optional, Dict, Any
from ..atoms.query_executor import QueryExecutor

logger = logging.getLogger(__name__)


class ApiKeyManager:
    """Manages API keys in the database"""
    
    def __init__(self, query_executor: QueryExecutor):
        self.executor = query_executor
    
    def get_api_key(self, service_name: str) -> Optional[Dict[str, Any]]:
        """Get an API key for a specific service"""
        query = "SELECT * FROM api_keys WHERE service_name = %s"
        result = self.executor.execute(query, (service_name,), fetch_one=True)
        if result:
            logger.info(f"Retrieved API key for service: {service_name}")
        else:
            logger.warning(f"No API key found for service: {service_name}")
        return result
    
    def get_active_api_key(self, service_name: str) -> Optional[str]:
        """Get the active API key for a specific service"""
        query = "SELECT api_key FROM api_keys WHERE service_name = %s AND is_active = true"
        result = self.executor.execute(query, (service_name,), fetch_one=True)
        if result:
            logger.info(f"Retrieved active API key for service: {service_name}")
            return result if isinstance(result, str) else result.get('api_key')
        else:
            logger.warning(f"No active API key found for service: {service_name}")
            return None
    
    def save_api_key(self, service_name: str, api_key: str, is_active: bool = True) -> int:
        """Save or update an API key"""
        # Check if the API key already exists
        existing = self.get_api_key(service_name)
        
        if existing:
            # Update existing key
            query = """
                UPDATE api_keys 
                SET api_key = %s, is_active = %s, updated_at = CURRENT_TIMESTAMP
                WHERE service_name = %s
            """
            result = self.executor.execute(query, (api_key, is_active, service_name))
            logger.info(f"Updated API key for service: {service_name}")
        else:
            # Insert new key
            query = """
                INSERT INTO api_keys (service_name, api_key, is_active)
                VALUES (%s, %s, %s)
            """
            result = self.executor.execute(query, (service_name, api_key, is_active))
            logger.info(f"Inserted new API key for service: {service_name}")
        
        return result


======== src\features\database\molecules\config_manager.py ========
"""Configuration management molecule"""
import logging
from typing import Optional, Dict, Any, List
from ..atoms.query_executor import QueryExecutor

logger = logging.getLogger(__name__)


class ConfigManager:
    """Manages application configuration in the database"""
    
    def __init__(self, query_executor: QueryExecutor):
        self.executor = query_executor
    
    def get_config(self, key: str) -> Optional[str]:
        """Get a configuration value by key"""
        query = "SELECT value FROM application_config WHERE key = %s"
        result = self.executor.execute(query, (key,), fetch_one=True)
        if result:
            value = result if isinstance(result, str) else result.get('value')
            logger.info(f"Retrieved config for key '{key}': {value}")
            return value
        else:
            logger.warning(f"No configuration found for key: {key}")
            return None
    
    def save_config(self, key: str, value: str) -> int:
        """Save or update a configuration value"""
        # Check if the config already exists
        existing = self.get_config(key)
        
        if existing is not None:
            # Update existing config
            query = """
                UPDATE application_config 
                SET value = %s, updated_at = CURRENT_TIMESTAMP
                WHERE key = %s
            """
            result = self.executor.execute(query, (value, key))
            logger.info(f"Updated config for key '{key}' with value: {value}")
        else:
            # Insert new config
            query = """
                INSERT INTO application_config (key, value)
                VALUES (%s, %s)
            """
            result = self.executor.execute(query, (key, value))
            logger.info(f"Inserted new config for key '{key}' with value: {value}")
        
        return result
    
    def get_all_configs(self) -> List[Dict[str, Any]]:
        """Get all configuration values"""
        query = "SELECT * FROM application_config ORDER BY key"
        results = self.executor.execute(query, fetch_all=True)
        logger.info(f"Retrieved {len(results)} configuration entries")
        return results
    
    def get_model_configs(self) -> List[Dict[str, Any]]:
        """Get model configurations"""
        query = """
            SELECT * FROM model_configs 
            WHERE is_active = true 
            ORDER BY provider, model_name
        """
        results = self.executor.execute(query, fetch_all=True)
        logger.info(f"Retrieved {len(results)} model configurations")
        return results


======== src\features\database\molecules\gemini_log_manager.py ========
"""Gemini API log management molecule"""
import logging
from typing import Optional, Dict, Any, List
from decimal import Decimal
from ..atoms.query_executor import QueryExecutor

logger = logging.getLogger(__name__)


class GeminiLogManager:
    """Manages Gemini API logs in the database"""
    
    def __init__(self, query_executor: QueryExecutor):
        self.executor = query_executor
    
    def save_log(
        self,
        model_name: str,
        prompt_tokens: int,
        response_tokens: int,
        total_tokens: int,
        prompt_cost: float,
        response_cost: float,
        total_cost: float,
        response_text: Optional[str] = None,
        response_summary: Optional[str] = None
    ) -> int:
        """Save a Gemini API log entry"""
        query = """
            INSERT INTO gemini_logs (
                model_name, prompt_tokens, response_tokens, total_tokens,
                prompt_cost, response_cost, total_cost, response_text, response_summary
            ) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s)
            RETURNING id
        """
        params = (
            model_name,
            prompt_tokens,
            response_tokens,
            total_tokens,
            Decimal(str(prompt_cost)),
            Decimal(str(response_cost)),
            Decimal(str(total_cost)),
            response_text,
            response_summary
        )
        
        log_id = self.executor.execute(query, params, return_id=True)
        logger.info(f"Saved Gemini log entry with ID: {log_id}")
        return log_id
    
    def get_logs(self, limit: int = 100, offset: int = 0) -> List[Dict[str, Any]]:
        """Retrieve Gemini logs with pagination"""
        query = """
            SELECT * FROM gemini_logs 
            ORDER BY created_at DESC 
            LIMIT %s OFFSET %s
        """
        results = self.executor.execute(query, (limit, offset), fetch_all=True)
        logger.info(f"Retrieved {len(results)} Gemini log entries")
        return results
    
    def get_total_usage(self) -> Dict[str, Any]:
        """Get total token usage and costs"""
        query = """
            SELECT 
                COUNT(*) as total_requests,
                SUM(prompt_tokens) as total_prompt_tokens,
                SUM(response_tokens) as total_response_tokens,
                SUM(total_tokens) as total_tokens,
                SUM(total_cost) as total_cost
            FROM gemini_logs
        """
        result = self.executor.execute(query, fetch_one=True)
        return result or {}


======== src\features\database\organisms\__init__.py ========



======== src\features\database\organisms\database_service.py ========
"""Database service organism - combines all database operations"""
import logging
from typing import Optional, Dict, Any, List
from ..atoms.db_connection import DatabaseConnection
from ..atoms.query_executor import QueryExecutor
from ..molecules.api_key_manager import ApiKeyManager
from ..molecules.config_manager import ConfigManager
from ..molecules.gemini_log_manager import GeminiLogManager

logger = logging.getLogger(__name__)


class DatabaseService:
    """High-level database service combining all database operations"""
    
    def __init__(self):
        self.db_connection = DatabaseConnection()
        self.query_executor: Optional[QueryExecutor] = None
        self.api_key_manager: Optional[ApiKeyManager] = None
        self.config_manager: Optional[ConfigManager] = None
        self.gemini_log_manager: Optional[GeminiLogManager] = None
        self._initialize()
    
    def _initialize(self):
        """Initialize the database connection and managers"""
        try:
            self.db_connection.connect()
            connection = self.db_connection.get_connection()
            self.query_executor = QueryExecutor(connection)
            self.api_key_manager = ApiKeyManager(self.query_executor)
            self.config_manager = ConfigManager(self.query_executor)
            self.gemini_log_manager = GeminiLogManager(self.query_executor)
            logger.info("Database service initialized successfully")
        except Exception as e:
            logger.error(f"Failed to initialize database service: {e}")
            raise
    
    def connect(self) -> None:
        """Connect to the database"""
        self.db_connection.connect()
        self._initialize()
    
    def disconnect(self) -> None:
        """Disconnect from the database"""
        self.db_connection.disconnect()
        self.query_executor = None
        self.api_key_manager = None
        self.config_manager = None
        self.gemini_log_manager = None
    
    def is_connected(self) -> bool:
        """Check if the database is connected"""
        return self.db_connection.is_connected()
    
    def execute_query(
        self, 
        query: str, 
        params: Optional[tuple] = None,
        fetch_one: bool = False,
        fetch_all: bool = False,
        return_id: bool = False
    ) -> Optional[Any]:
        """Execute a raw SQL query"""
        if not self.query_executor:
            raise ConnectionError("Database service not initialized")
        return self.query_executor.execute(query, params, fetch_one, fetch_all, return_id)
    
    def get_ignored_patterns(self) -> List[str]:
        """Get ignored file patterns from the database"""
        query = "SELECT pattern FROM gitignore_patterns ORDER BY pattern"
        results = self.execute_query(query, fetch_all=True)
        return [r['pattern'] for r in results] if results else []
    
    def save_ignored_patterns(self, patterns: List[str]) -> None:
        """Save ignored file patterns to the database"""
        # Clear existing patterns
        self.execute_query("DELETE FROM gitignore_patterns")
        
        # Insert new patterns
        for pattern in patterns:
            if pattern.strip():
                query = "INSERT INTO gitignore_patterns (pattern) VALUES (%s)"
                self.execute_query(query, (pattern.strip(),))
        
        logger.info(f"Saved {len(patterns)} ignored patterns to database")


======== src\features\database\__init__.py ========



======== src\features\database\commands.py ========
"""Database feature commands"""
from typing import Optional, Dict, Any, List
from src.gateway.bus._base import Command


class ConnectDatabase(Command):
    """Command to establish database connection"""
    pass


class DisconnectDatabase(Command):
    """Command to close database connection"""
    pass


class ExecuteQuery(Command):
    """Command to execute a database query"""
    query: str
    params: Optional[tuple] = None
    fetch_one: bool = False
    fetch_all: bool = False
    return_id: bool = False


class GetApiKey(Command):
    """Command to get an API key from database"""
    service_name: str


class GetActiveApiKey(Command):
    """Command to get an active API key for a service"""
    service_name: str


class SaveApiKey(Command):
    """Command to save or update an API key"""
    service_name: str
    api_key: str
    is_active: bool = True


class GetConfig(Command):
    """Command to get a configuration value"""
    key: str


class SaveConfig(Command):
    """Command to save a configuration value"""
    key: str
    value: str


class GetAllConfigs(Command):
    """Command to get all configuration values"""
    pass


class GetModelConfigs(Command):
    """Command to get model configurations"""
    pass


class SaveGeminiLog(Command):
    """Command to save a Gemini API log entry"""
    model_name: str
    prompt_tokens: int
    response_tokens: int
    total_tokens: int
    prompt_cost: float
    response_cost: float
    total_cost: float
    response_text: Optional[str] = None
    response_summary: Optional[str] = None


class GetGeminiLogs(Command):
    """Command to retrieve Gemini logs"""
    limit: int = 100
    offset: int = 0


class GetIgnoredPatterns(Command):
    """Command to get ignored file patterns"""
    pass


class SaveIgnoredPatterns(Command):
    """Command to save ignored file patterns"""
    patterns: List[str]


class CheckDatabaseConnection(Command):
    """Command to check if database connection is active"""
    pass


======== src\features\database\handlers.py ========
"""Database feature command handlers"""
import logging
from src.gateway.bus.database_command_bus import DatabaseCommandBus
from src.gateway import EventBus, Event, ServiceLocator
from .commands import (
    ConnectDatabase, DisconnectDatabase, ExecuteQuery,
    GetApiKey, GetActiveApiKey, SaveApiKey,
    GetConfig, SaveConfig, GetAllConfigs, GetModelConfigs,
    SaveGeminiLog, GetGeminiLogs,
    GetIgnoredPatterns, SaveIgnoredPatterns,
    CheckDatabaseConnection
)
from .organisms.database_service import DatabaseService

logger = logging.getLogger(__name__)


# Database connection events
class DatabaseConnectedEvent(Event):
    """Event emitted when database is connected"""
    pass


class DatabaseDisconnectedEvent(Event):
    """Event emitted when database is disconnected"""
    pass


# Initialize database service and register with ServiceLocator
db_service = DatabaseService()
ServiceLocator.provide("database", db_service)


@DatabaseCommandBus.register(ConnectDatabase)
async def handle_connect_database(cmd: ConnectDatabase):
    """Handle database connection command"""
    db_service = ServiceLocator.get("database")
    db_service.connect()
    EventBus.emit(DatabaseConnectedEvent())
    return {"status": "connected"}


@DatabaseCommandBus.register(DisconnectDatabase)
async def handle_disconnect_database(cmd: DisconnectDatabase):
    """Handle database disconnection command"""
    db_service = ServiceLocator.get("database")
    db_service.disconnect()
    EventBus.emit(DatabaseDisconnectedEvent())
    return {"status": "disconnected"}


@DatabaseCommandBus.register(CheckDatabaseConnection)
async def handle_check_connection(cmd: CheckDatabaseConnection):
    """Check if database is connected"""
    db_service = ServiceLocator.get("database")
    return {"connected": db_service.is_connected()}


@DatabaseCommandBus.register(ExecuteQuery)
async def handle_execute_query(cmd: ExecuteQuery):
    """Execute a raw SQL query"""
    db_service = ServiceLocator.get("database")
    result = db_service.execute_query(
        cmd.query, 
        cmd.params, 
        cmd.fetch_one, 
        cmd.fetch_all, 
        cmd.return_id
    )
    return result


@DatabaseCommandBus.register(GetApiKey)
async def handle_get_api_key(cmd: GetApiKey):
    """Get an API key for a service"""
    db_service = ServiceLocator.get("database")
    return db_service.api_key_manager.get_api_key(cmd.service_name)


@DatabaseCommandBus.register(GetActiveApiKey)
async def handle_get_active_api_key(cmd: GetActiveApiKey):
    """Get the active API key for a service"""
    db_service = ServiceLocator.get("database")
    return db_service.api_key_manager.get_active_api_key(cmd.service_name)


@DatabaseCommandBus.register(SaveApiKey)
async def handle_save_api_key(cmd: SaveApiKey):
    """Save or update an API key"""
    db_service = ServiceLocator.get("database")
    rows_affected = db_service.api_key_manager.save_api_key(
        cmd.service_name, 
        cmd.api_key, 
        cmd.is_active
    )
    return {"rows_affected": rows_affected}


@DatabaseCommandBus.register(GetConfig)
async def handle_get_config(cmd: GetConfig):
    """Get a configuration value"""
    db_service = ServiceLocator.get("database")
    return db_service.config_manager.get_config(cmd.key)


@DatabaseCommandBus.register(SaveConfig)
async def handle_save_config(cmd: SaveConfig):
    """Save a configuration value"""
    db_service = ServiceLocator.get("database")
    rows_affected = db_service.config_manager.save_config(cmd.key, cmd.value)
    return {"rows_affected": rows_affected}


@DatabaseCommandBus.register(GetAllConfigs)
async def handle_get_all_configs(cmd: GetAllConfigs):
    """Get all configuration values"""
    db_service = ServiceLocator.get("database")
    return db_service.config_manager.get_all_configs()


@DatabaseCommandBus.register(GetModelConfigs)
async def handle_get_model_configs(cmd: GetModelConfigs):
    """Get model configurations"""
    db_service = ServiceLocator.get("database")
    return db_service.config_manager.get_model_configs()


@DatabaseCommandBus.register(SaveGeminiLog)
async def handle_save_gemini_log(cmd: SaveGeminiLog):
    """Save a Gemini API log entry"""
    db_service = ServiceLocator.get("database")
    log_id = db_service.gemini_log_manager.save_log(
        cmd.model_name,
        cmd.prompt_tokens,
        cmd.response_tokens,
        cmd.total_tokens,
        cmd.prompt_cost,
        cmd.response_cost,
        cmd.total_cost,
        cmd.response_text,
        cmd.response_summary
    )
    return {"log_id": log_id}


@DatabaseCommandBus.register(GetGeminiLogs)
async def handle_get_gemini_logs(cmd: GetGeminiLogs):
    """Get Gemini API logs"""
    db_service = ServiceLocator.get("database")
    return db_service.gemini_log_manager.get_logs(cmd.limit, cmd.offset)


@DatabaseCommandBus.register(GetIgnoredPatterns)
async def handle_get_ignored_patterns(cmd: GetIgnoredPatterns):
    """Get ignored file patterns"""
    db_service = ServiceLocator.get("database")
    return db_service.get_ignored_patterns()


@DatabaseCommandBus.register(SaveIgnoredPatterns)
async def handle_save_ignored_patterns(cmd: SaveIgnoredPatterns):
    """Save ignored file patterns"""
    db_service = ServiceLocator.get("database")
    db_service.save_ignored_patterns(cmd.patterns)
    return {"status": "saved", "count": len(cmd.patterns)}



======== src\features\file_management\atoms\__init__.py ========



======== src\features\file_management\atoms\file_scanner.py ========
"""File scanner atom - scans directories for files"""
import os
import logging
from pathlib import Path
from typing import List, Set, Optional, Dict, Any

logger = logging.getLogger(__name__)


class FileScanner:
    """Scans directories and returns file information"""
    
    def __init__(self):
        self.excluded_dirs = {
            '.git', '__pycache__', 'node_modules', 
            '.venv', 'venv', '.env', 'env',
            '.idea', '.vscode', 'dist', 'build',
            '*.egg-info', '.pytest_cache', '.mypy_cache'
        }
    
    def scan_directory(
        self, 
        directory: Path, 
        recursive: bool = True,
        include_hidden: bool = False,
        exclude_patterns: Optional[Set[str]] = None
    ) -> List[Path]:
        """Scan directory for files"""
        if not directory.exists() or not directory.is_dir():
            logger.warning(f"Directory does not exist or is not a directory: {directory}")
            return []
        
        files = []
        exclude_patterns = exclude_patterns or set()
        
        try:
            if recursive:
                for root, dirs, filenames in os.walk(directory):
                    root_path = Path(root)
                    
                    # Filter out excluded directories
                    dirs[:] = [
                        d for d in dirs 
                        if d not in self.excluded_dirs
                        and (include_hidden or not d.startswith('.'))
                    ]
                    
                    # Add files
                    for filename in filenames:
                        if not include_hidden and filename.startswith('.'):
                            continue
                        
                        file_path = root_path / filename
                        if not self._should_exclude(file_path, exclude_patterns):
                            files.append(file_path)
            else:
                # Non-recursive scan
                for item in directory.iterdir():
                    if item.is_file():
                        if not include_hidden and item.name.startswith('.'):
                            continue
                        if not self._should_exclude(item, exclude_patterns):
                            files.append(item)
        
        except PermissionError as e:
            logger.error(f"Permission denied accessing directory: {e}")
        except Exception as e:
            logger.error(f"Error scanning directory {directory}: {e}")
        
        return sorted(files)
    
    def _should_exclude(self, file_path: Path, patterns: Set[str]) -> bool:
        """Check if file should be excluded based on patterns"""
        path_str = str(file_path)
        for pattern in patterns:
            if pattern in path_str:
                return True
        return False
    
    def get_file_info(self, file_path: Path) -> Dict[str, Any]:
        """Get detailed information about a file"""
        try:
            stat = file_path.stat()
            return {
                'path': str(file_path),
                'name': file_path.name,
                'size': stat.st_size,
                'modified': stat.st_mtime,
                'is_binary': self._is_binary(file_path),
                'extension': file_path.suffix
            }
        except Exception as e:
            logger.error(f"Error getting file info for {file_path}: {e}")
            return {
                'path': str(file_path),
                'name': file_path.name,
                'error': str(e)
            }
    
    def _is_binary(self, file_path: Path) -> bool:
        """Check if file is binary"""
        try:
            with open(file_path, 'rb') as f:
                chunk = f.read(1024)
                return b'\x00' in chunk
        except:
            return True


======== src\features\file_management\atoms\file_watcher.py ========
"""File watcher atom - monitors file system changes"""
import logging
from pathlib import Path
from typing import Optional, Callable, Set
from watchdog.observers import Observer
from watchdog.events import FileSystemEventHandler, FileSystemEvent

logger = logging.getLogger(__name__)


class FileWatcherHandler(FileSystemEventHandler):
    """Handles file system events"""
    
    def __init__(self, callback: Callable[[FileSystemEvent], None], ignore_patterns: Optional[Set[str]] = None):
        self.callback = callback
        self.ignore_patterns = ignore_patterns or {'.git', '__pycache__', '.pyc'}
    
    def _should_ignore(self, event: FileSystemEvent) -> bool:
        """Check if event should be ignored"""
        path_str = str(event.src_path)
        for pattern in self.ignore_patterns:
            if pattern in path_str:
                return True
        return False
    
    def on_any_event(self, event: FileSystemEvent):
        """Handle any file system event"""
        if not self._should_ignore(event):
            try:
                self.callback(event)
            except Exception as e:
                logger.error(f"Error in file watcher callback: {e}")


class FileWatcher:
    """Watches for file system changes"""
    
    def __init__(self):
        self.observer: Optional[Observer] = None
        self.watch_path: Optional[Path] = None
        self.handler: Optional[FileWatcherHandler] = None
    
    def start(self, path: Path, callback: Callable[[FileSystemEvent], None], ignore_patterns: Optional[Set[str]] = None):
        """Start watching a directory"""
        if self.observer and self.observer.is_alive():
            self.stop()
        
        self.watch_path = path
        self.handler = FileWatcherHandler(callback, ignore_patterns)
        self.observer = Observer()
        
        try:
            self.observer.schedule(self.handler, str(path), recursive=True)
            self.observer.start()
            logger.info(f"Started file watcher for: {path}")
        except Exception as e:
            logger.error(f"Failed to start file watcher: {e}")
            self.observer = None
            raise
    
    def stop(self):
        """Stop watching"""
        if self.observer and self.observer.is_alive():
            self.observer.stop()
            self.observer.join(timeout=2)
            logger.info(f"Stopped file watcher for: {self.watch_path}")
        
        self.observer = None
        self.watch_path = None
        self.handler = None
    
    def is_watching(self) -> bool:
        """Check if watcher is active"""
        return bool(self.observer and self.observer.is_alive())


======== src\features\file_management\molecules\__init__.py ========



======== src\features\file_management\molecules\file_tree_builder.py ========
"""File tree builder molecule - builds hierarchical file structures"""
import logging
from pathlib import Path
from typing import Dict, List, Any, Optional, Set

logger = logging.getLogger(__name__)


class FileTreeNode:
    """Represents a node in the file tree"""
    
    def __init__(self, path: Path, is_dir: bool = False):
        self.path = path
        self.name = path.name
        self.is_dir = is_dir
        self.children: List[FileTreeNode] = []
        self.checked = False
        self.parent: Optional[FileTreeNode] = None
    
    def add_child(self, child: 'FileTreeNode'):
        """Add a child node"""
        child.parent = self
        self.children.append(child)
    
    def to_dict(self) -> Dict[str, Any]:
        """Convert to dictionary representation"""
        return {
            'path': str(self.path),
            'name': self.name,
            'is_dir': self.is_dir,
            'checked': self.checked,
            'children': [child.to_dict() for child in self.children]
        }


class FileTreeBuilder:
    """Builds hierarchical file tree structures"""
    
    def __init__(self):
        self.root_node: Optional[FileTreeNode] = None
        self.path_to_node: Dict[str, FileTreeNode] = {}
        self.checked_paths: Set[str] = set()
    
    def build_tree(self, root_path: Path, file_paths: List[Path]) -> FileTreeNode:
        """Build a file tree from a list of file paths"""
        self.root_node = FileTreeNode(root_path, is_dir=True)
        self.path_to_node = {str(root_path): self.root_node}
        
        # Sort paths to ensure parents come before children
        sorted_paths = sorted(file_paths)
        
        for file_path in sorted_paths:
            self._add_path_to_tree(file_path, root_path)
        
        # Apply checked states
        self._apply_checked_states()
        
        return self.root_node
    
    def _add_path_to_tree(self, file_path: Path, root_path: Path):
        """Add a file path to the tree"""
        try:
            relative_path = file_path.relative_to(root_path)
        except ValueError:
            logger.warning(f"Path {file_path} is not relative to root {root_path}")
            return
        
        # Build the path components
        parts = relative_path.parts
        current_path = root_path
        current_node = self.root_node
        
        # Process each part of the path
        for i, part in enumerate(parts):
            current_path = current_path / part
            path_str = str(current_path)
            
            if path_str not in self.path_to_node:
                # Create new node
                is_dir = i < len(parts) - 1 or current_path.is_dir()
                new_node = FileTreeNode(current_path, is_dir=is_dir)
                current_node.add_child(new_node)
                self.path_to_node[path_str] = new_node
                current_node = new_node
            else:
                current_node = self.path_to_node[path_str]
    
    def check_file(self, file_path: str, checked: bool):
        """Check or uncheck a file"""
        if checked:
            self.checked_paths.add(file_path)
        else:
            self.checked_paths.discard(file_path)
        
        # Update node if tree is built
        if file_path in self.path_to_node:
            self.path_to_node[file_path].checked = checked
    
    def check_all(self, checked: bool):
        """Check or uncheck all files"""
        if checked:
            # Add all file paths to checked set
            for path_str, node in self.path_to_node.items():
                if not node.is_dir:
                    self.checked_paths.add(path_str)
                    node.checked = True
        else:
            # Clear all checked paths
            self.checked_paths.clear()
            for node in self.path_to_node.values():
                node.checked = False
    
    def get_checked_files(self) -> List[str]:
        """Get list of checked file paths"""
        return sorted(list(self.checked_paths))
    
    def _apply_checked_states(self):
        """Apply checked states to nodes"""
        for path_str in self.checked_paths:
            if path_str in self.path_to_node:
                self.path_to_node[path_str].checked = True
    
    def generate_tree_text(self, node: Optional[FileTreeNode] = None, prefix: str = "", is_last: bool = True) -> str:
        """Generate text representation of the tree"""
        if node is None:
            node = self.root_node
            if node is None:
                return ""
        
        # Build the current line
        connector = "└── " if is_last else "├── "
        line = prefix + connector + node.name
        
        if node.is_dir:
            line += "/"
        if node.checked:
            line += " ✓"
        
        lines = [line]
        
        # Process children
        if node.children:
            extension = "    " if is_last else "│   "
            for i, child in enumerate(node.children):
                is_last_child = i == len(node.children) - 1
                child_lines = self.generate_tree_text(
                    child, 
                    prefix + extension, 
                    is_last_child
                )
                lines.append(child_lines)
        
        return "\n".join(lines)


======== src\features\file_management\molecules\gitignore_filter.py ========
"""Gitignore filter molecule - filters files based on gitignore patterns"""
import logging
import fnmatch
from pathlib import Path
from typing import List, Set, Optional

logger = logging.getLogger(__name__)


class GitignoreFilter:
    """Filters files based on gitignore patterns"""
    
    def __init__(self):
        self.patterns: Set[str] = set()
        self.compiled_patterns: List[str] = []
    
    def load_patterns(self, patterns: List[str]):
        """Load gitignore patterns"""
        self.patterns = set()
        self.compiled_patterns = []
        
        for pattern in patterns:
            pattern = pattern.strip()
            if pattern and not pattern.startswith('#'):
                self.patterns.add(pattern)
                # Convert gitignore pattern to fnmatch pattern
                if pattern.endswith('/'):
                    # Directory pattern
                    self.compiled_patterns.append(pattern.rstrip('/'))
                else:
                    self.compiled_patterns.append(pattern)
        
        logger.info(f"Loaded {len(self.compiled_patterns)} gitignore patterns")
    
    def should_ignore(self, file_path: Path, root_path: Optional[Path] = None) -> bool:
        """Check if a file should be ignored"""
        if root_path:
            try:
                relative_path = file_path.relative_to(root_path)
                path_str = str(relative_path).replace('\\', '/')
            except ValueError:
                path_str = str(file_path).replace('\\', '/')
        else:
            path_str = str(file_path).replace('\\', '/')
        
        # Check each pattern
        for pattern in self.compiled_patterns:
            if self._match_pattern(path_str, pattern):
                return True
        
        return False
    
    def filter_files(self, file_paths: List[Path], root_path: Optional[Path] = None) -> List[Path]:
        """Filter a list of files based on gitignore patterns"""
        filtered = []
        
        for file_path in file_paths:
            if not self.should_ignore(file_path, root_path):
                filtered.append(file_path)
        
        logger.debug(f"Filtered {len(file_paths)} files to {len(filtered)} files")
        return filtered
    
    def _match_pattern(self, path: str, pattern: str) -> bool:
        """Match a path against a gitignore pattern"""
        # Handle negation patterns (starting with !)
        if pattern.startswith('!'):
            return False
        
        # Handle directory patterns
        if '/' in pattern:
            # Pattern with directory separator
            if pattern.startswith('/'):
                # Absolute pattern (from root)
                pattern = pattern[1:]
                return fnmatch.fnmatch(path, pattern)
            else:
                # Relative pattern - can match anywhere
                parts = path.split('/')
                pattern_parts = pattern.split('/')
                
                for i in range(len(parts) - len(pattern_parts) + 1):
                    if all(fnmatch.fnmatch(parts[i + j], pattern_parts[j]) 
                           for j in range(len(pattern_parts))):
                        return True
                return False
        else:
            # Simple pattern - match basename
            basename = path.split('/')[-1]
            return fnmatch.fnmatch(basename, pattern)
    
    def add_pattern(self, pattern: str):
        """Add a single pattern"""
        pattern = pattern.strip()
        if pattern and not pattern.startswith('#'):
            self.patterns.add(pattern)
            if pattern.endswith('/'):
                self.compiled_patterns.append(pattern.rstrip('/'))
            else:
                self.compiled_patterns.append(pattern)
    
    def remove_pattern(self, pattern: str):
        """Remove a pattern"""
        pattern = pattern.strip()
        self.patterns.discard(pattern)
        # Rebuild compiled patterns
        self.load_patterns(list(self.patterns))
    
    def get_patterns(self) -> List[str]:
        """Get current patterns"""
        return sorted(list(self.patterns))


======== src\features\file_management\organisms\__init__.py ========



======== src\features\file_management\organisms\file_system_service.py ========
"""File system service organism - manages all file operations"""
import logging
from pathlib import Path
from typing import Optional, List, Dict, Any, Set
from watchdog.events import FileSystemEvent

from src.gateway import EventBus, Event, ServiceLocator
from ..atoms.file_scanner import FileScanner
from ..atoms.file_watcher import FileWatcher
from ..molecules.file_tree_builder import FileTreeBuilder, FileTreeNode
from ..molecules.gitignore_filter import GitignoreFilter

logger = logging.getLogger(__name__)


# File system events
class FileSystemChangedEvent(Event):
    """Event emitted when file system changes"""
    def __init__(self, event_type: str, path: str):
        self.event_type = event_type
        self.path = path


class ProjectFolderChangedEvent(Event):
    """Event emitted when project folder changes"""
    def __init__(self, old_path: Optional[str], new_path: str):
        self.old_path = old_path
        self.new_path = new_path


class FileSystemService:
    """High-level file system service"""
    
    def __init__(self):
        self.scanner = FileScanner()
        self.watcher = FileWatcher()
        self.tree_builder = FileTreeBuilder()
        self.gitignore_filter = GitignoreFilter()
        
        self.project_folder: Optional[Path] = None
        self.file_cache: List[Path] = []
        self.tree_cache: Optional[FileTreeNode] = None
        
        # Load gitignore patterns from config
        self._load_gitignore_patterns()
    
    def _load_gitignore_patterns(self):
        """Load gitignore patterns from configuration"""
        try:
            config_service = ServiceLocator.get("config")
            if config_service and config_service.gitignore_manager:
                patterns = config_service.gitignore_manager.get_all_patterns()
                self.gitignore_filter.load_patterns(patterns)
                logger.info(f"Loaded {len(patterns)} gitignore patterns")
        except Exception as e:
            logger.warning(f"Could not load gitignore patterns: {e}")
    
    def set_project_folder(self, folder_path: str) -> bool:
        """Set the project folder"""
        new_path = Path(folder_path)
        
        if not new_path.exists() or not new_path.is_dir():
            logger.error(f"Invalid project folder: {folder_path}")
            return False
        
        old_path = str(self.project_folder) if self.project_folder else None
        self.project_folder = new_path
        
        # Stop existing watcher
        if self.watcher.is_watching():
            self.watcher.stop()
        
        # Clear cache
        self.file_cache.clear()
        self.tree_cache = None
        
        # Emit event
        EventBus.emit(ProjectFolderChangedEvent(old_path=old_path, new_path=str(new_path)))
        
        # Start watching the new folder
        self._start_watching()
        
        # Scan the new folder
        self.refresh_file_system()
        
        logger.info(f"Project folder set to: {new_path}")
        return True
    
    def get_project_folder(self) -> Optional[str]:
        """Get current project folder"""
        return str(self.project_folder) if self.project_folder else None
    
    def refresh_file_system(self):
        """Refresh file system cache"""
        if not self.project_folder:
            logger.warning("No project folder set")
            return
        
        # Scan directory
        self.file_cache = self.scanner.scan_directory(
            self.project_folder,
            recursive=True,
            include_hidden=False
        )
        
        # Apply gitignore filter
        self.file_cache = self.gitignore_filter.filter_files(
            self.file_cache,
            self.project_folder
        )
        
        # Rebuild tree
        self.tree_cache = self.tree_builder.build_tree(
            self.project_folder,
            self.file_cache
        )
        
        logger.info(f"File system refreshed: {len(self.file_cache)} files found")
    
    def get_file_tree(self) -> Optional[Dict[str, Any]]:
        """Get file tree structure"""
        if not self.tree_cache:
            self.refresh_file_system()
        
        if self.tree_cache:
            return self.tree_cache.to_dict()
        return None
    
    def check_file(self, file_path: str, checked: bool):
        """Check or uncheck a file"""
        self.tree_builder.check_file(file_path, checked)
        
        # Update tree cache if it exists
        if self.tree_cache:
            node = self.tree_builder.path_to_node.get(file_path)
            if node:
                node.checked = checked
    
    def check_all_files(self, checked: bool):
        """Check or uncheck all files"""
        self.tree_builder.check_all(checked)
        
        # Update tree cache if it exists
        if self.tree_cache:
            for node in self.tree_builder.path_to_node.values():
                if not node.is_dir:
                    node.checked = checked
    
    def get_checked_files(self) -> List[str]:
        """Get list of checked files"""
        return self.tree_builder.get_checked_files()
    
    def get_file_content(self, file_path: str) -> Optional[str]:
        """Read file content"""
        path = Path(file_path)
        
        if not path.exists() or not path.is_file():
            logger.error(f"File not found: {file_path}")
            return None
        
        try:
            with open(path, 'r', encoding='utf-8') as f:
                return f.read()
        except Exception as e:
            logger.error(f"Error reading file {file_path}: {e}")
            return None
    
    def generate_directory_tree(self, include_files: bool = True, max_depth: Optional[int] = None) -> str:
        """Generate directory tree text"""
        if not self.tree_cache:
            self.refresh_file_system()
        
        if self.tree_cache:
            return self.tree_builder.generate_tree_text(self.tree_cache)
        return ""
    
    def _start_watching(self):
        """Start watching the project folder"""
        if not self.project_folder:
            return
        
        def on_change(event: FileSystemEvent):
            """Handle file system change"""
            logger.debug(f"File system event: {event.event_type} - {event.src_path}")
            
            # Emit event
            EventBus.emit(FileSystemChangedEvent(
                event_type=event.event_type,
                path=event.src_path
            ))
            
            # Schedule refresh (debounced in real implementation)
            self.refresh_file_system()
        
        try:
            self.watcher.start(
                self.project_folder,
                on_change,
                ignore_patterns={'.git', '__pycache__', '*.pyc'}
            )
        except Exception as e:
            logger.error(f"Failed to start file watcher: {e}")
    
    def stop_watching(self):
        """Stop file system watcher"""
        self.watcher.stop()
    
    def apply_gitignore_filter(self, file_paths: List[str]) -> List[str]:
        """Apply gitignore filtering to file paths"""
        paths = [Path(p) for p in file_paths]
        filtered = self.gitignore_filter.filter_files(paths, self.project_folder)
        return [str(p) for p in filtered]



======== src\features\file_management\__init__.py ========



======== src\features\file_management\commands.py ========
"""File management feature commands"""
from typing import Optional, List, Dict, Any, Set
from pathlib import Path
from src.gateway.bus._base import Command


class SetProjectFolder(Command):
    """Command to set the project folder"""
    folder_path: str


class GetProjectFolder(Command):
    """Command to get current project folder"""
    pass


class ScanDirectory(Command):
    """Command to scan a directory for files"""
    directory_path: str
    recursive: bool = True
    include_hidden: bool = False


class GetFileTree(Command):
    """Command to get the file tree structure"""
    root_path: Optional[str] = None
    include_hidden: bool = False


class CheckFile(Command):
    """Command to check/select a file"""
    file_path: str
    checked: bool


class CheckAllFiles(Command):
    """Command to check all files"""
    checked: bool


class GetCheckedFiles(Command):
    """Command to get all checked files"""
    pass


class GetFileContent(Command):
    """Command to read file content"""
    file_path: str


class RefreshFileSystem(Command):
    """Command to refresh file system cache"""
    pass


class ApplyGitignoreFilter(Command):
    """Command to apply gitignore filtering"""
    file_paths: List[str]


class StartFileWatcher(Command):
    """Command to start file system watcher"""
    watch_path: str


class StopFileWatcher(Command):
    """Command to stop file system watcher"""
    pass


class GetDirectoryTree(Command):
    """Command to generate directory tree text"""
    root_path: str
    include_files: bool = True
    max_depth: Optional[int] = None


class GetFilteredFiles(Command):
    """Command to get files with filtering applied"""
    root_path: str
    patterns: Optional[List[str]] = None
    exclude_patterns: Optional[List[str]] = None


======== src\features\file_management\handlers.py ========
"""File management feature command handlers"""
import logging
from src.gateway.bus.file_management_command_bus import FileManagementCommandBus
from src.gateway import EventBus, ServiceLocator
from .commands import (
    SetProjectFolder, GetProjectFolder, ScanDirectory, GetFileTree,
    CheckFile, CheckAllFiles, GetCheckedFiles, GetFileContent,
    RefreshFileSystem, ApplyGitignoreFilter, StartFileWatcher,
    StopFileWatcher, GetDirectoryTree, GetFilteredFiles
)
from .organisms.file_system_service import FileSystemService

logger = logging.getLogger(__name__)


# Initialize file system service and register with ServiceLocator
file_system_service = FileSystemService()
ServiceLocator.provide("file_system", file_system_service)


@FileManagementCommandBus.register(SetProjectFolder)
async def handle_set_project_folder(cmd: SetProjectFolder):
    """Set the project folder"""
    service = ServiceLocator.get("file_system")
    success = service.set_project_folder(cmd.folder_path)
    return {"success": success, "path": cmd.folder_path}


@FileManagementCommandBus.register(GetProjectFolder)
async def handle_get_project_folder(cmd: GetProjectFolder):
    """Get current project folder"""
    service = ServiceLocator.get("file_system")
    path = service.get_project_folder()
    return {"path": path}


@FileManagementCommandBus.register(ScanDirectory)
async def handle_scan_directory(cmd: ScanDirectory):
    """Scan a directory for files"""
    service = ServiceLocator.get("file_system")
    from pathlib import Path
    
    files = service.scanner.scan_directory(
        Path(cmd.directory_path),
        recursive=cmd.recursive,
        include_hidden=cmd.include_hidden
    )
    
    # Apply gitignore filter
    filtered_files = service.gitignore_filter.filter_files(files)
    
    return {
        "directory": cmd.directory_path,
        "files": [str(f) for f in filtered_files],
        "count": len(filtered_files)
    }


@FileManagementCommandBus.register(GetFileTree)
async def handle_get_file_tree(cmd: GetFileTree):
    """Get the file tree structure"""
    service = ServiceLocator.get("file_system")
    
    if cmd.root_path:
        # Set project folder if provided
        service.set_project_folder(cmd.root_path)
    
    tree = service.get_file_tree()
    return {"tree": tree}


@FileManagementCommandBus.register(CheckFile)
async def handle_check_file(cmd: CheckFile):
    """Check or uncheck a file"""
    service = ServiceLocator.get("file_system")
    service.check_file(cmd.file_path, cmd.checked)
    return {"file": cmd.file_path, "checked": cmd.checked}


@FileManagementCommandBus.register(CheckAllFiles)
async def handle_check_all_files(cmd: CheckAllFiles):
    """Check or uncheck all files"""
    service = ServiceLocator.get("file_system")
    service.check_all_files(cmd.checked)
    
    checked_count = len(service.get_checked_files())
    return {"checked": cmd.checked, "count": checked_count}


@FileManagementCommandBus.register(GetCheckedFiles)
async def handle_get_checked_files(cmd: GetCheckedFiles):
    """Get all checked files"""
    service = ServiceLocator.get("file_system")
    files = service.get_checked_files()
    return {"files": files, "count": len(files)}


@FileManagementCommandBus.register(GetFileContent)
async def handle_get_file_content(cmd: GetFileContent):
    """Read file content"""
    service = ServiceLocator.get("file_system")
    content = service.get_file_content(cmd.file_path)
    
    return {
        "file": cmd.file_path,
        "content": content,
        "exists": content is not None
    }


@FileManagementCommandBus.register(RefreshFileSystem)
async def handle_refresh_file_system(cmd: RefreshFileSystem):
    """Refresh file system cache"""
    service = ServiceLocator.get("file_system")
    service.refresh_file_system()
    
    return {
        "status": "refreshed",
        "file_count": len(service.file_cache)
    }


@FileManagementCommandBus.register(ApplyGitignoreFilter)
async def handle_apply_gitignore_filter(cmd: ApplyGitignoreFilter):
    """Apply gitignore filtering to files"""
    service = ServiceLocator.get("file_system")
    filtered = service.apply_gitignore_filter(cmd.file_paths)
    
    return {
        "original_count": len(cmd.file_paths),
        "filtered_count": len(filtered),
        "filtered_files": filtered
    }


@FileManagementCommandBus.register(StartFileWatcher)
async def handle_start_file_watcher(cmd: StartFileWatcher):
    """Start file system watcher"""
    service = ServiceLocator.get("file_system")
    
    # Set project folder and start watching
    success = service.set_project_folder(cmd.watch_path)
    
    return {
        "started": success and service.watcher.is_watching(),
        "path": cmd.watch_path
    }


@FileManagementCommandBus.register(StopFileWatcher)
async def handle_stop_file_watcher(cmd: StopFileWatcher):
    """Stop file system watcher"""
    service = ServiceLocator.get("file_system")
    service.stop_watching()
    
    return {"stopped": True}


@FileManagementCommandBus.register(GetDirectoryTree)
async def handle_get_directory_tree(cmd: GetDirectoryTree):
    """Generate directory tree text"""
    service = ServiceLocator.get("file_system")
    
    # Set project folder if needed
    if str(service.project_folder) != cmd.root_path:
        service.set_project_folder(cmd.root_path)
    
    tree_text = service.generate_directory_tree(
        include_files=cmd.include_files,
        max_depth=cmd.max_depth
    )
    
    return {"tree": tree_text}


@FileManagementCommandBus.register(GetFilteredFiles)
async def handle_get_filtered_files(cmd: GetFilteredFiles):
    """Get files with filtering applied"""
    service = ServiceLocator.get("file_system")
    from pathlib import Path
    
    # Scan directory
    files = service.scanner.scan_directory(
        Path(cmd.root_path),
        recursive=True,
        exclude_patterns=set(cmd.exclude_patterns or [])
    )
    
    # Apply patterns if provided
    if cmd.patterns:
        import fnmatch
        filtered = []
        for file_path in files:
            for pattern in cmd.patterns:
                if fnmatch.fnmatch(str(file_path), pattern):
                    filtered.append(file_path)
                    break
        files = filtered
    
    return {
        "root": cmd.root_path,
        "files": [str(f) for f in files],
        "count": len(files)
    }



======== src\features\gemini\atoms\__init__.py ========



======== src\features\gemini\molecules\__init__.py ========



======== src\features\gemini\organisms\__init__.py ========



======== src\features\gemini\__init__.py ========



======== src\features\gemini\commands.py ========



======== src\features\gemini\handlers.py ========



======== src\features\prompt_builder\atoms\__init__.py ========



======== src\features\prompt_builder\atoms\prompt_formatter.py ========
"""Prompt formatter atom - formats prompt components"""
import logging
from typing import List, Dict, Any, Optional

logger = logging.getLogger(__name__)


class PromptFormatter:
    """Formats prompt components into final prompt"""
    
    def __init__(self):
        self.file_separator = "\n\n" + "="*60 + "\n\n"
        self.section_separator = "\n\n"
    
    def format_file_content(self, file_path: str, content: str) -> str:
        """Format a single file's content for inclusion in prompt"""
        header = f"File: {file_path}"
        separator = "-" * len(header)
        
        return f"{header}\n{separator}\n{content}"
    
    def format_attachment(self, attachment_info: Dict[str, Any]) -> str:
        """Format an attachment for inclusion in prompt"""
        name = attachment_info.get('name', 'Unnamed')
        file_type = attachment_info.get('type', 'Unknown')
        size = attachment_info.get('size', 0)
        
        header = f"Attachment: {name} (Type: {file_type}, Size: {size} bytes)"
        
        # For image attachments, just include metadata
        if file_type.startswith('image/'):
            return f"{header}\n[Image content will be sent as multimodal input]"
        
        # For text attachments, include content if available
        content = attachment_info.get('content', '')
        if content:
            return f"{header}\n{content}"
        
        return header
    
    def build_enhanced_prompt(
        self,
        system_prompt: Optional[str] = None,
        user_prompt: Optional[str] = None,
        file_contents: Optional[List[Dict[str, str]]] = None,
        attachments: Optional[List[Dict[str, Any]]] = None
    ) -> str:
        """Build an enhanced prompt with all components"""
        sections = []
        
        # Add system prompt
        if system_prompt:
            sections.append(f"=== SYSTEM PROMPT ===\n{system_prompt}")
        
        # Add file contents
        if file_contents:
            file_section = "=== FILE CONTENTS ===\n"
            formatted_files = []
            
            for file_info in file_contents:
                file_path = file_info.get('path', 'Unknown')
                content = file_info.get('content', '')
                formatted_files.append(self.format_file_content(file_path, content))
            
            file_section += self.file_separator.join(formatted_files)
            sections.append(file_section)
        
        # Add attachments
        if attachments:
            attachment_section = "=== ATTACHMENTS ===\n"
            formatted_attachments = []
            
            for attachment in attachments:
                formatted_attachments.append(self.format_attachment(attachment))
            
            attachment_section += self.section_separator.join(formatted_attachments)
            sections.append(attachment_section)
        
        # Add user prompt
        if user_prompt:
            sections.append(f"=== USER PROMPT ===\n{user_prompt}")
        
        # Join all sections
        final_prompt = self.section_separator.join(sections)
        
        logger.debug(f"Built enhanced prompt with {len(sections)} sections")
        return final_prompt
    
    def build_metaprompt(
        self,
        template: str,
        content: str,
        variables: Optional[Dict[str, str]] = None
    ) -> str:
        """Build a metaprompt using a template"""
        # Replace variables in template
        if variables:
            for key, value in variables.items():
                placeholder = f"{{{{{key}}}}}"
                template = template.replace(placeholder, value)
        
        # Replace main content placeholder
        template = template.replace("{{CONTENT}}", content)
        
        logger.debug("Built metaprompt from template")
        return template
    
    def truncate_prompt(self, prompt: str, max_length: int) -> str:
        """Truncate prompt to maximum length"""
        if len(prompt) <= max_length:
            return prompt
        
        # Truncate and add ellipsis
        truncated = prompt[:max_length - 3] + "..."
        logger.warning(f"Prompt truncated from {len(prompt)} to {max_length} characters")
        
        return truncated
    
    def estimate_token_count(self, text: str) -> int:
        """Rough estimation of token count"""
        # Simple estimation: ~4 characters per token
        return len(text) // 4


======== src\features\prompt_builder\molecules\__init__.py ========



======== src\features\prompt_builder\molecules\prompt_validator.py ========
"""Prompt validator molecule - validates prompt components"""
import logging
from typing import Dict, List, Tuple, Optional

logger = logging.getLogger(__name__)


class PromptValidator:
    """Validates prompt components and final prompts"""
    
    def __init__(self):
        self.max_prompt_length = 1_000_000  # 1M characters
        self.max_file_size = 100_000  # 100K per file
        self.max_attachment_size = 10_000_000  # 10MB
        self.supported_image_types = {'image/jpeg', 'image/png', 'image/gif', 'image/webp'}
    
    def validate_system_prompt(self, prompt: str) -> Tuple[bool, Optional[str]]:
        """Validate system prompt"""
        if not prompt:
            return True, None  # Empty is allowed
        
        if len(prompt) > self.max_prompt_length:
            return False, f"System prompt too long: {len(prompt)} characters (max: {self.max_prompt_length})"
        
        # Check for common issues
        if prompt.count('{{') != prompt.count('}}'):
            return False, "Unmatched template variables in system prompt"
        
        return True, None
    
    def validate_user_prompt(self, prompt: str) -> Tuple[bool, Optional[str]]:
        """Validate user prompt"""
        if not prompt:
            return False, "User prompt cannot be empty"
        
        if len(prompt) > self.max_prompt_length:
            return False, f"User prompt too long: {len(prompt)} characters (max: {self.max_prompt_length})"
        
        return True, None
    
    def validate_file_content(self, file_info: Dict[str, str]) -> Tuple[bool, Optional[str]]:
        """Validate file content for inclusion"""
        file_path = file_info.get('path', 'Unknown')
        content = file_info.get('content', '')
        
        if not content:
            return False, f"File {file_path} has no content"
        
        if len(content) > self.max_file_size:
            return False, f"File {file_path} too large: {len(content)} characters (max: {self.max_file_size})"
        
        # Check if file appears to be binary
        if '\x00' in content:
            return False, f"File {file_path} appears to be binary"
        
        return True, None
    
    def validate_attachment(self, attachment: Dict[str, any]) -> Tuple[bool, Optional[str]]:
        """Validate attachment"""
        name = attachment.get('name', 'Unknown')
        file_type = attachment.get('type', 'Unknown')
        size = attachment.get('size', 0)
        
        if size > self.max_attachment_size:
            return False, f"Attachment {name} too large: {size} bytes (max: {self.max_attachment_size})"
        
        # Validate image attachments
        if file_type.startswith('image/'):
            if file_type not in self.supported_image_types:
                return False, f"Unsupported image type: {file_type}"
        
        return True, None
    
    def validate_complete_prompt(
        self,
        system_prompt: Optional[str] = None,
        user_prompt: Optional[str] = None,
        file_contents: Optional[List[Dict[str, str]]] = None,
        attachments: Optional[List[Dict[str, any]]] = None
    ) -> Tuple[bool, List[str]]:
        """Validate complete prompt with all components"""
        errors = []
        total_size = 0
        
        # Validate system prompt
        if system_prompt:
            valid, error = self.validate_system_prompt(system_prompt)
            if not valid:
                errors.append(error)
            total_size += len(system_prompt)
        
        # Validate user prompt
        if user_prompt:
            valid, error = self.validate_user_prompt(user_prompt)
            if not valid:
                errors.append(error)
            total_size += len(user_prompt)
        
        # Validate file contents
        if file_contents:
            for file_info in file_contents:
                valid, error = self.validate_file_content(file_info)
                if not valid:
                    errors.append(error)
                else:
                    total_size += len(file_info.get('content', ''))
        
        # Validate attachments
        if attachments:
            for attachment in attachments:
                valid, error = self.validate_attachment(attachment)
                if not valid:
                    errors.append(error)
        
        # Check total size
        if total_size > self.max_prompt_length:
            errors.append(f"Total prompt size too large: {total_size} characters (max: {self.max_prompt_length})")
        
        return len(errors) == 0, errors
    
    def get_prompt_stats(
        self,
        system_prompt: Optional[str] = None,
        user_prompt: Optional[str] = None,
        file_contents: Optional[List[Dict[str, str]]] = None,
        attachments: Optional[List[Dict[str, any]]] = None
    ) -> Dict[str, any]:
        """Get statistics about the prompt"""
        stats = {
            'system_prompt_length': len(system_prompt) if system_prompt else 0,
            'user_prompt_length': len(user_prompt) if user_prompt else 0,
            'file_count': len(file_contents) if file_contents else 0,
            'attachment_count': len(attachments) if attachments else 0,
            'total_file_size': 0,
            'total_attachment_size': 0,
            'estimated_tokens': 0
        }
        
        if file_contents:
            stats['total_file_size'] = sum(len(f.get('content', '')) for f in file_contents)
        
        if attachments:
            stats['total_attachment_size'] = sum(a.get('size', 0) for a in attachments)
        
        # Estimate tokens (rough: 4 chars = 1 token)
        total_chars = (
            stats['system_prompt_length'] + 
            stats['user_prompt_length'] + 
            stats['total_file_size']
        )
        stats['estimated_tokens'] = total_chars // 4
        
        return stats


======== src\features\prompt_builder\organisms\__init__.py ========



======== src\features\prompt_builder\organisms\prompt_service.py ========
"""Prompt service organism - manages prompt building operations"""
import logging
from typing import Optional, List, Dict, Any, Tuple
from src.gateway import ServiceLocator, EventBus, Event
from ..atoms.prompt_formatter import PromptFormatter
from ..molecules.prompt_validator import PromptValidator

logger = logging.getLogger(__name__)


# Prompt events
class PromptBuiltEvent(Event):
    """Event emitted when prompt is built"""
    def __init__(self, mode: str, total_length: int):
        self.mode = mode
        self.total_length = total_length


class PromptValidationFailedEvent(Event):
    """Event emitted when prompt validation fails"""
    def __init__(self, errors: List[str]):
        self.errors = errors


class PromptService:
    """High-level prompt building service"""
    
    def __init__(self):
        self.formatter = PromptFormatter()
        self.validator = PromptValidator()
        
        self.system_prompt: str = ""
        self.user_prompt: str = ""
        self.current_mode: str = "enhanced"
        
        # Cache for file contents and attachments
        self._file_contents_cache: List[Dict[str, str]] = []
        self._attachments_cache: List[Dict[str, Any]] = []
    
    def set_system_prompt(self, content: str) -> bool:
        """Set system prompt content"""
        valid, error = self.validator.validate_system_prompt(content)
        if not valid:
            logger.error(f"Invalid system prompt: {error}")
            return False
        
        self.system_prompt = content
        logger.info(f"System prompt set: {len(content)} characters")
        return True
    
    def get_system_prompt(self) -> str:
        """Get current system prompt"""
        return self.system_prompt
    
    def set_user_prompt(self, content: str) -> bool:
        """Set user prompt content"""
        valid, error = self.validator.validate_user_prompt(content)
        if not valid:
            logger.error(f"Invalid user prompt: {error}")
            return False
        
        self.user_prompt = content
        logger.info(f"User prompt set: {len(content)} characters")
        return True
    
    def get_user_prompt(self) -> str:
        """Get current user prompt"""
        return self.user_prompt
    
    def set_mode(self, mode: str) -> bool:
        """Set prompt building mode"""
        if mode not in ["enhanced", "metaprompt"]:
            logger.error(f"Invalid mode: {mode}")
            return False
        
        self.current_mode = mode
        logger.info(f"Prompt mode set to: {mode}")
        return True
    
    def get_mode(self) -> str:
        """Get current prompt mode"""
        return self.current_mode
    
    async def build_prompt(
        self,
        include_files: bool = True,
        include_attachments: bool = True,
        include_system_prompt: bool = True,
        include_user_prompt: bool = True
    ) -> Tuple[bool, str, List[str]]:
        """Build the final prompt"""
        errors = []
        
        # Gather components
        system = self.system_prompt if include_system_prompt else None
        user = self.user_prompt if include_user_prompt else None
        
        # Get file contents if requested
        file_contents = []
        if include_files:
            file_contents = await self._get_file_contents()
        
        # Get attachments if requested
        attachments = []
        if include_attachments:
            attachments = await self._get_attachments()
        
        # Validate complete prompt
        valid, validation_errors = self.validator.validate_complete_prompt(
            system, user, file_contents, attachments
        )
        
        if not valid:
            errors.extend(validation_errors)
            EventBus.emit(PromptValidationFailedEvent(errors=errors))
            return False, "", errors
        
        # Build prompt based on mode
        if self.current_mode == "enhanced":
            prompt = self.formatter.build_enhanced_prompt(
                system_prompt=system,
                user_prompt=user,
                file_contents=file_contents,
                attachments=attachments
            )
        else:  # metaprompt mode
            # Build base content
            base_content = self.formatter.build_enhanced_prompt(
                system_prompt=None,  # Don't include system in base
                user_prompt=user,
                file_contents=file_contents,
                attachments=attachments
            )
            
            # Apply metaprompt template
            template = system or "{{CONTENT}}"  # Use system as template
            prompt = self.formatter.build_metaprompt(template, base_content)
        
        # Emit success event
        EventBus.emit(PromptBuiltEvent(mode=self.current_mode, total_length=len(prompt)))
        
        logger.info(f"Prompt built successfully: {len(prompt)} characters")
        return True, prompt, []
    
    async def get_prompt_preview(self, max_length: int = 1000) -> str:
        """Get a preview of the prompt"""
        success, prompt, errors = await self.build_prompt()
        
        if not success:
            return f"Error building prompt: {', '.join(errors)}"
        
        return self.formatter.truncate_prompt(prompt, max_length)
    
    def get_prompt_components(self) -> Dict[str, Any]:
        """Get all prompt components"""
        return {
            "system_prompt": self.system_prompt,
            "user_prompt": self.user_prompt,
            "mode": self.current_mode,
            "file_count": len(self._file_contents_cache),
            "attachment_count": len(self._attachments_cache)
        }
    
    def clear_prompts(self, clear_system: bool = False, clear_user: bool = True):
        """Clear prompt contents"""
        if clear_system:
            self.system_prompt = ""
            logger.info("System prompt cleared")
        
        if clear_user:
            self.user_prompt = ""
            logger.info("User prompt cleared")
    
    def get_prompt_stats(self) -> Dict[str, Any]:
        """Get statistics about the current prompt"""
        return self.validator.get_prompt_stats(
            system_prompt=self.system_prompt,
            user_prompt=self.user_prompt,
            file_contents=self._file_contents_cache,
            attachments=self._attachments_cache
        )
    
    async def _get_file_contents(self) -> List[Dict[str, str]]:
        """Get contents of checked files"""
        try:
            # Get file system service
            file_service = ServiceLocator.get("file_system")
            if not file_service:
                logger.warning("File system service not available")
                return []
            
            # Get checked files
            checked_files = file_service.get_checked_files()
            
            # Read file contents
            file_contents = []
            for file_path in checked_files:
                content = file_service.get_file_content(file_path)
                if content:
                    file_contents.append({
                        'path': file_path,
                        'content': content
                    })
            
            self._file_contents_cache = file_contents
            return file_contents
            
        except Exception as e:
            logger.error(f"Error getting file contents: {e}")
            return []
    
    async def _get_attachments(self) -> List[Dict[str, Any]]:
        """Get attachment information"""
        try:
            # Get attachment service when implemented
            # For now, return cached attachments
            return self._attachments_cache
            
        except Exception as e:
            logger.error(f"Error getting attachments: {e}")
            return []


# Import asyncio for preview method
import asyncio



======== src\features\prompt_builder\__init__.py ========



======== src\features\prompt_builder\commands.py ========
"""Prompt builder feature commands"""
from typing import Optional, List, Dict, Any
from src.gateway.bus._base import Command


class SetSystemPrompt(Command):
    """Command to set system prompt content"""
    content: str


class GetSystemPrompt(Command):
    """Command to get current system prompt"""
    pass


class SetUserPrompt(Command):
    """Command to set user prompt content"""
    content: str


class GetUserPrompt(Command):
    """Command to get current user prompt"""
    pass


class BuildPrompt(Command):
    """Command to build the final prompt"""
    include_files: bool = True
    include_attachments: bool = True
    include_system_prompt: bool = True
    include_user_prompt: bool = True
    mode: str = "enhanced"  # "enhanced" or "metaprompt"


class GetPromptComponents(Command):
    """Command to get all prompt components"""
    pass


class ValidatePrompt(Command):
    """Command to validate prompt components"""
    pass


class GetPromptPreview(Command):
    """Command to get a preview of the built prompt"""
    max_length: int = 1000


class ClearPrompts(Command):
    """Command to clear all prompts"""
    clear_system: bool = False
    clear_user: bool = True


class SetPromptMode(Command):
    """Command to set prompt building mode"""
    mode: str  # "enhanced" or "metaprompt"


class GetPromptMode(Command):
    """Command to get current prompt mode"""
    pass


class ApplyTemplate(Command):
    """Command to apply a template to prompts"""
    template_name: str
    target: str  # "system" or "user"


======== src\features\prompt_builder\handlers.py ========
"""Prompt builder feature command handlers"""
import logging
from src.gateway.bus.prompt_builder_command_bus import PromptBuilderCommandBus
from src.gateway import EventBus, ServiceLocator
from .commands import (
    SetSystemPrompt, GetSystemPrompt, SetUserPrompt, GetUserPrompt,
    BuildPrompt, GetPromptComponents, ValidatePrompt, GetPromptPreview,
    ClearPrompts, SetPromptMode, GetPromptMode, ApplyTemplate
)
from .organisms.prompt_service import PromptService

logger = logging.getLogger(__name__)


# Initialize prompt service and register with ServiceLocator
prompt_service = PromptService()
ServiceLocator.provide("prompt_builder", prompt_service)


@PromptBuilderCommandBus.register(SetSystemPrompt)
async def handle_set_system_prompt(cmd: SetSystemPrompt):
    """Set system prompt content"""
    service = ServiceLocator.get("prompt_builder")
    success = service.set_system_prompt(cmd.content)
    return {"success": success, "length": len(cmd.content)}


@PromptBuilderCommandBus.register(GetSystemPrompt)
async def handle_get_system_prompt(cmd: GetSystemPrompt):
    """Get current system prompt"""
    service = ServiceLocator.get("prompt_builder")
    content = service.get_system_prompt()
    return {"content": content, "length": len(content)}


@PromptBuilderCommandBus.register(SetUserPrompt)
async def handle_set_user_prompt(cmd: SetUserPrompt):
    """Set user prompt content"""
    service = ServiceLocator.get("prompt_builder")
    success = service.set_user_prompt(cmd.content)
    return {"success": success, "length": len(cmd.content)}


@PromptBuilderCommandBus.register(GetUserPrompt)
async def handle_get_user_prompt(cmd: GetUserPrompt):
    """Get current user prompt"""
    service = ServiceLocator.get("prompt_builder")
    content = service.get_user_prompt()
    return {"content": content, "length": len(content)}


@PromptBuilderCommandBus.register(BuildPrompt)
async def handle_build_prompt(cmd: BuildPrompt):
    """Build the final prompt"""
    service = ServiceLocator.get("prompt_builder")
    
    # Set mode if different
    if cmd.mode != service.get_mode():
        service.set_mode(cmd.mode)
    
    success, prompt, errors = await service.build_prompt(
        include_files=cmd.include_files,
        include_attachments=cmd.include_attachments,
        include_system_prompt=cmd.include_system_prompt,
        include_user_prompt=cmd.include_user_prompt
    )
    
    return {
        "success": success,
        "prompt": prompt if success else None,
        "errors": errors,
        "length": len(prompt) if success else 0
    }


@PromptBuilderCommandBus.register(GetPromptComponents)
async def handle_get_prompt_components(cmd: GetPromptComponents):
    """Get all prompt components"""
    service = ServiceLocator.get("prompt_builder")
    components = service.get_prompt_components()
    return components


@PromptBuilderCommandBus.register(ValidatePrompt)
async def handle_validate_prompt(cmd: ValidatePrompt):
    """Validate prompt components"""
    service = ServiceLocator.get("prompt_builder")
    
    # Build prompt to validate
    success, _, errors = await service.build_prompt()
    
    # Get stats
    stats = service.get_prompt_stats()
    
    return {
        "valid": success,
        "errors": errors,
        "stats": stats
    }


@PromptBuilderCommandBus.register(GetPromptPreview)
async def handle_get_prompt_preview(cmd: GetPromptPreview):
    """Get a preview of the built prompt"""
    service = ServiceLocator.get("prompt_builder")
    preview = await service.get_prompt_preview(cmd.max_length)
    
    return {
        "preview": preview,
        "truncated": len(preview) >= cmd.max_length
    }


@PromptBuilderCommandBus.register(ClearPrompts)
async def handle_clear_prompts(cmd: ClearPrompts):
    """Clear prompt contents"""
    service = ServiceLocator.get("prompt_builder")
    service.clear_prompts(
        clear_system=cmd.clear_system,
        clear_user=cmd.clear_user
    )
    
    return {
        "cleared_system": cmd.clear_system,
        "cleared_user": cmd.clear_user
    }


@PromptBuilderCommandBus.register(SetPromptMode)
async def handle_set_prompt_mode(cmd: SetPromptMode):
    """Set prompt building mode"""
    service = ServiceLocator.get("prompt_builder")
    success = service.set_mode(cmd.mode)
    
    return {
        "success": success,
        "mode": cmd.mode if success else service.get_mode()
    }


@PromptBuilderCommandBus.register(GetPromptMode)
async def handle_get_prompt_mode(cmd: GetPromptMode):
    """Get current prompt mode"""
    service = ServiceLocator.get("prompt_builder")
    mode = service.get_mode()
    return {"mode": mode}


@PromptBuilderCommandBus.register(ApplyTemplate)
async def handle_apply_template(cmd: ApplyTemplate):
    """Apply a template to prompts"""
    # This would integrate with the templates feature
    # For now, return a placeholder response
    logger.warning("Template application not yet implemented")
    
    return {
        "success": False,
        "error": "Template feature not yet implemented",
        "template": cmd.template_name,
        "target": cmd.target
    }



======== src\features\state\atoms\__init__.py ========



======== src\features\state\molecules\__init__.py ========



======== src\features\state\organisms\__init__.py ========



======== src\features\state\__init__.py ========



======== src\features\state\commands.py ========



======== src\features\state\handlers.py ========



======== src\features\templates\atoms\__init__.py ========



======== src\features\templates\molecules\__init__.py ========



======== src\features\templates\organisms\__init__.py ========



======== src\features\templates\__init__.py ========



======== src\features\templates\commands.py ========



======== src\features\templates\handlers.py ========



======== src\features\tokens\atoms\__init__.py ========



======== src\features\tokens\atoms\claude_tokenizer.py ========
"""Claude tokenizer atom - calculates tokens for Anthropic models"""
import logging
import httpx
from typing import Optional, Dict

logger = logging.getLogger(__name__)


class ClaudeTokenizer:
    """Tokenizer for Anthropic Claude models using API"""
    
    def __init__(self):
        self.api_endpoint = "https://api.anthropic.com/v1/tokenize"
        self._api_key: Optional[str] = None
        self._client = httpx.Client(timeout=30.0)
    
    def set_api_key(self, api_key: str):
        """Set API key for Claude tokenization"""
        self._api_key = api_key
    
    def count_tokens(self, text: str, model: str = "claude-3") -> int:
        """Count tokens in text using Claude API"""
        if not text:
            return 0
        
        # If no API key, use fallback estimation
        if not self._api_key:
            logger.warning("No Claude API key available, using fallback estimation")
            return self._estimate_tokens(text)
        
        try:
            response = self._client.post(
                self.api_endpoint,
                headers={
                    "X-API-Key": self._api_key,
                    "Content-Type": "application/json",
                    "anthropic-version": "2023-06-01"
                },
                json={
                    "text": text,
                    "model": model
                }
            )
            
            if response.status_code == 200:
                data = response.json()
                return data.get("token_count", 0)
            else:
                logger.error(f"Claude tokenization API error: {response.status_code}")
                return self._estimate_tokens(text)
                
        except Exception as e:
            logger.error(f"Error calling Claude tokenization API: {e}")
            return self._estimate_tokens(text)
    
    def _estimate_tokens(self, text: str) -> int:
        """Estimate tokens when API is not available"""
        # Claude uses roughly similar tokenization to GPT
        # Estimate ~4 characters per token
        return len(text) // 4
    
    def get_model_limits(self, model: str) -> Dict[str, int]:
        """Get token limits for Claude models"""
        limits = {
            "claude-3-opus": {"context": 200000, "max_output": 4096},
            "claude-3-sonnet": {"context": 200000, "max_output": 4096},
            "claude-3-haiku": {"context": 200000, "max_output": 4096},
            "claude-2.1": {"context": 200000, "max_output": 4096},
            "claude-2": {"context": 100000, "max_output": 4096},
            "claude-instant": {"context": 100000, "max_output": 4096},
        }
        
        return limits.get(model, {"context": 100000, "max_output": 4096})
    
    def truncate_to_tokens(self, text: str, max_tokens: int, model: str = "claude-3") -> str:
        """Truncate text to fit within token limit"""
        # Since we can't tokenize without API, use character-based approximation
        estimated_chars = max_tokens * 4
        if len(text) <= estimated_chars:
            return text
        
        return text[:estimated_chars]
    
    def __del__(self):
        """Cleanup HTTP client"""
        if hasattr(self, '_client'):
            self._client.close()


======== src\features\tokens\atoms\gemini_tokenizer.py ========
"""Gemini tokenizer atom - calculates tokens for Google models"""
import logging
from typing import Optional, Dict, Any
import google.generativeai as genai

logger = logging.getLogger(__name__)


class GeminiTokenizer:
    """Tokenizer for Google Gemini models"""
    
    def __init__(self):
        self._model_cache = {}
        self._api_key: Optional[str] = None
    
    def set_api_key(self, api_key: str):
        """Set API key for Gemini"""
        self._api_key = api_key
        genai.configure(api_key=api_key)
    
    def count_tokens(self, text: str, model: str = "gemini-pro") -> int:
        """Count tokens in text using Gemini API"""
        if not text:
            return 0
        
        if not self._api_key:
            logger.warning("No Gemini API key available, using fallback estimation")
            return self._estimate_tokens(text)
        
        try:
            # Get or create model instance
            if model not in self._model_cache:
                self._model_cache[model] = genai.GenerativeModel(model)
            
            model_instance = self._model_cache[model]
            
            # Count tokens
            token_count = model_instance.count_tokens(text)
            return token_count.total_tokens
            
        except Exception as e:
            logger.error(f"Error counting Gemini tokens: {e}")
            return self._estimate_tokens(text)
    
    def count_multimodal_tokens(
        self,
        text: str,
        images: Optional[List[Any]] = None,
        model: str = "gemini-pro-vision"
    ) -> Dict[str, int]:
        """Count tokens for multimodal content"""
        if not self._api_key:
            logger.warning("No Gemini API key available, using fallback estimation")
            text_tokens = self._estimate_tokens(text)
            image_tokens = len(images) * 258 if images else 0  # ~258 tokens per image
            return {
                "text_tokens": text_tokens,
                "image_tokens": image_tokens,
                "total_tokens": text_tokens + image_tokens
            }
        
        try:
            # Get or create model instance
            if model not in self._model_cache:
                self._model_cache[model] = genai.GenerativeModel(model)
            
            model_instance = self._model_cache[model]
            
            # Build content list
            content = [text]
            if images:
                content.extend(images)
            
            # Count tokens
            token_count = model_instance.count_tokens(content)
            
            # Estimate breakdown (Gemini doesn't provide detailed breakdown)
            text_tokens = self._estimate_tokens(text)
            total = token_count.total_tokens
            image_tokens = max(0, total - text_tokens)
            
            return {
                "text_tokens": text_tokens,
                "image_tokens": image_tokens,
                "total_tokens": total
            }
            
        except Exception as e:
            logger.error(f"Error counting multimodal tokens: {e}")
            text_tokens = self._estimate_tokens(text)
            image_tokens = len(images) * 258 if images else 0
            return {
                "text_tokens": text_tokens,
                "image_tokens": image_tokens,
                "total_tokens": text_tokens + image_tokens
            }
    
    def _estimate_tokens(self, text: str) -> int:
        """Estimate tokens when API is not available"""
        # Gemini uses roughly similar tokenization
        # Estimate ~4 characters per token
        return len(text) // 4
    
    def get_model_limits(self, model: str) -> Dict[str, Any]:
        """Get token limits for Gemini models"""
        limits = {
            "gemini-pro": {
                "context": 32768,
                "max_output": 8192,
                "supports_images": False,
                "supports_video": False
            },
            "gemini-pro-vision": {
                "context": 16384,
                "max_output": 2048,
                "supports_images": True,
                "supports_video": True,
                "max_images": 16,
                "max_video_length": 1  # minutes
            },
            "gemini-pro-1.5": {
                "context": 1048576,  # 1M tokens
                "max_output": 8192,
                "supports_images": True,
                "supports_video": True
            }
        }
        
        return limits.get(model, {
            "context": 32768,
            "max_output": 2048,
            "supports_images": False,
            "supports_video": False
        })
    
    def estimate_image_tokens(self, image_size: tuple[int, int]) -> int:
        """Estimate tokens for an image based on size"""
        # Gemini uses approximately 258 tokens per image
        # regardless of size (as of current models)
        return 258
    
    def estimate_video_tokens(self, duration_seconds: int, fps: int = 1) -> int:
        """Estimate tokens for video content"""
        # Gemini samples video at 1 FPS by default
        # Each frame counts as an image (~258 tokens)
        frames = duration_seconds * fps
        return frames * 258


# Import for type hints
from typing import List


======== src\features\tokens\atoms\gpt_tokenizer.py ========
"""GPT tokenizer atom - calculates tokens for OpenAI models"""
import logging
from typing import Optional
import tiktoken

logger = logging.getLogger(__name__)


class GPTTokenizer:
    """Tokenizer for OpenAI GPT models"""
    
    def __init__(self):
        self._encodings = {}
        self._model_to_encoding = {
            "gpt-4": "cl100k_base",
            "gpt-4-32k": "cl100k_base",
            "gpt-4-turbo": "cl100k_base",
            "gpt-4-turbo-preview": "cl100k_base",
            "gpt-3.5-turbo": "cl100k_base",
            "gpt-3.5-turbo-16k": "cl100k_base",
            "text-davinci-003": "p50k_base",
            "text-davinci-002": "p50k_base",
        }
    
    def get_encoding(self, model: str) -> Optional[tiktoken.Encoding]:
        """Get encoding for a specific model"""
        encoding_name = self._model_to_encoding.get(model, "cl100k_base")
        
        if encoding_name not in self._encodings:
            try:
                self._encodings[encoding_name] = tiktoken.get_encoding(encoding_name)
                logger.debug(f"Loaded encoding {encoding_name} for model {model}")
            except Exception as e:
                logger.error(f"Failed to load encoding {encoding_name}: {e}")
                return None
        
        return self._encodings[encoding_name]
    
    def count_tokens(self, text: str, model: str = "gpt-4") -> int:
        """Count tokens in text for a specific model"""
        if not text:
            return 0
        
        encoding = self.get_encoding(model)
        if not encoding:
            # Fallback to character-based estimation
            logger.warning(f"Using fallback token estimation for model {model}")
            return len(text) // 4
        
        try:
            tokens = encoding.encode(text)
            return len(tokens)
        except Exception as e:
            logger.error(f"Error counting tokens: {e}")
            return len(text) // 4
    
    def truncate_to_tokens(self, text: str, max_tokens: int, model: str = "gpt-4") -> str:
        """Truncate text to fit within token limit"""
        if not text:
            return text
        
        encoding = self.get_encoding(model)
        if not encoding:
            # Fallback to character-based truncation
            max_chars = max_tokens * 4
            return text[:max_chars]
        
        try:
            tokens = encoding.encode(text)
            if len(tokens) <= max_tokens:
                return text
            
            # Truncate tokens and decode back to text
            truncated_tokens = tokens[:max_tokens]
            return encoding.decode(truncated_tokens)
        except Exception as e:
            logger.error(f"Error truncating text: {e}")
            max_chars = max_tokens * 4
            return text[:max_chars]
    
    def get_model_limits(self, model: str) -> Dict[str, int]:
        """Get token limits for a model"""
        limits = {
            "gpt-4": {"context": 8192, "max_output": 4096},
            "gpt-4-32k": {"context": 32768, "max_output": 4096},
            "gpt-4-turbo": {"context": 128000, "max_output": 4096},
            "gpt-4-turbo-preview": {"context": 128000, "max_output": 4096},
            "gpt-3.5-turbo": {"context": 4096, "max_output": 4096},
            "gpt-3.5-turbo-16k": {"context": 16384, "max_output": 4096},
            "text-davinci-003": {"context": 4097, "max_output": 4000},
        }
        
        return limits.get(model, {"context": 4096, "max_output": 2048})


# Import for type hints
from typing import Dict


======== src\features\tokens\molecules\__init__.py ========



======== src\features\tokens\molecules\cost_calculator.py ========
"""Cost calculator molecule - calculates API costs based on tokens"""
import logging
from typing import Dict, Optional
from decimal import Decimal

logger = logging.getLogger(__name__)


class CostCalculator:
    """Calculates API costs for different models"""
    
    def __init__(self):
        # Prices per 1K tokens (in USD)
        self.pricing = {
            # OpenAI GPT-4
            "gpt-4": {
                "prompt": Decimal("0.03"),
                "completion": Decimal("0.06")
            },
            "gpt-4-32k": {
                "prompt": Decimal("0.06"),
                "completion": Decimal("0.12")
            },
            "gpt-4-turbo": {
                "prompt": Decimal("0.01"),
                "completion": Decimal("0.03")
            },
            "gpt-4-turbo-preview": {
                "prompt": Decimal("0.01"),
                "completion": Decimal("0.03")
            },
            # OpenAI GPT-3.5
            "gpt-3.5-turbo": {
                "prompt": Decimal("0.0005"),
                "completion": Decimal("0.0015")
            },
            "gpt-3.5-turbo-16k": {
                "prompt": Decimal("0.001"),
                "completion": Decimal("0.002")
            },
            # Anthropic Claude
            "claude-3-opus": {
                "prompt": Decimal("0.015"),
                "completion": Decimal("0.075")
            },
            "claude-3-sonnet": {
                "prompt": Decimal("0.003"),
                "completion": Decimal("0.015")
            },
            "claude-3-haiku": {
                "prompt": Decimal("0.00025"),
                "completion": Decimal("0.00125")
            },
            # Google Gemini
            "gemini-pro": {
                "prompt": Decimal("0.0005"),
                "completion": Decimal("0.0015")
            },
            "gemini-pro-vision": {
                "prompt": Decimal("0.0005"),
                "completion": Decimal("0.0015"),
                "image": Decimal("0.002")  # per image
            },
            "gemini-pro-1.5": {
                "prompt": Decimal("0.00125"),
                "completion": Decimal("0.005")
            }
        }
    
    def calculate_cost(
        self,
        prompt_tokens: int,
        completion_tokens: int,
        model: str,
        image_count: int = 0
    ) -> Dict[str, Decimal]:
        """Calculate cost for API usage"""
        if model not in self.pricing:
            logger.warning(f"Unknown model {model}, using default pricing")
            pricing = {
                "prompt": Decimal("0.001"),
                "completion": Decimal("0.002")
            }
        else:
            pricing = self.pricing[model]
        
        # Calculate text costs
        prompt_cost = (Decimal(prompt_tokens) / 1000) * pricing["prompt"]
        completion_cost = (Decimal(completion_tokens) / 1000) * pricing["completion"]
        
        # Calculate image costs if applicable
        image_cost = Decimal("0")
        if image_count > 0 and "image" in pricing:
            image_cost = Decimal(image_count) * pricing["image"]
        
        total_cost = prompt_cost + completion_cost + image_cost
        
        return {
            "prompt_cost": prompt_cost,
            "completion_cost": completion_cost,
            "image_cost": image_cost,
            "total_cost": total_cost,
            "currency": "USD"
        }
    
    def estimate_monthly_cost(
        self,
        daily_requests: int,
        avg_prompt_tokens: int,
        avg_completion_tokens: int,
        model: str,
        avg_images_per_request: int = 0
    ) -> Dict[str, Decimal]:
        """Estimate monthly API costs"""
        # Calculate daily cost
        daily_cost = self.calculate_cost(
            prompt_tokens=daily_requests * avg_prompt_tokens,
            completion_tokens=daily_requests * avg_completion_tokens,
            model=model,
            image_count=daily_requests * avg_images_per_request
        )
        
        # Multiply by 30 for monthly estimate
        monthly_cost = {}
        for key, value in daily_cost.items():
            if key == "currency":
                monthly_cost[key] = value
            else:
                monthly_cost[key] = value * 30
        
        return monthly_cost
    
    def get_model_pricing(self, model: str) -> Optional[Dict[str, Decimal]]:
        """Get pricing information for a model"""
        return self.pricing.get(model)
    
    def compare_models(
        self,
        prompt_tokens: int,
        completion_tokens: int,
        models: Optional[List[str]] = None
    ) -> Dict[str, Dict[str, Decimal]]:
        """Compare costs across different models"""
        if models is None:
            models = list(self.pricing.keys())
        
        comparison = {}
        for model in models:
            if model in self.pricing:
                cost = self.calculate_cost(prompt_tokens, completion_tokens, model)
                comparison[model] = cost
        
        # Sort by total cost
        sorted_comparison = dict(
            sorted(comparison.items(), key=lambda x: x[1]["total_cost"])
        )
        
        return sorted_comparison
    
    def format_cost(self, cost: Decimal, include_currency: bool = True) -> str:
        """Format cost for display"""
        formatted = f"${cost:.4f}"
        if include_currency:
            formatted += " USD"
        return formatted


# Import for type hints
from typing import List


======== src\features\tokens\organisms\__init__.py ========



======== src\features\tokens\organisms\token_service.py ========
"""Token service organism - manages token calculation operations"""
import logging
from typing import Dict, Any, Optional, Tuple
from src.gateway import ServiceLocator, EventBus, Event
from ..atoms.gpt_tokenizer import GPTTokenizer
from ..atoms.claude_tokenizer import ClaudeTokenizer
from ..atoms.gemini_tokenizer import GeminiTokenizer
from ..molecules.cost_calculator import CostCalculator

logger = logging.getLogger(__name__)


# Token calculation events
class TokensCalculatedEvent(Event):
    """Event emitted when tokens are calculated"""
    def __init__(self, model: str, token_count: int):
        self.model = model
        self.token_count = token_count


class CostCalculatedEvent(Event):
    """Event emitted when cost is calculated"""
    def __init__(self, model: str, total_cost: float):
        self.model = model
        self.total_cost = total_cost


class TokenService:
    """High-level token calculation service"""
    
    def __init__(self):
        self.gpt_tokenizer = GPTTokenizer()
        self.claude_tokenizer = ClaudeTokenizer()
        self.gemini_tokenizer = GeminiTokenizer()
        self.cost_calculator = CostCalculator()
        
        # Token usage tracking
        self.usage_stats = {
            "total_prompt_tokens": 0,
            "total_completion_tokens": 0,
            "total_cost": 0.0,
            "by_model": {}
        }
        
        # API keys are initialized asynchronously when needed
    
    async def _initialize_api_keys(self):
        """Initialize API keys from config service"""
        try:
            config_service = ServiceLocator.get("config")
            if config_service and config_service.get_settings():
                # Get Claude API key
                claude_key = config_service.get_settings().anthropic_api_key
                if claude_key:
                    self.claude_tokenizer.set_api_key(claude_key)
                
                # Get Gemini API key
                gemini_key = await config_service.get_active_gemini_key()
                if gemini_key:
                    self.gemini_tokenizer.set_api_key(gemini_key)
                
        except Exception as e:
            logger.warning(f"Could not initialize API keys: {e}")
    
    async def _init_gemini_key(self, config_service):
        """Initialize Gemini API key asynchronously"""
        gemini_key = await config_service.get_active_gemini_key()
        if gemini_key:
            self.gemini_tokenizer.set_api_key(gemini_key)
    
    def calculate_tokens(self, text: str, model: str = "gpt-4") -> int:
        """Calculate tokens for text using tiktoken regardless of model"""
        if not text:
            return 0
        
        # Always use tiktoken for token calculation
        # Map all models to their closest GPT equivalent for tokenization
        tiktoken_model = self._get_tiktoken_model(model)
        tokens = self.gpt_tokenizer.count_tokens(text, tiktoken_model)
        
        logger.debug(f"Calculated {tokens} tokens for {len(text)} characters using tiktoken model: {tiktoken_model}")
        
        # Emit event
        EventBus.emit(TokensCalculatedEvent(model=model, token_count=tokens))
        
        # Update usage stats
        self._update_usage_stats(model, tokens, 0)
        
        return tokens
    
    def _get_tiktoken_model(self, model: str) -> str:
        """Map any model to appropriate tiktoken model"""
        # Claude and Gemini models use similar tokenization to GPT-4
        if model.startswith("claude") or model.startswith("gemini"):
            return "gpt-4"
        elif model.startswith("gpt"):
            # Return the actual GPT model name
            return model
        else:
            # Default to GPT-4 tokenization
            return "gpt-4"
    
    async def calculate_prompt_tokens(
        self,
        include_files: bool = True,
        include_attachments: bool = True,
        include_system_prompt: bool = True,
        include_user_prompt: bool = True,
        model: str = "gpt-4"
    ) -> Dict[str, Any]:
        """Calculate tokens for complete prompt"""
        try:
            # Get prompt builder service
            prompt_service = ServiceLocator.get("prompt_builder")
            if not prompt_service:
                logger.error("Prompt builder service not available")
                return {"error": "Service not available", "tokens": 0}
            
            # Build prompt
            success, prompt, errors = await prompt_service.build_prompt(
                include_files=include_files,
                include_attachments=include_attachments,
                include_system_prompt=include_system_prompt,
                include_user_prompt=include_user_prompt
            )
            
            if not success:
                return {"error": f"Failed to build prompt: {errors}", "tokens": 0}
            
            # Calculate tokens
            tokens = self.calculate_tokens(prompt, model)
            
            # Get breakdown
            components = prompt_service.get_prompt_components()
            
            return {
                "total_tokens": tokens,
                "model": model,
                "components": components,
                "prompt_length": len(prompt)
            }
            
        except Exception as e:
            logger.error(f"Error calculating prompt tokens: {e}")
            return {"error": str(e), "tokens": 0}
    
    def calculate_file_tokens(self, file_path: str, model: str = "gpt-4") -> Dict[str, Any]:
        """Calculate tokens for a file"""
        try:
            # Get file content
            file_service = ServiceLocator.get("file_system")
            if not file_service:
                return {"error": "File system service not available", "tokens": 0}
            
            content = file_service.get_file_content(file_path)
            if not content:
                return {"error": "Could not read file", "tokens": 0}
            
            # Calculate tokens
            tokens = self.calculate_tokens(content, model)
            
            return {
                "file": file_path,
                "tokens": tokens,
                "model": model,
                "file_size": len(content)
            }
            
        except Exception as e:
            logger.error(f"Error calculating file tokens: {e}")
            return {"error": str(e), "tokens": 0}
    
    def calculate_multimodal_tokens(
        self,
        text_content: str,
        image_count: int = 0,
        video_count: int = 0,
        audio_count: int = 0
    ) -> Dict[str, Any]:
        """Calculate tokens for multimodal content (Gemini)"""
        # Text tokens
        text_tokens = self.gemini_tokenizer.count_tokens(text_content, "gemini-pro-vision")
        
        # Image tokens (258 per image)
        image_tokens = image_count * 258
        
        # Video tokens (258 per second at 1 FPS)
        video_tokens = video_count * 258  # Assuming 1 second per video for simplicity
        
        # Audio not yet supported
        audio_tokens = 0
        
        total_tokens = text_tokens + image_tokens + video_tokens + audio_tokens
        
        return {
            "text_tokens": text_tokens,
            "image_tokens": image_tokens,
            "video_tokens": video_tokens,
            "audio_tokens": audio_tokens,
            "total_tokens": total_tokens,
            "breakdown": {
                "images": image_count,
                "videos": video_count,
                "audio": audio_count
            }
        }
    
    def estimate_cost(
        self,
        prompt_tokens: int,
        completion_tokens: int,
        model: str = "gpt-4",
        image_count: int = 0
    ) -> Dict[str, Any]:
        """Estimate API cost based on tokens"""
        cost_data = self.cost_calculator.calculate_cost(
            prompt_tokens,
            completion_tokens,
            model,
            image_count
        )
        
        # Convert Decimal to float for JSON serialization
        result = {
            "prompt_tokens": prompt_tokens,
            "completion_tokens": completion_tokens,
            "model": model,
            "costs": {
                "prompt_cost": float(cost_data["prompt_cost"]),
                "completion_cost": float(cost_data["completion_cost"]),
                "image_cost": float(cost_data["image_cost"]),
                "total_cost": float(cost_data["total_cost"]),
                "currency": cost_data["currency"]
            }
        }
        
        # Emit event
        EventBus.emit(CostCalculatedEvent(
            model=model,
            total_cost=result["costs"]["total_cost"]
        ))
        
        # Update usage stats
        self._update_usage_stats(model, prompt_tokens, completion_tokens)
        self.usage_stats["total_cost"] += result["costs"]["total_cost"]
        
        return result
    
    def get_token_limits(self) -> Dict[str, Dict[str, Any]]:
        """Get token limits for all models"""
        limits = {}
        
        # GPT models
        for model in ["gpt-4", "gpt-4-32k", "gpt-4-turbo", "gpt-3.5-turbo"]:
            limits[model] = self.gpt_tokenizer.get_model_limits(model)
        
        # Claude models
        for model in ["claude-3-opus", "claude-3-sonnet", "claude-3-haiku"]:
            limits[model] = self.claude_tokenizer.get_model_limits(model)
        
        # Gemini models
        for model in ["gemini-pro", "gemini-pro-vision", "gemini-pro-1.5"]:
            limits[model] = self.gemini_tokenizer.get_model_limits(model)
        
        return limits
    
    def get_model_info(self, model: str) -> Dict[str, Any]:
        """Get detailed information about a model"""
        # Get limits
        if model.startswith("gpt"):
            limits = self.gpt_tokenizer.get_model_limits(model)
        elif model.startswith("claude"):
            limits = self.claude_tokenizer.get_model_limits(model)
        elif model.startswith("gemini"):
            limits = self.gemini_tokenizer.get_model_limits(model)
        else:
            limits = {"context": 4096, "max_output": 2048}
        
        # Get pricing
        pricing = self.cost_calculator.get_model_pricing(model)
        
        return {
            "model": model,
            "limits": limits,
            "pricing": {k: float(v) for k, v in pricing.items()} if pricing else None,
            "provider": self._get_provider(model)
        }
    
    def get_usage_stats(self) -> Dict[str, Any]:
        """Get current token usage statistics"""
        return self.usage_stats.copy()
    
    def _get_provider(self, model: str) -> str:
        """Get provider name for a model"""
        if model.startswith("gpt") or model.startswith("text-"):
            return "OpenAI"
        elif model.startswith("claude"):
            return "Anthropic"
        elif model.startswith("gemini"):
            return "Google"
        else:
            return "Unknown"
    
    def _update_usage_stats(self, model: str, prompt_tokens: int, completion_tokens: int):
        """Update usage statistics"""
        self.usage_stats["total_prompt_tokens"] += prompt_tokens
        self.usage_stats["total_completion_tokens"] += completion_tokens
        
        if model not in self.usage_stats["by_model"]:
            self.usage_stats["by_model"][model] = {
                "prompt_tokens": 0,
                "completion_tokens": 0,
                "requests": 0
            }
        
        self.usage_stats["by_model"][model]["prompt_tokens"] += prompt_tokens
        self.usage_stats["by_model"][model]["completion_tokens"] += completion_tokens
        self.usage_stats["by_model"][model]["requests"] += 1


# Import asyncio for async initialization
import asyncio



======== src\features\tokens\__init__.py ========



======== src\features\tokens\commands.py ========
"""Token calculation feature commands"""
from typing import Optional, List, Dict, Any
from src.gateway.bus._base import Command


class CalculateTokens(Command):
    """Command to calculate tokens for text"""
    text: str
    model: str = "gpt-4"  # gpt-4, claude, gemini


class CalculatePromptTokens(Command):
    """Command to calculate tokens for complete prompt"""
    include_files: bool = True
    include_attachments: bool = True
    include_system_prompt: bool = True
    include_user_prompt: bool = True
    model: str = "gpt-4"


class CalculateFileTokens(Command):
    """Command to calculate tokens for a file"""
    file_path: str
    model: str = "gpt-4"


class CalculateMultimodalTokens(Command):
    """Command to calculate tokens for multimodal content (Gemini)"""
    text_content: str
    image_count: int = 0
    video_count: int = 0
    audio_count: int = 0


class GetTokenUsage(Command):
    """Command to get current token usage statistics"""
    pass


class GetTokenLimits(Command):
    """Command to get token limits for different models"""
    pass


class EstimateCost(Command):
    """Command to estimate API cost based on tokens"""
    prompt_tokens: int
    completion_tokens: int
    model: str = "gpt-4"


class GetModelInfo(Command):
    """Command to get model information including token limits"""
    model: str


======== src\features\tokens\handlers.py ========
"""Token calculation feature command handlers"""
import logging
from src.gateway.bus.tokens_command_bus import TokensCommandBus
from src.gateway import EventBus, ServiceLocator
from .commands import (
    CalculateTokens, CalculatePromptTokens, CalculateFileTokens,
    CalculateMultimodalTokens, GetTokenUsage, GetTokenLimits,
    EstimateCost, GetModelInfo
)
from .organisms.token_service import TokenService

logger = logging.getLogger(__name__)


# Initialize token service and register with ServiceLocator
token_service = TokenService()
ServiceLocator.provide("tokens", token_service)


@TokensCommandBus.register(CalculateTokens)
async def handle_calculate_tokens(cmd: CalculateTokens):
    """Calculate tokens for text"""
    service = ServiceLocator.get("tokens")
    tokens = service.calculate_tokens(cmd.text, cmd.model)
    
    return {
        "text_length": len(cmd.text),
        "tokens": tokens,
        "model": cmd.model,
        "ratio": tokens / len(cmd.text) if cmd.text else 0
    }


@TokensCommandBus.register(CalculatePromptTokens)
async def handle_calculate_prompt_tokens(cmd: CalculatePromptTokens):
    """Calculate tokens for complete prompt"""
    service = ServiceLocator.get("tokens")
    result = await service.calculate_prompt_tokens(
        include_files=cmd.include_files,
        include_attachments=cmd.include_attachments,
        include_system_prompt=cmd.include_system_prompt,
        include_user_prompt=cmd.include_user_prompt,
        model=cmd.model
    )
    
    return result


@TokensCommandBus.register(CalculateFileTokens)
async def handle_calculate_file_tokens(cmd: CalculateFileTokens):
    """Calculate tokens for a file"""
    service = ServiceLocator.get("tokens")
    result = service.calculate_file_tokens(cmd.file_path, cmd.model)
    
    return result


@TokensCommandBus.register(CalculateMultimodalTokens)
async def handle_calculate_multimodal_tokens(cmd: CalculateMultimodalTokens):
    """Calculate tokens for multimodal content"""
    service = ServiceLocator.get("tokens")
    result = service.calculate_multimodal_tokens(
        text_content=cmd.text_content,
        image_count=cmd.image_count,
        video_count=cmd.video_count,
        audio_count=cmd.audio_count
    )
    
    return result


@TokensCommandBus.register(GetTokenUsage)
async def handle_get_token_usage(cmd: GetTokenUsage):
    """Get current token usage statistics"""
    service = ServiceLocator.get("tokens")
    stats = service.get_usage_stats()
    
    return stats


@TokensCommandBus.register(GetTokenLimits)
async def handle_get_token_limits(cmd: GetTokenLimits):
    """Get token limits for different models"""
    service = ServiceLocator.get("tokens")
    limits = service.get_token_limits()
    
    return {"limits": limits}


@TokensCommandBus.register(EstimateCost)
async def handle_estimate_cost(cmd: EstimateCost):
    """Estimate API cost based on tokens"""
    service = ServiceLocator.get("tokens")
    result = service.estimate_cost(
        prompt_tokens=cmd.prompt_tokens,
        completion_tokens=cmd.completion_tokens,
        model=cmd.model
    )
    
    return result


@TokensCommandBus.register(GetModelInfo)
async def handle_get_model_info(cmd: GetModelInfo):
    """Get model information including token limits"""
    service = ServiceLocator.get("tokens")
    info = service.get_model_info(cmd.model)
    
    return info



======== src\features\xml_processor\atoms\__init__.py ========



======== src\features\xml_processor\molecules\__init__.py ========



======== src\features\xml_processor\organisms\__init__.py ========



======== src\features\xml_processor\__init__.py ========



======== src\features\xml_processor\commands.py ========



======== src\features\xml_processor\handlers.py ========



======== src\features\__init__.py ========



======== src\gateway\bus\__init__.py ========



======== src\gateway\bus\_base.py ========
from typing import Callable, Dict, Type
from pydantic import BaseModel
import logging

logger_base_bus = logging.getLogger(__name__)

class Command(BaseModel): 
    """Base command class for all commands in the system"""
    pass

class BaseCommandBus:
    """Base class for feature-specific command buses"""
    
    # Each subclass gets its own _handlers dict initialized
    def __init_subclass__(cls, **kwargs):
        super().__init_subclass__(**kwargs)
        cls._handlers = {}
        logger_base_bus.debug(f"Initialized _handlers for subclass: {cls.__name__}")

    @classmethod
    def register(cls, cmd_type: Type[Command]):
        """Decorator to register command handlers"""
        def decorator(fn: Callable):
            if not hasattr(cls, '_handlers') or not isinstance(cls._handlers, dict):
                logger_base_bus.warning(f"_handlers not properly initialized for {cls.__name__}. Initializing now.")
                cls._handlers = {}
            
            cls._handlers[cmd_type] = fn
            logger_base_bus.info(f"Handler {fn.__name__} registered for command {cmd_type.__name__} in bus {cls.__name__}. Current handlers count: {len(cls._handlers)}")
            return fn
        return decorator

    @classmethod
    async def handle(cls, cmd: Command):
        """Handle a command by dispatching to the appropriate handler"""
        if not hasattr(cls, '_handlers') or not isinstance(cls._handlers, dict):
            logger_base_bus.error(f"Cannot handle command: _handlers not initialized for {cls.__name__}")
            raise ValueError(f"_handlers not initialized for command bus {cls.__name__}")

        handler = cls._handlers.get(type(cmd))
        if handler:
            return await handler(cmd)
        else:
            logger_base_bus.error(f"No handler registered for command type {type(cmd)} in {cls.__name__}. Available handlers: {list(cls._handlers.keys())}")
            raise ValueError(f"No handler registered for command type {type(cmd)} in {cls.__name__}")


======== src\gateway\bus\config_command_bus.py ========
from ._base import BaseCommandBus

class ConfigCommandBus(BaseCommandBus):
    """Configuration feature slice command bus"""
    pass


======== src\gateway\bus\database_command_bus.py ========
from ._base import BaseCommandBus

class DatabaseCommandBus(BaseCommandBus):
    """Database feature slice command bus"""
    pass


======== src\gateway\bus\event_bus.py ========
from collections import defaultdict
from typing import Callable, DefaultDict, Any, Type
import logging

logger = logging.getLogger(__name__)

class Event:
    """Base event class for all events in the system"""
    pass

class EventBus:
    """Global event bus for cross-feature communication"""
    _subs: DefaultDict[Type[Event], list[Callable]] = defaultdict(list)

    @classmethod
    def on(cls, event_type: Type[Event]):
        """Decorator to register event handlers"""
        def decorator(fn: Callable):
            cls._subs[event_type].append(fn)
            logger.debug(f"Handler {fn.__name__} registered for event {event_type.__name__}")
            return fn
        return decorator

    @classmethod
    def emit(cls, event: Event, *args, **kwargs):
        """Emit an event to all registered handlers"""
        event_type = type(event)
        if event_type in cls._subs:
            logger.debug(f"Emitting event {event_type.__name__} to {len(cls._subs[event_type])} handlers. Event data: {event}")
            for fn in cls._subs[event_type]:
                try:
                    fn(event, *args, **kwargs)
                except Exception as e:
                    logger.error(f"Error in event handler {fn.__name__} for event {event_type.__name__}: {e}", exc_info=True)
        else:
            logger.debug(f"No handlers registered for event {event_type.__name__}")


======== src\gateway\bus\file_management_command_bus.py ========
from ._base import BaseCommandBus

class FileManagementCommandBus(BaseCommandBus):
    """File management feature slice command bus"""
    pass


======== src\gateway\bus\prompt_builder_command_bus.py ========
from ._base import BaseCommandBus

class PromptBuilderCommandBus(BaseCommandBus):
    """Prompt builder feature slice command bus"""
    pass


======== src\gateway\bus\service_locator.py ========
import logging
from typing import Any, Dict

_internal_logger = logging.getLogger("src.gateway.service_locator")

# Module-level pool for services
_module_level_pool: Dict[str, Any] = {}
_module_level_pool_initialized_log_done = False

if not _module_level_pool_initialized_log_done:
    _internal_logger.debug(f"ServiceLocator module instance created/imported. Initial _module_level_pool id: {id(_module_level_pool)}, content: {list(_module_level_pool.keys()) if _module_level_pool else 'empty'}")
    _module_level_pool_initialized_log_done = True

class ServiceLocator:
    """Service locator pattern for dependency injection"""
    _class_info_logged = False

    @classmethod
    def _log_class_info_once(cls):
        if not cls._class_info_logged:
            _internal_logger.debug(f"ServiceLocator class accessed. id(ServiceLocator class): {id(cls)}")
            cls._class_info_logged = True

    @classmethod
    def provide(cls, key: str, obj: Any) -> None:
        """Register a service with the locator"""
        cls._log_class_info_once()
        global _module_level_pool
        _internal_logger.debug(f"[PROVIDE PRE] Key: '{key}', Current _module_level_pool id: {id(_module_level_pool)}, Current _module_level_pool keys: {list(_module_level_pool.keys())}")
        if key in _module_level_pool:
            _internal_logger.warning(f"Service key '{key}' already exists in ServiceLocator. Overwriting.")
        _module_level_pool[key] = obj
        _internal_logger.debug(f"[PROVIDE POST] Service '{key}' (type: {type(obj).__name__}) provided. New _module_level_pool keys: {list(_module_level_pool.keys())}, _module_level_pool id: {id(_module_level_pool)}")

    @classmethod
    def get(cls, key: str) -> Any:
        """Retrieve a service from the locator"""
        cls._log_class_info_once()
        global _module_level_pool
        _internal_logger.debug(f"[GET PRE] Key: '{key}', Current _module_level_pool id: {id(_module_level_pool)}, Current _module_level_pool keys: {list(_module_level_pool.keys())}")
        try:
            service = _module_level_pool[key]
            _internal_logger.debug(f"[GET POST] Service '{key}' (type: {type(service).__name__}) retrieved successfully.")
            return service
        except KeyError:
            _internal_logger.error(f"Service key '{key}' not found in ServiceLocator. _module_level_pool id: {id(_module_level_pool)}, Available services: {list(_module_level_pool.keys())}")
            raise KeyError(f"Service '{key}' not found. Available services: {list(_module_level_pool.keys())}")

    @classmethod
    def reset(cls) -> None:
        """Clear all registered services"""
        cls._log_class_info_once()
        global _module_level_pool
        _internal_logger.info(f"[RESET PRE] Current _module_level_pool id: {id(_module_level_pool)}, Current _module_level_pool keys: {list(_module_level_pool.keys())}")
        _module_level_pool.clear()
        _internal_logger.info(f"[RESET POST] ServiceLocator._module_level_pool has been cleared. _module_level_pool id: {id(_module_level_pool)}")


======== src\gateway\bus\tokens_command_bus.py ========
from ._base import BaseCommandBus

class TokensCommandBus(BaseCommandBus):
    """Token calculation feature slice command bus"""
    pass


======== src\gateway\__init__.py ========
"""
Gateway module - Central hub for FAH architecture
Provides access to:
- Feature-specific command buses
- Global event bus
- Service locator
"""

from importlib import import_module
from pathlib import Path
import logging

logger = logging.getLogger(__name__)

# Auto-discover and load all command buses
_bus_pkg_path = Path(__file__).parent / "bus"
if _bus_pkg_path.is_dir():
    for file in _bus_pkg_path.glob("*_command_bus.py"):
        module_name = f"src.gateway.bus.{file.stem}"
        try:
            module = import_module(module_name)
            bus_class_name = next((name for name in dir(module) if name.endswith("CommandBus") and name != "BaseCommandBus"), None)
            if bus_class_name:
                bus_instance_name = file.stem 
                globals()[bus_instance_name] = getattr(module, bus_class_name)
                logger.info(f"Successfully loaded and registered Command Bus: {bus_instance_name} (Class: {bus_class_name})")
            else:
                logger.warning(f"Could not find a CommandBus class in module: {module_name}")
        except ImportError as e:
            logger.error(f"Failed to import Command Bus module {module_name}: {e}")
        except Exception as e:
            logger.error(f"Error processing Command Bus module {module_name}: {e}")
else:
    logger.warning(f"Command Bus package directory not found: {_bus_pkg_path}")

# Export common gateway components
from .bus.event_bus import EventBus, Event
from .bus.service_locator import ServiceLocator

__all__ = ['EventBus', 'Event', 'ServiceLocator']


======== src\shared\atoms\__init__.py ========



======== src\shared\atoms\file_utils.py ========
"""Shared file utilities atom"""
import os
from pathlib import Path
from typing import List, Optional, Set


class FileUtils:
    """Common file operation utilities"""
    
    @staticmethod
    def ensure_directory(path: Path) -> Path:
        """Ensure a directory exists, create if it doesn't"""
        path.mkdir(parents=True, exist_ok=True)
        return path
    
    @staticmethod
    def read_lines(file_path: Path, encoding: str = 'utf-8') -> List[str]:
        """Read all lines from a file"""
        if not file_path.exists():
            return []
        
        with open(file_path, 'r', encoding=encoding) as f:
            return f.readlines()
    
    @staticmethod
    def write_lines(file_path: Path, lines: List[str], encoding: str = 'utf-8') -> None:
        """Write lines to a file"""
        with open(file_path, 'w', encoding=encoding) as f:
            f.writelines(lines)
    
    @staticmethod
    def find_files(
        root_path: Path,
        pattern: str = "*",
        recursive: bool = True,
        exclude_dirs: Optional[Set[str]] = None
    ) -> List[Path]:
        """Find files matching a pattern"""
        if exclude_dirs is None:
            exclude_dirs = {'.git', '__pycache__', 'node_modules', '.venv', 'venv'}
        
        files = []
        
        if recursive:
            for path in root_path.rglob(pattern):
                # Skip excluded directories
                if any(excluded in path.parts for excluded in exclude_dirs):
                    continue
                if path.is_file():
                    files.append(path)
        else:
            for path in root_path.glob(pattern):
                if path.is_file():
                    files.append(path)
        
        return sorted(files)
    
    @staticmethod
    def get_relative_path(file_path: Path, base_path: Path) -> str:
        """Get relative path from base path"""
        try:
            return str(file_path.relative_to(base_path))
        except ValueError:
            return str(file_path)
    
    @staticmethod
    def is_binary_file(file_path: Path) -> bool:
        """Check if a file is binary"""
        try:
            with open(file_path, 'rb') as f:
                chunk = f.read(1024)
                # Check for null bytes
                return b'\x00' in chunk
        except Exception:
            return True


======== src\shared\atoms\logger.py ========
"""Shared logger atom - provides consistent logging across features"""
import logging
import sys
from typing import Optional


class Logger:
    """Centralized logger configuration"""
    
    _initialized = False
    
    @classmethod
    def setup(
        cls,
        level: int = logging.INFO,
        format_string: Optional[str] = None,
        log_file: Optional[str] = None
    ) -> None:
        """Setup root logger configuration"""
        if cls._initialized:
            return
        
        if format_string is None:
            format_string = '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
        
        # Configure root logger
        root_logger = logging.getLogger()
        root_logger.setLevel(level)
        
        # Console handler
        console_handler = logging.StreamHandler(sys.stdout)
        console_handler.setLevel(level)
        console_formatter = logging.Formatter(format_string)
        console_handler.setFormatter(console_formatter)
        root_logger.addHandler(console_handler)
        
        # File handler (optional)
        if log_file:
            file_handler = logging.FileHandler(log_file)
            file_handler.setLevel(level)
            file_handler.setFormatter(console_formatter)
            root_logger.addHandler(file_handler)
        
        cls._initialized = True
    
    @staticmethod
    def get_logger(name: str) -> logging.Logger:
        """Get a logger instance for a specific module"""
        return logging.getLogger(name)


======== src\shared\atoms\validators.py ========
"""Shared validators atom - common validation utilities"""
import re
from typing import Optional
from pathlib import Path


class Validators:
    """Common validation utilities"""
    
    @staticmethod
    def is_valid_api_key(api_key: str, service: str) -> bool:
        """Validate API key format for different services"""
        if not api_key or not isinstance(api_key, str):
            return False
        
        # Remove whitespace
        api_key = api_key.strip()
        
        if service == 'google' or service == 'gemini':
            # Gemini API keys typically start with 'AIza' and are 39 characters
            return len(api_key) == 39 and api_key.startswith('AIza')
        
        elif service == 'anthropic' or service == 'claude':
            # Anthropic keys start with 'sk-ant-' 
            return api_key.startswith('sk-ant-') and len(api_key) > 20
        
        elif service == 'openai':
            # OpenAI keys start with 'sk-'
            return api_key.startswith('sk-') and len(api_key) > 20
        
        return False
    
    @staticmethod
    def is_valid_file_path(path: str) -> bool:
        """Check if a path is valid"""
        try:
            Path(path)
            return True
        except Exception:
            return False
    
    @staticmethod
    def is_valid_url(url: str) -> bool:
        """Basic URL validation"""
        url_pattern = re.compile(
            r'^https?://'  # http:// or https://
            r'(?:(?:[A-Z0-9](?:[A-Z0-9-]{0,61}[A-Z0-9])?\.)+[A-Z]{2,6}\.?|'  # domain...
            r'localhost|'  # localhost...
            r'\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3})'  # ...or ip
            r'(?::\d+)?'  # optional port
            r'(?:/?|[/?]\S+)$', re.IGNORECASE)
        return url_pattern.match(url) is not None
    
    @staticmethod
    def sanitize_filename(filename: str) -> str:
        """Sanitize filename by removing invalid characters"""
        # Remove invalid characters for filenames
        invalid_chars = '<>:"|?*'
        for char in invalid_chars:
            filename = filename.replace(char, '_')
        
        # Remove leading/trailing dots and spaces
        filename = filename.strip('. ')
        
        # Ensure it's not empty
        if not filename:
            filename = 'unnamed'
        
        return filename
    
    @staticmethod
    def validate_json_schema(data: dict, schema: dict) -> tuple[bool, Optional[str]]:
        """Basic JSON schema validation (simplified)"""
        # This is a placeholder for more complex validation
        # In production, you'd use jsonschema library
        try:
            # Basic type checking
            for key, expected_type in schema.get('properties', {}).items():
                if key in schema.get('required', []) and key not in data:
                    return False, f"Missing required field: {key}"
                
                if key in data:
                    # Simplified type checking
                    value = data[key]
                    if 'type' in expected_type:
                        if expected_type['type'] == 'string' and not isinstance(value, str):
                            return False, f"Field {key} must be a string"
                        elif expected_type['type'] == 'number' and not isinstance(value, (int, float)):
                            return False, f"Field {key} must be a number"
                        elif expected_type['type'] == 'boolean' and not isinstance(value, bool):
                            return False, f"Field {key} must be a boolean"
                        elif expected_type['type'] == 'array' and not isinstance(value, list):
                            return False, f"Field {key} must be an array"
                        elif expected_type['type'] == 'object' and not isinstance(value, dict):
                            return False, f"Field {key} must be an object"
            
            return True, None
            
        except Exception as e:
            return False, str(e)


======== src\shared\__init__.py ========



======== src\ui\bridges\__init__.py ========
"""UI Bridge layer - connects PyQt6 UI to FAH architecture"""


======== src\ui\bridges\fah_bridge.py ========
"""FAH Bridge - Main bridge between UI and FAH architecture"""
import asyncio
import logging
from typing import Any, Dict, Optional, Callable
from PyQt6.QtCore import QObject, pyqtSignal, QThread, pyqtSlot
from concurrent.futures import ThreadPoolExecutor
import functools

logger = logging.getLogger(__name__)


class AsyncWorker(QThread):
    """Worker thread for running async FAH commands"""
    
    result_ready = pyqtSignal(object)
    error_occurred = pyqtSignal(str)
    
    def __init__(self, coro, parent=None):
        super().__init__(parent)
        self.coro = coro
        self.loop = None
    
    def run(self):
        """Run the async coroutine in a new event loop"""
        try:
            # Create new event loop for this thread
            self.loop = asyncio.new_event_loop()
            asyncio.set_event_loop(self.loop)
            
            # Run the coroutine
            result = self.loop.run_until_complete(self.coro)
            self.result_ready.emit(result)
            
        except Exception as e:
            logger.error(f"Error in async worker: {e}")
            self.error_occurred.emit(str(e))
        finally:
            if self.loop:
                self.loop.close()


class FAHBridge(QObject):
    """Bridge between PyQt6 UI and FAH command bus architecture"""
    
    # Signals for UI updates
    command_completed = pyqtSignal(str, object)  # command_name, result
    command_failed = pyqtSignal(str, str)  # command_name, error
    
    def __init__(self):
        super().__init__()
        self._workers = []
        self._executor = ThreadPoolExecutor(max_workers=4)
        
        # Import gateway after initialization
        self._gateway = None
        self._initialize_gateway()
    
    def _initialize_gateway(self):
        """Initialize gateway and import all handlers"""
        try:
            # Import gateway
            from src import gateway as gw
            self._gateway = gw
            
            # Import all feature handlers to register them
            import src.features.database.handlers
            import src.features.config.handlers
            import src.features.file_management.handlers
            import src.features.prompt_builder.handlers
            import src.features.tokens.handlers
            
            logger.info("FAH Bridge initialized with all handlers")
            
        except Exception as e:
            logger.error(f"Failed to initialize FAH Bridge: {e}")
            raise
    
    def execute_command(self, bus_name: str, command: Any, callback: Optional[Callable] = None):
        """Execute a FAH command asynchronously"""
        
        async def _execute():
            """Inner async function to execute command"""
            try:
                # Get the command bus
                bus = getattr(self._gateway, f"{bus_name}_command_bus", None)
                if not bus:
                    raise ValueError(f"Command bus '{bus_name}_command_bus' not found")
                
                # Execute command
                result = await bus.handle(command)
                return result
                
            except Exception as e:
                logger.error(f"Error executing command {command.__class__.__name__}: {e}")
                raise
        
        # Create worker thread
        worker = AsyncWorker(_execute())
        
        # Connect signals
        if callback:
            worker.result_ready.connect(callback)
        
        worker.result_ready.connect(
            lambda result: self.command_completed.emit(command.__class__.__name__, result)
        )
        worker.error_occurred.connect(
            lambda error: self.command_failed.emit(command.__class__.__name__, error)
        )
        
        # Track worker and start
        self._workers.append(worker)
        worker.finished.connect(lambda: self._cleanup_worker(worker))
        worker.start()
    
    def execute_command_sync(self, bus_name: str, command: Any) -> Any:
        """Execute a FAH command synchronously (blocks)"""
        future = self._executor.submit(self._execute_sync, bus_name, command)
        return future.result()
    
    def _execute_sync(self, bus_name: str, command: Any) -> Any:
        """Internal sync execution"""
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        
        try:
            bus = getattr(self._gateway, f"{bus_name}_command_bus", None)
            if not bus:
                raise ValueError(f"Command bus '{bus_name}_command_bus' not found")
            
            result = loop.run_until_complete(bus.handle(command))
            return result
        finally:
            loop.close()
    
    def _cleanup_worker(self, worker: AsyncWorker):
        """Clean up finished worker"""
        if worker in self._workers:
            self._workers.remove(worker)
        worker.deleteLater()
    
    def shutdown(self):
        """Shutdown the bridge"""
        # Wait for all workers to finish
        for worker in self._workers:
            if worker.isRunning():
                worker.quit()
                worker.wait(1000)
        
        # Shutdown executor
        self._executor.shutdown(wait=True)
    
    # Convenience methods for common operations
    
    @pyqtSlot(str)
    def set_project_folder(self, folder_path: str):
        """Set project folder"""
        from src.features.file_management.commands import SetProjectFolder
        self.execute_command("file_management", SetProjectFolder(folder_path=folder_path))
    
    @pyqtSlot()
    def load_configuration(self):
        """Load application configuration"""
        from src.features.config.commands import LoadConfiguration
        self.execute_command("config", LoadConfiguration())
    
    @pyqtSlot(str, bool)
    def check_file(self, file_path: str, checked: bool):
        """Check or uncheck a file"""
        from src.features.file_management.commands import CheckFile
        self.execute_command("file_management", CheckFile(file_path=file_path, checked=checked))
    
    @pyqtSlot(str)
    def set_system_prompt(self, content: str):
        """Set system prompt content"""
        from src.features.prompt_builder.commands import SetSystemPrompt
        self.execute_command("prompt_builder", SetSystemPrompt(content=content))
    
    @pyqtSlot(str)
    def set_user_prompt(self, content: str):
        """Set user prompt content"""
        from src.features.prompt_builder.commands import SetUserPrompt
        self.execute_command("prompt_builder", SetUserPrompt(content=content))
    
    @pyqtSlot()
    def build_prompt(self, callback: Optional[Callable] = None):
        """Build the final prompt"""
        from src.features.prompt_builder.commands import BuildPrompt
        self.execute_command("prompt_builder", BuildPrompt(), callback)
    
    @pyqtSlot(str, str)
    def calculate_tokens(self, text: str, model: str = "gpt-4"):
        """Calculate tokens for text"""
        from src.features.tokens.commands import CalculateTokens
        self.execute_command("tokens", CalculateTokens(text=text, model=model))


======== src\ui\controllers\main_controller.py ========
"""FAH-based main controller - manages main window operations using FAH architecture"""
import logging
from typing import Optional, Dict, Any
from PyQt6.QtCore import QObject, pyqtSignal, pyqtSlot
from PyQt6.QtWidgets import QFileDialog, QMessageBox
from ..bridges.fah_bridge import FAHBridge

logger = logging.getLogger(__name__)


class MainController(QObject):
    """Main controller using FAH architecture"""
    
    # Signals
    project_folder_changed = pyqtSignal(str)
    prompt_built = pyqtSignal(str)
    tokens_calculated = pyqtSignal(dict)
    status_message = pyqtSignal(str)
    error_occurred = pyqtSignal(str)
    
    def __init__(self, main_window):
        super().__init__()
        self.main_window = main_window
        self.bridge = FAHBridge()
        
        # Connect bridge signals
        self.bridge.command_completed.connect(self._handle_command_completion)
        self.bridge.command_failed.connect(self._handle_command_failure)
        
        # Initialize application
        self._initialize_app()
    
    def _initialize_app(self):
        """Initialize the application"""
        # Load configuration
        self.bridge.load_configuration()
        
        # Set up initial state
        self.status_message.emit("Application initialized")
    
    @pyqtSlot(str, object)
    def _handle_command_completion(self, command_name: str, result: Any):
        """Handle successful command completion"""
        logger.debug(f"Command {command_name} completed: {result}")
        
        # Handle specific command results
        if command_name == "SetProjectFolder":
            if result.get("success"):
                self.project_folder_changed.emit(result.get("path", ""))
                self.status_message.emit(f"Project folder set: {result.get('path', '')}")
        
        elif command_name == "BuildPrompt":
            if result.get("success"):
                prompt = result.get("prompt", "")
                self.prompt_built.emit(prompt)
                self.status_message.emit(f"Prompt built: {result.get('length', 0)} characters")
            else:
                errors = result.get("errors", [])
                self.error_occurred.emit(f"Failed to build prompt: {', '.join(errors)}")
        
        elif command_name == "CalculateTokens":
            self.tokens_calculated.emit(result)
            self.status_message.emit(f"Tokens calculated: {result.get('tokens', 0)}")
        
        elif command_name == "LoadConfiguration":
            self.status_message.emit("Configuration loaded successfully")
    
    @pyqtSlot(str, str)
    def _handle_command_failure(self, command_name: str, error: str):
        """Handle command failure"""
        logger.error(f"Command {command_name} failed: {error}")
        self.error_occurred.emit(f"{command_name} failed: {error}")
    
    # UI action handlers
    
    @pyqtSlot()
    def select_project_folder(self):
        """Show folder selection dialog"""
        folder = QFileDialog.getExistingDirectory(
            self.main_window,
            "Select Project Folder",
            "",
            QFileDialog.Option.ShowDirsOnly
        )
        
        if folder:
            self.bridge.set_project_folder(folder)
    
    @pyqtSlot(str, bool)
    def check_file(self, file_path: str, checked: bool):
        """Check or uncheck a file"""
        from src.features.file_management.commands import CheckFile
        self.bridge.execute_command("file_management", CheckFile(file_path=file_path, checked=checked))
    
    @pyqtSlot(bool)
    def check_all_files(self, checked: bool):
        """Check or uncheck all files"""
        from src.features.file_management.commands import CheckAllFiles
        self.bridge.execute_command("file_management", CheckAllFiles(checked=checked))
    
    @pyqtSlot(str)
    def update_system_prompt(self, content: str):
        """Update system prompt content"""
        from src.features.prompt_builder.commands import SetSystemPrompt
        self.bridge.execute_command("prompt_builder", SetSystemPrompt(content=content))
    
    @pyqtSlot(str)
    def update_user_prompt(self, content: str):
        """Update user prompt content"""
        from src.features.prompt_builder.commands import SetUserPrompt
        self.bridge.execute_command("prompt_builder", SetUserPrompt(content=content))
    
    @pyqtSlot()
    def build_prompt(self):
        """Build the final prompt"""
        from src.features.prompt_builder.commands import BuildPrompt
        
        def handle_result(result):
            if result.get("success"):
                # Copy to clipboard
                prompt = result.get("prompt", "")
                clipboard = self.main_window.app.clipboard()
                clipboard.setText(prompt)
                
                # Show success message
                QMessageBox.information(
                    self.main_window,
                    "Prompt Built",
                    f"Prompt built successfully!\n"
                    f"Length: {result.get('length', 0)} characters\n"
                    f"The prompt has been copied to clipboard."
                )
        
        self.bridge.execute_command("prompt_builder", BuildPrompt(), callback=handle_result)
    
    @pyqtSlot()
    def calculate_prompt_tokens(self):
        """Calculate tokens for the current prompt"""
        from src.features.tokens.commands import CalculatePromptTokens
        
        # Get current model selection (default to gpt-4)
        model = self.main_window.token_model_combo.currentText() or "gpt-4"
        
        def handle_result(result):
            if "error" not in result:
                self.tokens_calculated.emit(result)
        
        self.bridge.execute_command(
            "tokens",
            CalculatePromptTokens(model=model),
            callback=handle_result
        )
    
    @pyqtSlot()
    def refresh_file_tree(self):
        """Refresh the file tree"""
        from src.features.file_management.commands import RefreshFileSystem
        self.bridge.execute_command("file_management", RefreshFileSystem())
        self.status_message.emit("File system refreshed")
    
    @pyqtSlot()
    def generate_directory_tree(self):
        """Generate directory tree text"""
        from src.features.file_management.commands import GetDirectoryTree, GetProjectFolder
        
        # First get the project folder
        def get_folder_callback(result):
            folder = result.get("path")
            if folder:
                # Then generate tree
                from src.features.file_management.commands import GetDirectoryTree
                self.bridge.execute_command(
                    "file_management",
                    GetDirectoryTree(root_path=folder),
                    callback=self._handle_directory_tree
                )
        
        self.bridge.execute_command(
            "file_management",
            GetProjectFolder(),
            callback=get_folder_callback
        )
    
    def _handle_directory_tree(self, result):
        """Handle directory tree generation result"""
        tree = result.get("tree", "")
        if tree:
            # Copy to clipboard
            clipboard = self.main_window.app.clipboard()
            clipboard.setText(tree)
            
            QMessageBox.information(
                self.main_window,
                "Directory Tree",
                "Directory tree has been copied to clipboard!"
            )
    
    @pyqtSlot()
    def save_state(self):
        """Save application state"""
        from src.features.state.commands import SaveState
        self.bridge.execute_command("state", SaveState())
        self.status_message.emit("State saved")
    
    @pyqtSlot()
    def load_last_state(self):
        """Load last saved state"""
        from src.features.state.commands import LoadLastState
        self.bridge.execute_command("state", LoadLastState())
        self.status_message.emit("Last state loaded")
    
    def shutdown(self):
        """Cleanup on shutdown"""
        # Save state before shutdown
        self.save_state()
        
        # Shutdown bridge
        self.bridge.shutdown()



======== src\ui\models\__init__.py ========
# This file makes Python treat the directory models as a package.



======== src\ui\models\file_system_models.py ========
import os
import fnmatch
from PyQt6.QtCore import QSortFilterProxyModel, Qt, QModelIndex, QFileInfo, QAbstractItemModel, pyqtSignal
from PyQt6.QtGui import QStandardItemModel, QStandardItem, QIcon, QColor, QBrush
from PyQt6.QtWidgets import QTreeView, QApplication, QStyle
from typing import Callable, Optional, Set, List, Dict, Any
from src.features.file_management.organisms.file_system_service import FileSystemService
from src.features.file_management.molecules.file_tree_builder import FileTreeNode
import logging

logger = logging.getLogger(__name__)

# --- Constants ---
NODE_ROLE = Qt.ItemDataRole.UserRole + 1 # Role to store FileTreeNode reference
PATH_ROLE = Qt.ItemDataRole.UserRole + 2 # Role to store absolute path

# --- Cached File System Model (using QStandardItemModel) ---
class CachedFileSystemModel(QStandardItemModel):
    """
    A model based on QStandardItemModel that displays the cached directory structure.
    It gets populated/updated by the FileSystemService.
    """
    # Signal emitted when the model needs to be repopulated
    request_repopulation = pyqtSignal()

    def __init__(self, parent=None):
        super().__init__(parent)
        self.setHorizontalHeaderLabels(['Name']) # Single column for name/icon
        self._icon_provider = QApplication.style() # Use application style for default icons
        self._folder_icon = self._icon_provider.standardIcon(QStyle.StandardPixmap.SP_DirIcon)
        self._file_icon = self._icon_provider.standardIcon(QStyle.StandardPixmap.SP_FileIcon)

    def populate_from_cache(self, root_node: Optional[FileTreeNode]):
        """
        Clears the model and populates it from the FileTreeNode structure.
        The root folder itself is not shown; its children are the top-level items.
        """
        self.clear()
        self.setHorizontalHeaderLabels(['Name']) # Reset header after clear
        if root_node:
            self._populate_children(self.invisibleRootItem(), root_node)
        logger.info("CachedFileSystemModel populated from cache.")

    def _populate_children(self, parent_item: QStandardItem, parent_node: FileTreeNode):
        """Recursively populates children items."""
        # Sort children by name (directories first, then files)
        sorted_children = sorted(parent_node.children, key=lambda node: (not node.is_dir, node.name.lower()))

        for child_node in sorted_children:
            child_item = self._create_item_from_node(child_node)
            parent_item.appendRow(child_item)
            if child_node.is_dir:
                self._populate_children(child_item, child_node)

    def _create_item_from_node(self, node: FileTreeNode) -> QStandardItem:
        """Creates a QStandardItem from a FileTreeNode."""
        item = QStandardItem(node.name)
        item.setEditable(False)
        item.setData(node, NODE_ROLE) # Store the node object
        item.setData(str(node.path), PATH_ROLE) # Store the path string
        item.setIcon(self._folder_icon if node.is_dir else self._file_icon)
        # Set checkable flag (proxy model will handle actual check state)
        item.setCheckable(True)
        item.setCheckState(Qt.CheckState.Unchecked) # Default to unchecked
        return item

    def find_item_by_path(self, path: str) -> Optional[QStandardItem]:
        """Finds a QStandardItem in the model by its absolute path."""
        if not path: return None
        # Iterate through all items to find the one with the matching path
        # This can be slow for very large models. Consider optimizing if needed.
        root = self.invisibleRootItem()
        queue = [root.child(i, 0) for i in range(root.rowCount())]
        while queue:
            item = queue.pop(0)
            if not item: continue
            item_path = item.data(PATH_ROLE)
            if item_path == path:
                return item
            # Add children to the queue
            for i in range(item.rowCount()):
                 child = item.child(i, 0)
                 if child: queue.append(child)
        return None

    def update_model_from_cache_change(self, cache_root: Optional[FileTreeNode]):
        """Handles cache updates from the service."""
        # For simplicity, repopulate the entire model on any cache change.
        logger.info("Received cache update signal. Repopulating model.")
        self.populate_from_cache(cache_root)


# --- Checkable Proxy Model (Adapted for CachedFileSystemModel) ---
class CheckableProxyModel(QSortFilterProxyModel):
    """
    Proxy model that provides checkable items.
    Handles recursive checking for folders and multi-selection checking.
    Works with CachedFileSystemModel.
    """
    # Signal to indicate check state dictionary has changed
    check_state_changed = pyqtSignal()

    def __init__(self, project_folder_getter: Callable[[], Optional[str]], fs_service: FileSystemService, tree_view: QTreeView, parent=None):
        super().__init__(parent)
        self.project_folder_getter = project_folder_getter
        self.fs_service = fs_service
        self.tree_view = tree_view
        self.checked_files_dict: Dict[str, bool] = {} # {file_path: bool} - Stores the check state
        self._is_setting_data = False

    def filterAcceptsRow(self, source_row: int, source_parent: QModelIndex) -> bool:
        """
        Determines if a row should be shown. In the new FAH architecture,
        the file list is pre-filtered by the FileSystemService, so this
        proxy model no longer needs to perform filtering. It just accepts all rows.
        """
        return True

    def data(self, index: QModelIndex, role: int = Qt.ItemDataRole.DisplayRole) -> Any:
        """
        Returns data for the item, including check state based on checked_files_dict.
        """
        if not index.isValid():
            return None

        if index.column() == 0 and role == Qt.ItemDataRole.CheckStateRole:
            file_path = self.mapToSource(index).data(PATH_ROLE)
            if file_path:
                is_checked = self.checked_files_dict.get(file_path, False)
                return Qt.CheckState.Checked if is_checked else Qt.CheckState.Unchecked
            return Qt.CheckState.Unchecked

        return super().data(index, role)

    def flags(self, index: QModelIndex) -> Qt.ItemFlag:
        """Returns item flags, ensuring checkable status comes from source."""
        flags = super().flags(index)
        if index.column() == 0:
            source_index = self.mapToSource(index)
            source_flags = self.sourceModel().flags(source_index)
            if source_flags & Qt.ItemFlag.ItemIsUserCheckable:
                flags |= Qt.ItemFlag.ItemIsUserCheckable
            flags |= Qt.ItemFlag.ItemIsEnabled
        return flags


    def setData(self, index: QModelIndex, value: Any, role: int = Qt.ItemDataRole.EditRole) -> bool:
        """
        Sets data for the item, handling check state changes for the proxy model's dictionary.
        Propagates changes to children based on the source model structure.
        """
        if self._is_setting_data:
            return False
        if index.column() != 0 or role != Qt.ItemDataRole.CheckStateRole:
            return super().setData(index, value, role)

        source_index = self.mapToSource(index)
        source_item = self.sourceModel().itemFromIndex(source_index)
        if not source_item: return False

        file_path = source_item.data(PATH_ROLE)
        node: Optional[FileTreeNode] = source_item.data(NODE_ROLE)
        if not file_path or not node:
            logger.warning(f"setData failed: Could not get path/node for index {index.row()},{index.column()}")
            return False

        self._is_setting_data = True
        try:
            if isinstance(value, Qt.CheckState):
                new_check_state = value
            elif isinstance(value, int):
                new_check_state = Qt.CheckState(value)
            else:
                logger.warning(f"setData: Unexpected value type for CheckStateRole: {type(value)}")
                self._is_setting_data = False
                return False

            is_checked = (new_check_state == Qt.CheckState.Checked)
            current_state_in_dict = self.checked_files_dict.get(file_path, False)

            if is_checked == current_state_in_dict:
                self._is_setting_data = False
                return True

            if is_checked:
                self.checked_files_dict[file_path] = True
            elif file_path in self.checked_files_dict:
                del self.checked_files_dict[file_path]

            self.dataChanged.emit(index, index, [role])

            if node.is_dir:
                self._update_children_state_recursive(source_item, is_checked)
                if is_checked:
                    self.expand_index_recursively(index)

            self.check_state_changed.emit()
            return True

        except Exception as e:
            logger.exception(f"Error in setData for path {file_path}: {e}")
            return False
        finally:
            self._is_setting_data = False

    def _update_children_state_recursive(self, parent_source_item: QStandardItem, checked: bool) -> None:
        """
        Recursively updates the check state dictionary for children of a source item.
        """
        source_model = self.sourceModel()
        for row in range(parent_source_item.rowCount()):
            child_source_item = parent_source_item.child(row, 0)
            if not child_source_item: continue

            child_node: Optional[FileTreeNode] = child_source_item.data(NODE_ROLE)
            child_path = child_source_item.data(PATH_ROLE)

            if not child_node or not child_path: continue

            current_state_in_dict = self.checked_files_dict.get(child_path, False)
            if checked != current_state_in_dict:
                if checked:
                    self.checked_files_dict[child_path] = True
                elif child_path in self.checked_files_dict:
                    del self.checked_files_dict[child_path]

                child_source_index = source_model.indexFromItem(child_source_item)
                child_proxy_index = self.mapFromSource(child_source_index)
                if child_proxy_index.isValid():
                    self.dataChanged.emit(child_proxy_index, child_proxy_index, [Qt.ItemDataRole.CheckStateRole])

            if child_node.is_dir:
                self._update_children_state_recursive(child_source_item, checked)

    def expand_index_recursively(self, proxy_index: QModelIndex):
        """Recursively expands the given index and its children in the tree view."""
        if not proxy_index.isValid(): return
        self.tree_view.expand(proxy_index)
        child_count = self.rowCount(proxy_index)
        for row in range(child_count):
            child_proxy_idx = self.index(row, 0, proxy_index)
            if child_proxy_idx.isValid():
                 source_idx = self.mapToSource(child_proxy_idx)
                 source_item = self.sourceModel().itemFromIndex(source_idx)
                 if source_item:
                     node: Optional[FileTreeNode] = source_item.data(NODE_ROLE)
                     if node and node.is_dir:
                          self.expand_index_recursively(child_proxy_idx)


    def get_file_path_from_index(self, proxy_index: QModelIndex) -> Optional[str]:
        """Gets the file path from a proxy index by looking at the source model."""
        if not proxy_index.isValid(): return None
        source_index = self.mapToSource(proxy_index)
        if source_index.isValid():
            return self.sourceModel().data(source_index, PATH_ROLE)
        return None

    def get_all_checked_paths(self) -> List[str]:
        """Returns a list of all paths currently marked as checked in the dictionary."""
        return list(self.checked_files_dict.keys())

    def get_checked_files(self) -> List[str]:
        """
        Returns a list of checked paths that correspond to actual files.
        """
        checked_files = []
        source_model = self.sourceModel()
        if not isinstance(source_model, CachedFileSystemModel):
             logger.warning("get_checked_files: Source model not CachedFileSystemModel.")
             return []

        for path, is_checked in self.checked_files_dict.items():
            if not is_checked: continue

            item = source_model.find_item_by_path(path)
            if item:
                node: Optional[FileTreeNode] = item.data(NODE_ROLE)
                if node and not node.is_dir:
                    checked_files.append(path)
            else:
                logger.warning(f"Item not found in model for checked path: {path}. Cannot determine if it is a file.")

        return checked_files

    def update_check_states_from_dict(self):
        """Forces UI update based on the current checked_files_dict."""
        logger.debug("Updating visual check states from dictionary.")
        self.beginResetModel()
        self.endResetModel()
        logger.debug("Finished updating visual check states.")



======== src\ui\styles\__init__.py ========
"""UI styles module"""


======== src\ui\styles\font_config.py ========
"""Font configuration for the application"""
import sys
import os
import logging
from pathlib import Path
from PyQt6.QtGui import QFont, QFontDatabase
from PyQt6.QtWidgets import QApplication

logger = logging.getLogger(__name__)


class FontConfig:
    """Manages font configuration for the application"""
    
    # Platform-specific font recommendations
    FONT_FAMILIES = {
        "win32": [
            "Segoe UI",           # Modern Windows UI font
            "Microsoft YaHei UI", # Chinese support
            "Malgun Gothic",      # Korean support
            "Yu Gothic UI",       # Japanese support
            "Tahoma",            # Fallback
            "Arial"              # Last resort
        ],
        "darwin": [
            "SF Pro Text",       # macOS system font
            "Helvetica Neue",    # Classic macOS
            "Arial",            # Fallback
            "Lucida Grande"     # Legacy macOS
        ],
        "linux": [
            "Ubuntu",           # Ubuntu default
            "DejaVu Sans",      # Common Linux font
            "Liberation Sans",  # Red Hat fonts
            "Noto Sans",        # Google's universal font
            "Arial"            # Fallback
        ]
    }
    
    # Font sizes for different UI elements
    FONT_SIZES = {
        "default": 10,
        "small": 8,
        "medium": 10,
        "large": 12,
        "title": 14
    }
    
    @classmethod
    def setup_application_fonts(cls, app: QApplication):
        """Setup fonts for the entire application"""
        # First try to load the Malgun Gothic font from resources
        custom_font_loaded = cls._load_custom_font()
        
        if custom_font_loaded:
            # Use Malgun Gothic as the default font
            default_font = QFont("Malgun Gothic")
            default_font.setPointSize(cls.FONT_SIZES["default"])
            default_font.setStyleHint(QFont.StyleHint.SansSerif)
            default_font.setWeight(QFont.Weight.Normal)
            
            # Apply to application
            app.setFont(default_font)
            logger.info(f"Application font set to: Malgun Gothic ({default_font.pointSize()}pt)")
        else:
            # Fallback to platform-specific fonts
            platform = sys.platform
            if platform not in cls.FONT_FAMILIES:
                platform = "linux"  # Default to Linux fonts
            
            font_families = cls.FONT_FAMILIES[platform]
            
            # Find the first available font
            default_font = cls._find_available_font(font_families)
            
            # Configure the font
            default_font.setPointSize(cls.FONT_SIZES["default"])
            default_font.setStyleHint(QFont.StyleHint.SansSerif)
            default_font.setWeight(QFont.Weight.Normal)
            
            # Apply to application
            app.setFont(default_font)
            
            logger.info(f"Application font set to: {default_font.family()} ({default_font.pointSize()}pt)")
        
        # Log available fonts for debugging
        cls._log_available_fonts()
    
    @classmethod
    def _find_available_font(cls, font_families: list) -> QFont:
        """Find the first available font from the list"""
        # In PyQt6, QFontDatabase is used as static methods
        available_families = QFontDatabase.families()
        
        for family in font_families:
            if family in available_families:
                font = QFont(family)
                # In PyQt6, we check if the font family was actually set
                if font.family() == family:
                    logger.debug(f"Found exact match for font: {family}")
                    return font
        
        # If no exact match, try partial match
        for family in font_families:
            for available in available_families:
                if family.lower() in available.lower():
                    font = QFont(available)
                    logger.debug(f"Found partial match: {available} for {family}")
                    return font
        
        # Last resort - use system default
        logger.warning("No preferred fonts found, using system default")
        return QFont()
    
    @classmethod
    def _load_custom_font(cls) -> bool:
        """Load custom Malgun Gothic font from resources"""
        try:
            # Find the font file path
            font_paths = [
                Path("resources/fonts/malgun.ttf"),
                Path(__file__).parent.parent.parent.parent / "resources" / "fonts" / "malgun.ttf",
                Path(os.getcwd()) / "resources" / "fonts" / "malgun.ttf"
            ]
            
            font_path = None
            for path in font_paths:
                if path.exists():
                    font_path = path
                    break
            
            if not font_path:
                logger.warning("Malgun Gothic font file not found in resources")
                return False
            
            # Load the font
            font_id = QFontDatabase.addApplicationFont(str(font_path))
            if font_id == -1:
                logger.error(f"Failed to load font from {font_path}")
                return False
            
            # Get the font family name
            font_families = QFontDatabase.applicationFontFamilies(font_id)
            if not font_families:
                logger.error("No font families found in loaded font")
                return False
            
            logger.info(f"Successfully loaded custom font: {font_families[0]} from {font_path}")
            return True
            
        except Exception as e:
            logger.error(f"Error loading custom font: {e}")
            return False
    
    @classmethod
    def _log_available_fonts(cls):
        """Log available system fonts for debugging"""
        # In PyQt6, QFontDatabase is used as static methods
        families = QFontDatabase.families()
        
        logger.debug(f"Total available font families: {len(families)}")
        
        # Log a sample of available fonts
        sample_size = min(10, len(families))
        logger.debug(f"Sample of available fonts: {families[:sample_size]}")
    
    @classmethod
    def get_font_for_element(cls, element_type: str) -> QFont:
        """Get configured font for specific UI element"""
        base_font = QApplication.font()
        
        if element_type == "title":
            font = QFont(base_font)
            font.setPointSize(cls.FONT_SIZES["title"])
            font.setWeight(QFont.Weight.Bold)
            return font
        elif element_type == "code":
            # Use monospace font for code
            font = QFont("Consolas" if sys.platform == "win32" else "Monaco" if sys.platform == "darwin" else "Monospace")
            font.setPointSize(cls.FONT_SIZES["medium"])
            font.setStyleHint(QFont.StyleHint.Monospace)
            return font
        elif element_type == "small":
            font = QFont(base_font)
            font.setPointSize(cls.FONT_SIZES["small"])
            return font
        else:
            return base_font
    
    @classmethod
    def apply_font_fixes(cls):
        """Apply platform-specific font fixes"""
        if sys.platform == "win32":
            # Windows-specific fixes
            import os
            # Disable font warnings
            os.environ['QT_LOGGING_RULES'] = 'qt.text.font.db=false'
            
            # Try to set better font rendering
            try:
                from PyQt6.QtCore import Qt
                QApplication.setAttribute(Qt.ApplicationAttribute.AA_UseHighDpiPixmaps, True)
                QApplication.setAttribute(Qt.ApplicationAttribute.AA_EnableHighDpiScaling, True)
            except:
                pass


======== src\ui\widgets\__init__.py ========
# This file makes Python treat the directory widgets as a package.



======== src\ui\widgets\check_box_delegate.py ========

# src/ui/widgets/check_box_delegate.py
from PyQt6.QtCore import Qt, QEvent, QRect, QModelIndex, QAbstractItemModel
from PyQt6.QtWidgets import QStyledItemDelegate, QApplication, QStyleOptionViewItem, QWidget, QStyle
from PyQt6.QtGui import QMouseEvent
import logging

logger = logging.getLogger(__name__)

class CheckBoxDelegate(QStyledItemDelegate):
    """
    체크박스 영역을 클릭했을 때만 체크 상태 토글을 처리하는 Delegate
    """
    def __init__(self, parent: QWidget = None):
        super().__init__(parent)

    def editorEvent(self, event: QEvent, model: QAbstractItemModel, option: QStyleOptionViewItem, index: QModelIndex) -> bool:
        """
        마우스 클릭 이벤트를 처리하여 체크박스 영역 클릭 시 모델 데이터를 업데이트합니다.
        """
        # 체크박스는 0번 컬럼에만 있으니, 그 외 컬럼은 기본 동작
        if index.column() != 0:
            return super().editorEvent(event, model, option, index)

        # 마우스 릴리즈 이벤트이고, 왼쪽 버튼일 때만 반응
        if event.type() == QEvent.Type.MouseButtonRelease and isinstance(event, QMouseEvent) and event.button() == Qt.MouseButton.LeftButton:
            # 체크박스 사각영역 계산
            style = QApplication.style() if self.parent() is None else self.parent().style()
            cb_rect = style.subElementRect(QStyle.SubElement.SE_ItemViewItemCheckIndicator, option, self.parent())

            # 마우스 클릭 위치가 체크박스 내부라면
            if cb_rect.contains(event.position().toPoint()):
                current_value = model.data(index, Qt.ItemDataRole.CheckStateRole)
                # PyQt6에서는 data()가 CheckState enum 값을 직접 반환할 수 있음
                if isinstance(current_value, Qt.CheckState):
                    current_state = current_value
                elif isinstance(current_value, int): # Fallback for integer representation
                    current_state = Qt.CheckState(current_value)
                else: # 예상치 못한 타입이면 처리 중단
                    logger.warning(f"Unexpected data type for CheckStateRole: {type(current_value)}")
                    return False

                # 체크 상태 토글
                new_state = Qt.CheckState.Unchecked if current_state == Qt.CheckState.Checked else Qt.CheckState.Checked

                # 모델 데이터 변경 시도 및 결과 로깅
                logger.debug(f"CheckBoxDelegate: Attempting setData for index {index.row()},{index.column()} with state {new_state}")
                success = model.setData(index, new_state, Qt.ItemDataRole.CheckStateRole)
                logger.debug(f"CheckBoxDelegate: setData call result: {success}")

                # setData가 성공적으로 모델 데이터를 변경했으면 True 반환
                if success:
                    return True # 이벤트 처리 완료, 다른 핸들러 호출 방지
                else:
                    # setData 실패 시 로그 남기고 기본 처리로 넘어감
                    logger.warning(f"CheckBoxDelegate: setData failed for index {index.row()},{index.column()}")
                    return False # setData 실패 시 False 반환

        # 다른 이벤트는 기본 처리
        return super().editorEvent(event, model, option, index)

    # paint 메서드는 기본 QStyledItemDelegate의 동작을 사용하므로 오버라이드 불필요
    # def paint(self, painter: QPainter, option: QStyleOptionViewItem, index: QModelIndex):
    #     super().paint(painter, option, index)




======== src\ui\widgets\custom_tab_bar.py ========

from PyQt6.QtWidgets import QTabBar, QTabWidget, QInputDialog, QMessageBox, QMainWindow # PyQt5 -> PyQt6
from PyQt6.QtCore import Qt # PyQt5 -> PyQt6
from PyQt6.QtGui import QMouseEvent # PyQt5 -> PyQt6
from .tab_manager import is_tab_deletable

class CustomTabBar(QTabBar):
    """
    Custom tab bar with features like adding new tabs, closing tabs with middle-click,
    and renaming tabs with double-click.
    """
    def __init__(self, parent: QTabWidget, main_window: QMainWindow):
        super().__init__(parent)
        self.main_window = main_window # MainWindow 참조 (새 탭 추가 시 필요)
        self.setTabsClosable(False) # 기본 닫기 버튼 숨김 (미들 클릭 사용)
        self.setMovable(True) # 탭 이동 가능
        # "+" 탭 추가 (새 탭 생성용)
        self.addTab("+")

    def mousePressEvent(self, event: QMouseEvent):
        """Handles left mouse button press for adding new tabs."""
        if event.button() == Qt.MouseButton.LeftButton: # Qt.LeftButton -> Qt.MouseButton.LeftButton
            pos = event.position().toPoint() # PyQt6: event.pos() -> event.position().toPoint()
            index = self.tabAt(pos)
            # "+" 탭 클릭 시 새 탭 추가 동작 연결
            if index >= 0 and self.tabText(index) == "+":
                # MainWindow의 메서드를 호출하여 새 탭 추가
                if hasattr(self.main_window, 'add_new_custom_tab'):
                    self.main_window.add_new_custom_tab()
                return # 이벤트 처리 완료
        super().mousePressEvent(event)

    def mouseReleaseEvent(self, event: QMouseEvent):
        """Handles middle mouse button release for closing tabs."""
        if event.button() == Qt.MouseButton.MiddleButton: # Qt.MiddleButton -> Qt.MouseButton.MiddleButton
            pos = event.position().toPoint() # PyQt6: event.pos() -> event.position().toPoint()
            index = self.tabAt(pos)
            if index >= 0:
                tab_text = self.tabText(index)
                if tab_text != "+" and is_tab_deletable(tab_text):
                    self.parentWidget().removeTab(index)
                elif tab_text != "+":
                    QMessageBox.warning(self.parentWidget(), "경고", f"'{tab_text}' 탭은 제거할 수 없습니다.")
                # "+" 탭은 아무 동작 안 함
        super().mouseReleaseEvent(event)

    def mouseDoubleClickEvent(self, event: QMouseEvent):
        """Handles left mouse button double-click for renaming tabs."""
        if event.button() == Qt.MouseButton.LeftButton: # Qt.LeftButton -> Qt.MouseButton.LeftButton
            pos = event.position().toPoint() # PyQt6: event.pos() -> event.position().toPoint()
            index = self.tabAt(pos)
            if index >= 0:
                tab_text = self.tabText(index)
                # 보호된 탭 또는 "+" 탭은 이름 변경 불가
                if tab_text != "+" and is_tab_deletable(tab_text):
                    new_name, ok = QInputDialog.getText(self.parentWidget(), "탭 이름 변경",
                                                        "새 탭 이름을 입력하세요:", text=tab_text)
                    if ok and new_name and new_name.strip():
                        new_name_stripped = new_name.strip()
                        # 보호된 이름으로 변경 불가 처리
                        if not is_tab_deletable(new_name_stripped):
                             QMessageBox.warning(self.parentWidget(), "경고", f"'{new_name_stripped}'(으)로는 변경할 수 없습니다.")
                             return
                        # 중복 탭 이름 검사
                        for i in range(self.count()):
                            if i != index and self.tabText(i) == new_name_stripped:
                                QMessageBox.warning(self.parentWidget(), "경고", f"'{new_name_stripped}' 탭이 이미 존재합니다.")
                                return
                        # 이름 변경 적용
                        self.setTabText(index, new_name_stripped)
                    elif ok:
                         QMessageBox.warning(self.parentWidget(), "경고", "탭 이름은 비워둘 수 없습니다.")
        super().mouseDoubleClickEvent(event)




======== src\ui\widgets\custom_text_edit.py ========

from PyQt6.QtWidgets import QTextEdit # PyQt5 -> PyQt6
from PyQt6.QtCore import QMimeData # PyQt5 -> PyQt6

class CustomTextEdit(QTextEdit):
    """
    Custom QTextEdit that only allows plain text pasting.
    """
    def __init__(self, parent=None):
        super().__init__(parent)

    def insertFromMimeData(self, source: QMimeData):
        """Overrides insertFromMimeData to paste only plain text."""
        if source.hasText():
            self.insertPlainText(source.text())



======== src\ui\widgets\file_tree_view.py ========
from PyQt6.QtWidgets import QTreeView, QApplication
from PyQt6.QtCore import Qt
from PyQt6.QtGui import QMouseEvent

class FileTreeView(QTreeView):
    """
    마우스 드래그로 여러 파일 선택 시 핸들링하여
    선택된 모든 파일의 체크 상태를 토글합니다.
    """
    def __init__(self, parent=None):
        super().__init__(parent)
        self._drag_start_pos = None
        self._dragging = False

    def mousePressEvent(self, event):
        if isinstance(event, QMouseEvent) and event.button() == Qt.MouseButton.LeftButton:
            self._drag_start_pos = event.pos()
            self._dragging = False
        super().mousePressEvent(event)

    def mouseMoveEvent(self, event):
        if self._drag_start_pos:
            distance = (event.pos() - self._drag_start_pos).manhattanLength()
            if distance > QApplication.startDragDistance():
                self._dragging = True
        super().mouseMoveEvent(event)

    def mouseReleaseEvent(self, event):
        if isinstance(event, QMouseEvent) and event.button() == Qt.MouseButton.LeftButton and self._dragging:
            # 드래그로 선택된 후 마우스 릴리즈 시 선택된 모든 파일 토글
            super().mouseReleaseEvent(event)
            indexes = self.selectionModel().selectedIndexes()
            # 0번 컬럼만 필터링
            col0_indexes = []
            rows = set()
            for idx in indexes:
                if idx.column() == 0 and idx.row() not in rows:
                    col0_indexes.append(idx)
                    rows.add(idx.row())
            if col0_indexes:
                first_state = self.model().data(col0_indexes[0], Qt.ItemDataRole.CheckStateRole)
                if isinstance(first_state, Qt.CheckState):
                    current_state = first_state
                elif isinstance(first_state, int):
                    current_state = Qt.CheckState(first_state)
                else:
                    return
                target_state = Qt.CheckState.Unchecked if current_state == Qt.CheckState.Checked else Qt.CheckState.Checked
                for idx in col0_indexes:
                    self.model().setData(idx, target_state, Qt.ItemDataRole.CheckStateRole)
            self._drag_start_pos = None
            self._dragging = False
        else:
            super().mouseReleaseEvent(event) 


======== src\ui\widgets\tab_manager.py ========
PROTECTED_TABS = {
    # 기본 UI 탭
    "시스템", "사용자", "파일 트리", "프롬프트 출력", "XML 입력", "Summary",
    # 기능성 탭
    "+", # 새 탭 추가 버튼
}

def is_tab_deletable(tab_name: str) -> bool:
    """Checks if a tab with the given name can be deleted or renamed by the user."""
    # 보호 목록에 없으면 삭제/이름 변경 가능
    return tab_name not in PROTECTED_TABS



======== src\ui\__init__.py ========
# This file makes Python treat the directory ui as a package.



======== src\ui\main_window.py ========
import os
import io
import logging
import datetime
from typing import Optional, List, Dict, Any
from PyQt6.QtWidgets import ( # PyQt5 -> PyQt6
    QMainWindow, QWidget, QVBoxLayout, QHBoxLayout,
    QTreeView, QTabWidget,
    QStatusBar, QPushButton, QLabel, QCheckBox,
    QAbstractItemView, QMenuBar, QSplitter, QStyleFactory, QApplication, QMenu,
    QTreeWidget, QTreeWidgetItem, QComboBox, QFileDialog, QInputDialog, QMessageBox,
    QFrame, QLineEdit, QDialog, QListWidget, QListWidgetItem, QStyle
)
from PyQt6.QtGui import QKeySequence, QIcon, QCursor, QMouseEvent, QFont, QDesktopServices, QPixmap, QImage, QAction, QKeyEvent # PyQt5 -> PyQt6, QAction, QKeyEvent 추가
from PyQt6.QtCore import Qt, QSize, QStandardPaths, QModelIndex, QItemSelection, QUrl, QThread, pyqtSignal, QObject, QBuffer, QIODevice, QTimer, QEvent # PyQt5 -> PyQt6, QEvent 추가

# FAH 아키텍처에 필요한 서비스만 import
from src.features.database.organisms.database_service import DatabaseService
from src.features.config.organisms.config_service import ConfigurationService
# ... 다른 필요한 FAH 서비스들 ...

# UI 관련 import
from src.ui.models.file_system_models import CachedFileSystemModel, CheckableProxyModel
from src.ui.widgets.custom_text_edit import CustomTextEdit
from src.ui.widgets.custom_tab_bar import CustomTabBar
from src.utils.helpers import get_resource_path
from src.utils.notifications import show_notification

# Pillow import 시도
try:
    from PIL import Image
    from PIL.ImageQt import ImageQt
    _PILLOW_AVAILABLE = True
except ImportError:
    _PILLOW_AVAILABLE = False

# 로거 설정
logger = logging.getLogger(__name__)

class MainWindow(QMainWindow):
    # 자동 저장 타이머 시그널
    state_changed_signal = pyqtSignal()

    def __init__(self):
        super().__init__()
        self._initialized = False
        self.base_title = "DuckPrompt"
        self.update_window_title()

        QApplication.setStyle(QStyleFactory.create("Fusion"))

        # --- 상태 변수 ---
        self.current_project_folder: Optional[str] = None
        self.last_generated_prompt: str = ""
        self.attached_items: List[Dict[str, Any]] = []
        self.api_call_start_time: Optional[datetime.datetime] = None
        self.api_timer = QTimer(self)
        self.api_timer.timeout.connect(self._update_api_elapsed_time)

        # --- 자동 저장 타이머 ---
        self.auto_save_timer = QTimer(self)
        self.auto_save_timer.setInterval(30000)
        self.auto_save_timer.setSingleShot(True)
        self.auto_save_timer.timeout.connect(self.save_state_to_default_handler) # 핸들러 연결

        # --- UI 구성 ---
        # UI 생성 로직은 외부 모듈로 분리 (가정)
        # from .main_window_setup_ui import create_menu_bar, create_widgets, create_layout, create_status_bar
        # create_menu_bar(self)
        # create_widgets(self)
        # create_layout(self)
        # create_status_bar(self)
        # 참고: 실제로는 이 파일에 UI 생성 코드가 모두 포함되어 있음.
        # 여기서는 설명을 위해 분리된 것처럼 가정합니다.
        # 기존 코드에서 UI 생성 부분을 그대로 가져옵니다.
        self.setup_ui() # UI 생성 메서드 호출

        # 시그널 연결 (새로운 FAH 컨트롤러에 연결하는 로직은 app.py에서 처리)
        # 자동 저장 타이머 시그널만 내부적으로 연결
        self.state_changed_signal.connect(self.restart_auto_save_timer)

        self._initialized = True
        self.restart_auto_save_timer()

    def setup_ui(self):
        """
        UI 위젯을 생성하고 레이아웃을 설정합니다.
        이 메서드는 main_window_setup_ui.py와 main_window_setup_layout.py의 내용을 통합합니다.
        """
        # --- 메뉴바 ---
        self.menubar = QMenuBar(self)
        self.setMenuBar(self.menubar)
        state_menu = self.menubar.addMenu("상태")
        self.export_state_action = QAction("상태 내보내기", self)
        self.import_state_action = QAction("상태 가져오기", self)
        state_menu.addAction(self.export_state_action)
        state_menu.addAction(self.import_state_action)
        help_menu = self.menubar.addMenu("도움말")
        open_readme_action = QAction("README 열기", self)
        open_readme_action.triggered.connect(self._open_readme)
        help_menu.addAction(open_readme_action)

        # --- 위젯 ---
        self.reset_program_btn = QPushButton("🗑️ 전체 프로그램 리셋")
        self.load_previous_work_btn = QPushButton("⏪ 마지막 작업 불러오기")
        self.save_current_work_btn = QPushButton("💾 현재 작업 저장")
        self.select_project_btn = QPushButton("📁 프로젝트 폴더 선택")
        self.project_folder_label = QLabel("현재 프로젝트 폴더: (선택 안 됨)")

        self.cached_model = CachedFileSystemModel()
        self.tree_view = QTreeView()
        # CheckableProxyModel 초기화는 컨트롤러에서 수행되거나 app.py에서 주입받아야 함
        # 여기서는 일단 생성만 해둠
        self.checkable_proxy = CheckableProxyModel(lambda: self.current_project_folder, None, self.tree_view)
        self.checkable_proxy.setSourceModel(self.cached_model)
        self.tree_view.setModel(self.checkable_proxy)
        self.tree_view.setSelectionMode(QAbstractItemView.SelectionMode.ExtendedSelection)
        self.tree_view.setContextMenuPolicy(Qt.ContextMenuPolicy.CustomContextMenu)

        self.attachment_group = QGroupBox("첨부 파일")
        attachment_layout = QVBoxLayout(self.attachment_group)
        self.attach_file_btn = QPushButton("📎 파일 첨부")
        self.paste_clipboard_btn = QPushButton("📋 클립보드 붙여넣기")
        self.remove_attachment_btn = QPushButton("➖ 선택 제거")
        btn_layout = QHBoxLayout()
        btn_layout.addWidget(self.attach_file_btn)
        btn_layout.addWidget(self.paste_clipboard_btn)
        btn_layout.addWidget(self.remove_attachment_btn)
        self.attachment_list_widget = QListWidget()
        attachment_layout.addLayout(btn_layout)
        attachment_layout.addWidget(self.attachment_list_widget)

        self.build_tabs = QTabWidget()
        self.build_tabs.setTabBar(CustomTabBar(self.build_tabs, self))
        self.system_tab = CustomTextEdit()
        self.user_tab = CustomTextEdit()
        self.dir_structure_tab = CustomTextEdit()
        self.prompt_output_tab = CustomTextEdit()
        self.xml_input_tab = CustomTextEdit()
        self.summary_tab = CustomTextEdit()
        self.build_tabs.addTab(self.system_tab, "시스템")
        self.build_tabs.addTab(self.user_tab, "사용자")
        self.build_tabs.addTab(self.dir_structure_tab, "파일 트리")
        self.build_tabs.addTab(self.prompt_output_tab, "프롬프트 출력")
        self.build_tabs.addTab(self.xml_input_tab, "XML/DMP 입력")
        self.build_tabs.addTab(self.summary_tab, "Summary")

        self.generate_tree_btn = QPushButton("🌳 트리 생성")
        self.generate_btn = QPushButton("✨ 프롬프트 생성")
        self.send_to_gemini_btn = QPushButton("♊ Gemini로 전송")
        self.copy_btn = QPushButton("📋 클립보드에 복사")
        self.run_xml_parser_btn = QPushButton("▶️ DMP 파서 실행")
        self.generate_all_btn = QPushButton("⚡️ 한번에 실행")
        self.run_buttons = [self.generate_tree_btn, self.generate_btn, self.send_to_gemini_btn, self.copy_btn, self.run_xml_parser_btn, self.generate_all_btn]
        
        self.llm_combo = QComboBox(); self.llm_combo.addItems(["Gemini", "Claude", "GPT"])
        self.model_name_combo = QComboBox(); self.model_name_combo.setEditable(True)
        self.gemini_param_widget = QWidget()
        gemini_param_layout = QHBoxLayout(self.gemini_param_widget)
        self.gemini_temp_edit = QLineEdit()
        self.gemini_thinking_checkbox = QCheckBox()
        self.gemini_budget_edit = QLineEdit()
        self.gemini_search_checkbox = QCheckBox()
        self.gemini_dmp_checkbox = QCheckBox()
        gemini_param_layout.addWidget(QLabel("Temp:"))
        gemini_param_layout.addWidget(self.gemini_temp_edit)
        gemini_param_layout.addWidget(QLabel("Search:"))
        gemini_param_layout.addWidget(self.gemini_search_checkbox)
        gemini_param_layout.addWidget(QLabel("DMP:"))
        gemini_param_layout.addWidget(self.gemini_dmp_checkbox)
        gemini_param_layout.addWidget(QLabel("Thinking:"))
        gemini_param_layout.addWidget(self.gemini_thinking_checkbox)
        gemini_param_layout.addWidget(QLabel("Budget:"))
        gemini_param_layout.addWidget(self.gemini_budget_edit)
        
        # --- 레이아웃 ---
        central_widget = QWidget()
        self.setCentralWidget(central_widget)
        main_layout = QVBoxLayout(central_widget)
        top_buttons_layout = QHBoxLayout()
        top_buttons_layout.addWidget(self.reset_program_btn)
        top_buttons_layout.addWidget(self.load_previous_work_btn)
        top_buttons_layout.addWidget(self.save_current_work_btn)
        top_buttons_layout.addWidget(self.select_project_btn)
        top_buttons_layout.addStretch(1)
        main_layout.addLayout(top_buttons_layout)
        main_layout.addWidget(self.project_folder_label)
        llm_params_layout = QHBoxLayout()
        llm_params_layout.addWidget(QLabel("Model:"))
        llm_params_layout.addWidget(self.llm_combo)
        llm_params_layout.addWidget(self.model_name_combo)
        llm_params_layout.addWidget(self.gemini_param_widget)
        llm_params_layout.addStretch(1)
        main_layout.addLayout(llm_params_layout)
        
        self.center_splitter = QSplitter(Qt.Orientation.Horizontal)
        left_panel = QWidget()
        left_layout = QVBoxLayout(left_panel)
        left_splitter = QSplitter(Qt.Orientation.Vertical)
        left_splitter.addWidget(self.tree_view)
        left_splitter.addWidget(self.attachment_group)
        left_layout.addWidget(left_splitter)
        self.center_splitter.addWidget(left_panel)
        
        right_panel = QWidget()
        right_layout = QVBoxLayout(right_panel)
        right_top_widget = QWidget()
        right_top_layout = QVBoxLayout(right_top_widget)
        run_buttons_layout = QHBoxLayout()
        for btn in self.run_buttons:
            run_buttons_layout.addWidget(btn)
        right_top_layout.addLayout(run_buttons_layout)
        right_top_layout.addWidget(self.build_tabs, 1)
        right_layout.addWidget(right_top_widget)
        self.center_splitter.addWidget(right_panel)
        
        main_layout.addWidget(self.center_splitter, 1)

        # --- 상태바 ---
        self.status_bar = QStatusBar()
        self.setStatusBar(self.status_bar)
        self.char_count_label = QLabel("Chars: 0")
        self.token_count_label = QLabel("토큰 계산: -")
        self.api_time_label = QLabel("API 시간: -")
        self.status_bar.addPermanentWidget(self.api_time_label)
        self.status_bar.addPermanentWidget(self.token_count_label)
        self.status_bar.addPermanentWidget(self.char_count_label)

    def _open_readme(self):
        readme_path = str(Path(__file__).parent.parent.parent / "README.md")
        if os.path.exists(readme_path):
            QDesktopServices.openUrl(QUrl.fromLocalFile(readme_path))
        else:
            QMessageBox.warning(self, "오류", "README.md 파일을 찾을 수 없습니다.")

    def update_window_title(self, folder_name: Optional[str] = None):
        title = f"{folder_name} - {self.base_title}" if folder_name else self.base_title
        self.setWindowTitle(title)

    def _update_api_elapsed_time(self):
        if self.api_call_start_time and hasattr(self, 'api_time_label'):
            elapsed = datetime.datetime.now() - self.api_call_start_time
            self.api_time_label.setText(f"API 경과: {str(elapsed).split('.')[0]}")

    def save_state_to_default_handler(self):
        # This is a placeholder. The actual logic is now in FAHMainController.
        # This could emit a signal that the controller listens to.
        logger.debug("Auto-save triggered. In a full FAH app, this would be handled by the controller.")
        pass

    def restart_auto_save_timer(self):
        if self._initialized:
            self.auto_save_timer.start(30000)

    def closeEvent(self, event):
        logger.info("Closing MainWindow.")
        self.auto_save_timer.stop()
        self.api_timer.stop()
        # Additional cleanup can be handled by the controller's shutdown method.
        super().closeEvent(event)



======== src\utils\__init__.py ========

# This file makes Python treat the directory utils as a package.

from .helpers import get_project_root, get_resource_path, calculate_char_count
from .notifications import show_notification

__all__ = [
    "get_project_root",
    "get_resource_path",
    "calculate_char_count",
    "show_notification",
]



======== src\utils\db_migration_script.py ========

import psycopg2
import logging
from typing import Dict, Any, Optional, List

# --- Database Connection Details (from db_service.py or environment) ---
DB_HOST = "postgresdb.lab.miraker.me"
DB_PORT = 5333
DB_NAME = "duck_agent"
DB_USER = "shacea"
DB_PASSWORD = "alfkzj9389" # Warning: Hardcoded password

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

def run_migration():
    """Performs the database migration: adds usage columns to api_keys, migrates data, drops api_key_usage."""
    conn = None
    try:
        # 1. Connect to the database
        logger.info(f"Connecting to database {DB_NAME} at {DB_HOST}:{DB_PORT}...")
        conn = psycopg2.connect(
            host=DB_HOST,
            port=DB_PORT,
            dbname=DB_NAME,
            user=DB_USER,
            password=DB_PASSWORD
        )
        conn.autocommit = False # Start transaction
        logger.info("Database connection successful.")
        cur = conn.cursor()

        # 2. Add new columns to api_keys table if they don't exist
        logger.info("Adding usage tracking columns to api_keys table (if they don't exist)...")
        columns_to_add = [
            ("last_api_call_timestamp", "TIMESTAMPTZ", "NULL"),
            ("calls_this_minute", "INTEGER", "NOT NULL DEFAULT 0"),
            ("minute_start_timestamp", "TIMESTAMPTZ", "NULL"),
            ("calls_this_day", "INTEGER", "NOT NULL DEFAULT 0"),
            ("day_start_timestamp", "TIMESTAMPTZ", "NULL")
        ]
        for col_name, col_type, col_constraint in columns_to_add:
            try:
                alter_sql = f"ALTER TABLE api_keys ADD COLUMN IF NOT EXISTS {col_name} {col_type} {col_constraint};"
                logger.debug(f"Executing: {alter_sql}")
                cur.execute(alter_sql)
                logger.info(f"Column '{col_name}' added or already exists in api_keys.")
            except psycopg2.Error as e:
                logger.error(f"Error adding column '{col_name}' to api_keys: {e}")
                raise # Stop migration if altering fails

        # 3. Check if api_key_usage table exists before attempting migration
        cur.execute("SELECT EXISTS (SELECT FROM information_schema.tables WHERE table_name = 'api_key_usage');")
        usage_table_exists = cur.fetchone()[0]

        if usage_table_exists:
            logger.info("api_key_usage table exists. Migrating data...")

            # 4. Fetch data from api_key_usage
            logger.info("Fetching data from api_key_usage table...")
            try:
                cur.execute("""
                    SELECT api_key_id, last_api_call_timestamp, calls_this_minute,
                           minute_start_timestamp, calls_this_day, day_start_timestamp
                    FROM api_key_usage;
                """)
                usage_data = cur.fetchall()
                logger.info(f"Fetched {len(usage_data)} rows from api_key_usage.")
            except psycopg2.Error as e:
                logger.error(f"Error fetching data from api_key_usage: {e}")
                raise

            # 5. Update api_keys table with migrated data
            logger.info("Updating api_keys table with migrated usage data...")
            update_count = 0
            for row in usage_data:
                key_id, last_call, calls_min, min_start, calls_day, day_start = row
                try:
                    update_sql = """
                        UPDATE api_keys
                        SET last_api_call_timestamp = %s,
                            calls_this_minute = %s,
                            minute_start_timestamp = %s,
                            calls_this_day = %s,
                            day_start_timestamp = %s,
                            updated_at = NOW()
                        WHERE id = %s;
                    """
                    cur.execute(update_sql, (last_call, calls_min, min_start, calls_day, day_start, key_id))
                    if cur.rowcount == 1:
                        update_count += 1
                    else:
                        logger.warning(f"API key ID {key_id} not found in api_keys table during migration update.")
                except psycopg2.Error as e:
                    logger.error(f"Error updating api_keys for key_id {key_id}: {e}")
                    # Decide whether to continue or stop on error
                    # raise # Uncomment to stop on first error
            logger.info(f"Successfully updated {update_count} rows in api_keys with usage data.")

            # 6. Drop the api_key_usage table
            logger.info("Dropping api_key_usage table...")
            try:
                cur.execute("DROP TABLE IF EXISTS api_key_usage;")
                logger.info("api_key_usage table dropped successfully.")
            except psycopg2.Error as e:
                logger.error(f"Error dropping api_key_usage table: {e}")
                raise
        else:
            logger.info("api_key_usage table does not exist. Skipping data migration and table drop.")

        # 7. Commit transaction
        conn.commit()
        logger.info("Database migration completed successfully.")

    except (Exception, psycopg2.Error) as error:
        logger.error(f"Database migration failed: {error}", exc_info=True)
        if conn:
            conn.rollback()
            logger.info("Transaction rolled back.")
    finally:
        if conn:
            cur.close()
            conn.close()
            logger.info("Database connection closed.")

if __name__ == "__main__":
    run_migration()



======== src\utils\helpers.py ========
import os
import sys
# import tiktoken # No longer directly used here, moved to TokenCalculationService
from typing import Union, Optional
# import threading # No longer needed for preloading here
from pathlib import Path # pathlib 사용

# --- 경로 관련 ---
def get_project_root() -> Path:
    """Gets the project root directory reliably."""
    if getattr(sys, 'frozen', False) and hasattr(sys, '_MEIPASS'):
        # PyInstaller 번들 환경
        return Path(sys._MEIPASS)
    else:
        # 개발 환경 (main.py 또는 src/app.py에서 실행 가정)

        src_dir = Path(__file__).parent.parent.resolve()
        # 프로젝트 루트는 src 폴더의 부모
        return src_dir.parent

def get_resource_path(relative_path: str) -> str:
    """
    Gets the absolute path to a resource file/directory.
    Assumes the 'resources' directory is at the project root.
    """
    project_root = get_project_root()
    resource_path = project_root / "resources" / relative_path
    return str(resource_path)

# --- 텍스트 계산 관련 ---
def calculate_char_count(text: str) -> int:
    """Calculates the number of characters in the text."""
    return len(text)

# calculate_token_count is now handled by TokenCalculationService
# def calculate_token_count(text: str) -> Optional[int]:
#     """
#     Calculates the number of tokens using the preloaded tiktoken encoding.
#     Returns None if encoding is not available or an error occurs.
#     """
#     # ... (old implementation removed) ...

# init_utils and preload_encoding are removed as tiktoken loading is now
# handled within TokenCalculationService when needed.
# def preload_encoding():
#     """Preloads the tiktoken encoding in a separate thread."""
#     # ... (old implementation removed) ...

# def init_utils():
#     """Initializes utility functions, including preloading encoding."""
#     # ... (old implementation removed) ...

# def get_encoding() -> Optional[tiktoken.Encoding]:
#     """Returns the preloaded tiktoken encoding, loading if necessary."""
#     # ... (old implementation removed) ...



======== src\utils\notifications.py ========
import logging
import os
from typing import Optional

# 애플리케이션 이름 전역 변수
_APP_NAME = "DuckPrompt"

# winotify import 시도
try:
    from winotify import Notification
    # winotify는 기본적으로 Windows에서만 작동합니다.
    _WINOTIFY_AVAILABLE = os.name == 'nt'
except ImportError:
    _WINOTIFY_AVAILABLE = False
    logging.warning("winotify library not found or OS is not Windows. Desktop notifications will be disabled.")

# helpers에서 아이콘 경로 함수 가져오기
from .helpers import get_resource_path

logger = logging.getLogger(__name__)

def show_notification(title: str, message: str, app_name: str = None, timeout: Optional[int] = None):
    """
    Displays a desktop notification using winotify (Windows only).

    Args:
        title: The title of the notification.
        message: The main message content of the notification.
        app_name: The name of the application sending the notification.
        timeout: Duration in seconds (winotify doesn't directly support timeout, Windows setting applies).
    """
    if not _WINOTIFY_AVAILABLE:
        logger.warning(f"Notification not shown (winotify unavailable or not Windows): Title='{title}', Message='{message[:50]}...'")
        return

    try:
        logger.info(f"Showing notification via winotify: Title='{title}', Message='{message[:50]}...'")

        # 아이콘 경로 가져오기
        icon_path = ""
        try:
            icon_path = get_resource_path("icons/rubber_duck.ico")
            if not os.path.exists(icon_path):
                logger.warning(f"Notification icon not found at: {icon_path}")
                icon_path = "" # 아이콘 경로 없으면 빈 문자열로 설정
        except Exception as e:
            logger.error(f"Error getting notification icon path: {e}")
            icon_path = ""

        # 애플리케이션 이름 설정
        notification_app_name = app_name if app_name else _APP_NAME

        # winotify Notification 객체 생성
        toast = Notification(
            app_id=notification_app_name,
            title=title,
            msg=message,
            icon=icon_path if icon_path else None  # 아이콘 경로 설정 (없으면 None)
        )

        # 알림 표시
        toast.show()
        logger.info("winotify notification shown successfully.")

    except Exception as e:
        logger.error(f"Failed to show winotify notification: {e}", exc_info=True)

# Example usage (for testing):
if __name__ == '__main__':
    logging.basicConfig(level=logging.INFO)
    print("Testing winotify notification...")
    if _WINOTIFY_AVAILABLE:
        show_notification("Test Notification", "This is a test message from notifications.py using winotify.")
        print("Notification test finished.")
    else:
        print("winotify is not available on this system (requires Windows and winotify library).")




======== src\utils\postgres_db_initializer.py ========

import psycopg2
import os
import yaml # YAML 파싱을 위해 추가
from pathlib import Path
from datetime import datetime
from typing import Dict, Any, Optional, List # 타입 힌트 추가

# --- Database Connection Details ---
# 환경 변수나 보안 관리 도구를 사용하는 것이 좋습니다.
DB_HOST = "postgresdb.lab.miraker.me"
DB_PORT = 5333
DB_NAME = "duck_agent"
DB_USER = "shacea"
DB_PASSWORD = "alfkzj9389" # 경고: 실제 비밀번호

# --- Project Root and Config File Path ---
# helpers.py의 get_project_root()를 사용하여 프로젝트 루트를 찾습니다.
# 이 파일이 src/utils/ 에 있으므로, 프로젝트 루트는 두 단계 위입니다.
try:
    PROJECT_ROOT = Path(__file__).parent.parent.parent.resolve()
except NameError:
    # __file__이 정의되지 않은 경우 (예: 인터프리터에서 직접 실행)
    PROJECT_ROOT = Path('.').resolve()

CONFIG_FILE_PATH = PROJECT_ROOT / "src" / "config.yml"


# --- SQL Schema Definition ---
# api_key_usage 테이블 제거, api_keys 테이블에 사용량 컬럼 추가
SCHEMA_SQL = """
-- 타임스탬프 자동 업데이트를 위한 함수 생성 (존재하지 않을 경우)
CREATE OR REPLACE FUNCTION trigger_set_timestamp()
RETURNS TRIGGER AS $$
BEGIN
  NEW.updated_at = NOW();
  RETURN NEW;
END;
$$ LANGUAGE plpgsql;

-- 기존 테이블 삭제 (스크립트를 여러 번 실행할 경우) - 주의: 데이터 손실 발생
-- DROP TABLE IF EXISTS application_config CASCADE;
-- DROP TABLE IF EXISTS model_rate_limits CASCADE;
-- DROP TABLE IF EXISTS api_keys CASCADE;
-- DROP TABLE IF EXISTS gemini_api_logs CASCADE;

-- ==== API 키 테이블 (사용량 컬럼 추가) ====
-- 테이블이 존재하지 않을 경우에만 생성 (IF NOT EXISTS 추가)
CREATE TABLE IF NOT EXISTS api_keys (
    id SERIAL PRIMARY KEY,
    api_key TEXT NOT NULL UNIQUE,
    provider TEXT NOT NULL DEFAULT 'google',
    description TEXT,
    is_active BOOLEAN NOT NULL DEFAULT TRUE,
    -- Usage tracking columns added
    last_api_call_timestamp TIMESTAMPTZ,
    calls_this_minute INTEGER NOT NULL DEFAULT 0,
    minute_start_timestamp TIMESTAMPTZ,
    calls_this_day INTEGER NOT NULL DEFAULT 0,
    day_start_timestamp TIMESTAMPTZ,
    -- Timestamps
    created_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
    updated_at TIMESTAMPTZ NOT NULL DEFAULT NOW()
);

-- 트리거가 존재하지 않을 경우에만 생성
DO $$
BEGIN
    IF NOT EXISTS (SELECT 1 FROM pg_trigger WHERE tgname = 'set_api_keys_timestamp') THEN
        CREATE TRIGGER set_api_keys_timestamp
        BEFORE UPDATE ON api_keys
        FOR EACH ROW
        EXECUTE FUNCTION trigger_set_timestamp();
    END IF;
END $$;

COMMENT ON TABLE api_keys IS 'Stores individual API keys, their metadata, and usage tracking.';
COMMENT ON COLUMN api_keys.api_key IS 'The actual API key string. Sensitive data.';
COMMENT ON COLUMN api_keys.provider IS 'The provider of the API key (e.g., google, anthropic).';
COMMENT ON COLUMN api_keys.description IS 'User-friendly description for the key.';
COMMENT ON COLUMN api_keys.is_active IS 'Flag to enable/disable the key for use.';
COMMENT ON COLUMN api_keys.last_api_call_timestamp IS 'Timestamp of the last successful API call using this key.';
COMMENT ON COLUMN api_keys.calls_this_minute IS 'Counter for calls made within the current minute window.';
COMMENT ON COLUMN api_keys.minute_start_timestamp IS 'Timestamp marking the beginning of the current minute window for rate limiting.';
COMMENT ON COLUMN api_keys.calls_this_day IS 'Counter for calls made within the current day window.';
COMMENT ON COLUMN api_keys.day_start_timestamp IS 'Timestamp marking the beginning of the current day window for rate limiting.';


-- ==== 모델별 기본 Rate Limit 테이블 ====
-- 테이블이 존재하지 않을 경우에만 생성
CREATE TABLE IF NOT EXISTS model_rate_limits (
    id SERIAL PRIMARY KEY,
    model_name TEXT NOT NULL UNIQUE,
    provider TEXT NOT NULL DEFAULT 'google',
    rpm_limit INTEGER NOT NULL,
    daily_limit INTEGER NOT NULL,
    notes TEXT,
    created_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
    updated_at TIMESTAMPTZ NOT NULL DEFAULT NOW()
);

-- 트리거가 존재하지 않을 경우에만 생성
DO $$
BEGIN
    IF NOT EXISTS (SELECT 1 FROM pg_trigger WHERE tgname = 'set_model_rate_limits_timestamp') THEN
        CREATE TRIGGER set_model_rate_limits_timestamp
        BEFORE UPDATE ON model_rate_limits
        FOR EACH ROW
        EXECUTE FUNCTION trigger_set_timestamp();
    END IF;
END $$;

COMMENT ON TABLE model_rate_limits IS 'Stores default rate limit information per model.';
COMMENT ON COLUMN model_rate_limits.model_name IS 'Identifier for the language model.';
COMMENT ON COLUMN model_rate_limits.rpm_limit IS 'Default Requests Per Minute limit for the model.';
COMMENT ON COLUMN model_rate_limits.daily_limit IS 'Default Requests Per Day limit for the model.';


-- ==== API 키 사용량 추적 테이블 (제거됨) ====
-- DROP TABLE IF EXISTS api_key_usage CASCADE;


-- ==== 애플리케이션 설정 테이블 ====
-- 테이블이 존재하지 않을 경우에만 생성
CREATE TABLE IF NOT EXISTS application_config (
    id SERIAL PRIMARY KEY,
    profile_name TEXT NOT NULL UNIQUE DEFAULT 'default',
    default_system_prompt TEXT,
    allowed_extensions TEXT[],
    excluded_dirs TEXT[],
    default_ignore_list TEXT[],
    gemini_default_model TEXT,
    claude_default_model TEXT,
    gpt_default_model TEXT,
    gemini_available_models TEXT[],
    claude_available_models TEXT[],
    gpt_available_models TEXT[],
    gemini_temperature NUMERIC(3, 2) DEFAULT 0.0,
    gemini_enable_thinking BOOLEAN DEFAULT TRUE,
    gemini_thinking_budget INTEGER DEFAULT 24576,
    gemini_enable_search BOOLEAN DEFAULT TRUE,
    created_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
    updated_at TIMESTAMPTZ NOT NULL DEFAULT NOW()
);

-- 트리거가 존재하지 않을 경우에만 생성
DO $$
BEGIN
    IF NOT EXISTS (SELECT 1 FROM pg_trigger WHERE tgname = 'set_application_config_timestamp') THEN
        CREATE TRIGGER set_application_config_timestamp
        BEFORE UPDATE ON application_config
        FOR EACH ROW
        EXECUTE FUNCTION trigger_set_timestamp();
    END IF;
END $$;

COMMENT ON TABLE application_config IS 'Stores application-wide configuration settings, replacing config.yml.';
COMMENT ON COLUMN application_config.profile_name IS 'Identifier for the configuration profile (e.g., default, development).';
COMMENT ON COLUMN application_config.allowed_extensions IS 'Array of allowed file extensions.';
COMMENT ON COLUMN application_config.excluded_dirs IS 'Array of directory/file patterns to exclude.';
COMMENT ON COLUMN application_config.default_ignore_list IS 'Array of default patterns to ignore.';
COMMENT ON COLUMN application_config.gemini_available_models IS 'Array of available Gemini model names.';
COMMENT ON COLUMN application_config.claude_available_models IS 'Array of available Claude model names.';
COMMENT ON COLUMN application_config.gpt_available_models IS 'Array of available GPT model names.';
COMMENT ON COLUMN application_config.gemini_temperature IS 'Generation temperature for Gemini models.';

-- ==== Gemini API 로그 테이블 ====
-- 테이블이 존재하지 않을 경우에만 생성
CREATE TABLE IF NOT EXISTS gemini_api_logs (
    id SERIAL PRIMARY KEY,
    request_timestamp TIMESTAMPTZ NOT NULL DEFAULT NOW(),
    response_timestamp TIMESTAMPTZ,
    model_name TEXT,
    request_prompt TEXT,
    request_attachments JSONB,
    response_text TEXT,
    response_xml TEXT,
    response_summary TEXT,
    error_message TEXT,
    elapsed_time_ms INTEGER,
    token_count INTEGER,
    api_key_id INTEGER REFERENCES api_keys(id) ON DELETE SET NULL -- FK 유지
);

-- 인덱스가 존재하지 않을 경우에만 생성
DO $$
BEGIN
    IF NOT EXISTS (SELECT 1 FROM pg_class c JOIN pg_namespace n ON n.oid = c.relnamespace WHERE c.relname = 'idx_gemini_api_logs_request_timestamp' AND n.nspname = 'public') THEN
        CREATE INDEX idx_gemini_api_logs_request_timestamp ON gemini_api_logs(request_timestamp);
    END IF;
    IF NOT EXISTS (SELECT 1 FROM pg_class c JOIN pg_namespace n ON n.oid = c.relnamespace WHERE c.relname = 'idx_gemini_api_logs_api_key_id' AND n.nspname = 'public') THEN
        CREATE INDEX idx_gemini_api_logs_api_key_id ON gemini_api_logs(api_key_id);
    END IF;
END $$;

COMMENT ON TABLE gemini_api_logs IS 'Stores logs of requests and responses to the Gemini API.';
COMMENT ON COLUMN gemini_api_logs.request_timestamp IS 'Timestamp when the request was initiated.';
COMMENT ON COLUMN gemini_api_logs.response_timestamp IS 'Timestamp when the response was received.';
COMMENT ON COLUMN gemini_api_logs.model_name IS 'The specific Gemini model used for the request.';
COMMENT ON COLUMN gemini_api_logs.request_prompt IS 'The text prompt sent to the API.';
COMMENT ON COLUMN gemini_api_logs.request_attachments IS 'JSONB data containing metadata about attached files/images (e.g., name, type, path).';
COMMENT ON COLUMN gemini_api_logs.response_text IS 'The raw text response from the Gemini API.';
COMMENT ON COLUMN gemini_api_logs.response_xml IS 'The parsed XML part of the response, if applicable.';
COMMENT ON COLUMN gemini_api_logs.response_summary IS 'The parsed summary part of the response, if applicable.';
COMMENT ON COLUMN gemini_api_logs.error_message IS 'Error message if the API call failed.';
COMMENT ON COLUMN gemini_api_logs.elapsed_time_ms IS 'Total time taken for the API call in milliseconds.';
COMMENT ON COLUMN gemini_api_logs.token_count IS 'Calculated token count for the request/response.';
COMMENT ON COLUMN gemini_api_logs.api_key_id IS 'Foreign key referencing the api_key used for the request.';

"""

def create_tables(conn):
    """Creates database tables based on the SCHEMA_SQL."""
    print("Attempting to create/update database tables...")
    try:
        with conn.cursor() as cur:
            cur.execute(SCHEMA_SQL)
        conn.commit()
        print("Tables created/updated (or already exist) successfully.")
    except psycopg2.Error as e:
        print(f"Error creating/updating tables: {e}")
        conn.rollback() # Roll back changes on error
        raise # Re-raise the exception to stop the script

def load_yaml_config(file_path: Path) -> Optional[Dict[str, Any]]:
    """Loads configuration from a YAML file."""
    if not file_path.exists():
        print(f"Error: Configuration file not found at {file_path}")
        return None
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            config = yaml.safe_load(f)
        print(f"Configuration loaded successfully from {file_path}")
        return config
    except yaml.YAMLError as e:
        print(f"Error parsing YAML file {file_path}: {e}")
        return None
    except Exception as e:
        print(f"Error reading configuration file {file_path}: {e}")
        return None

def insert_or_update_config(conn, config_data: Dict[str, Any]):
    """Inserts or updates the 'default' profile in the application_config table."""
    print("Attempting to insert/update application configuration...")
    profile_name = 'default' # Assuming we always update the default profile

    # Prepare data for insertion/update, handling potential missing keys and types
    # Convert sets from YAML (!!set) to lists for PostgreSQL TEXT[]
    allowed_extensions = list(config_data.get('allowed_extensions', set()))
    excluded_dirs = list(config_data.get('excluded_dirs', set()))
    default_ignore_list = list(config_data.get('default_ignore_list', []))
    gemini_available_models = list(config_data.get('gemini_available_models', []))
    claude_available_models = list(config_data.get('claude_available_models', []))
    gpt_available_models = list(config_data.get('gpt_available_models', []))

    # Ensure boolean values are correctly interpreted
    gemini_enable_thinking = bool(config_data.get('gemini_enable_thinking', True))
    gemini_enable_search = bool(config_data.get('gemini_enable_search', True))

    # Ensure numeric values are correctly interpreted, providing defaults
    try:
        gemini_temperature = float(config_data.get('gemini_temperature', 0.0))
    except (ValueError, TypeError):
        gemini_temperature = 0.0
    try:
        gemini_thinking_budget = int(config_data.get('gemini_thinking_budget', 24576))
    except (ValueError, TypeError):
        gemini_thinking_budget = 24576

    # SQL query using ON CONFLICT for upsert
    sql = """
        INSERT INTO application_config (
            profile_name, default_system_prompt, allowed_extensions, excluded_dirs,
            default_ignore_list, gemini_default_model, claude_default_model, gpt_default_model,
            gemini_available_models, claude_available_models, gpt_available_models,
            gemini_temperature, gemini_enable_thinking, gemini_thinking_budget, gemini_enable_search
        ) VALUES (
            %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s
        )
        ON CONFLICT (profile_name) DO UPDATE SET
            default_system_prompt = EXCLUDED.default_system_prompt,
            allowed_extensions = EXCLUDED.allowed_extensions,
            excluded_dirs = EXCLUDED.excluded_dirs,
            default_ignore_list = EXCLUDED.default_ignore_list,
            gemini_default_model = EXCLUDED.gemini_default_model,
            claude_default_model = EXCLUDED.claude_default_model,
            gpt_default_model = EXCLUDED.gpt_default_model,
            gemini_available_models = EXCLUDED.gemini_available_models,
            claude_available_models = EXCLUDED.claude_available_models,
            gpt_available_models = EXCLUDED.gpt_available_models,
            gemini_temperature = EXCLUDED.gemini_temperature,
            gemini_enable_thinking = EXCLUDED.gemini_enable_thinking,
            gemini_thinking_budget = EXCLUDED.gemini_thinking_budget,
            gemini_enable_search = EXCLUDED.gemini_enable_search,
            updated_at = NOW();
    """
    params = (
        profile_name,
        config_data.get('default_system_prompt'),
        allowed_extensions,
        excluded_dirs,
        default_ignore_list,
        config_data.get('gemini_default_model'),
        config_data.get('claude_default_model'),
        config_data.get('gpt_default_model'),
        gemini_available_models,
        claude_available_models,
        gpt_available_models,
        gemini_temperature,
        gemini_enable_thinking,
        gemini_thinking_budget,
        gemini_enable_search
    )

    try:
        with conn.cursor() as cur:
            cur.execute(sql, params)
        conn.commit()
        print(f"Application configuration for profile '{profile_name}' inserted/updated successfully.")
    except psycopg2.Error as e:
        print(f"Error inserting/updating application configuration: {e}")
        conn.rollback()
    except Exception as e:
        print(f"An unexpected error occurred during config update: {e}")
        conn.rollback()

def insert_or_update_api_key(conn, api_key: str, provider: str):
    """Inserts or updates an API key in the api_keys table."""
    if not api_key:
        print(f"Skipping API key insertion/update for {provider}: Key is empty.")
        return

    print(f"Attempting to insert/update API key for provider: {provider}...")
    # Add default NULL/0 values for new usage columns on insert
    sql = """
        INSERT INTO api_keys (api_key, provider, is_active,
                              last_api_call_timestamp, calls_this_minute, minute_start_timestamp,
                              calls_this_day, day_start_timestamp)
        VALUES (%s, %s, %s, NULL, 0, NULL, 0, NULL)
        ON CONFLICT (api_key) DO UPDATE SET
            provider = EXCLUDED.provider,
            is_active = EXCLUDED.is_active,
            -- Do not reset usage columns on conflict update here
            updated_at = NOW();
    """
    params = (api_key, provider, True) # Always set as active when loading from config

    try:
        with conn.cursor() as cur:
            cur.execute(sql, params)
        conn.commit()
        print(f"API key for provider '{provider}' inserted/updated successfully.")
    except psycopg2.Error as e:
        print(f"Error inserting/updating API key for {provider}: {e}")
        conn.rollback()
    except Exception as e:
        print(f"An unexpected error occurred during API key update for {provider}: {e}")
        conn.rollback()

def insert_or_update_rate_limit(conn, model_name: str, provider: str, rpm_limit: int, daily_limit: int, notes: Optional[str] = None):
    """Inserts or updates a model's rate limit in the model_rate_limits table."""
    print(f"Attempting to insert/update rate limit for model: {model_name}...")
    sql = """
        INSERT INTO model_rate_limits (model_name, provider, rpm_limit, daily_limit, notes)
        VALUES (%s, %s, %s, %s, %s)
        ON CONFLICT (model_name) DO UPDATE SET
            provider = EXCLUDED.provider,
            rpm_limit = EXCLUDED.rpm_limit,
            daily_limit = EXCLUDED.daily_limit,
            notes = EXCLUDED.notes,
            updated_at = NOW();
    """
    params = (model_name, provider, rpm_limit, daily_limit, notes)

    try:
        with conn.cursor() as cur:
            cur.execute(sql, params)
        conn.commit()
        print(f"Rate limit for model '{model_name}' inserted/updated successfully.")
    except psycopg2.Error as e:
        print(f"Error inserting/updating rate limit for {model_name}: {e}")
        conn.rollback()
    except Exception as e:
        print(f"An unexpected error occurred during rate limit update for {model_name}: {e}")
        conn.rollback()

def main():
    """Main function to connect, setup/update DB schema, and load config."""
    conn = None
    try:
        # 1. Connect to the database
        print(f"Connecting to database {DB_NAME} at {DB_HOST}:{DB_PORT}...")
        conn = psycopg2.connect(
            host=DB_HOST,
            port=DB_PORT,
            dbname=DB_NAME,
            user=DB_USER,
            password=DB_PASSWORD
        )
        print("Database connection successful.")

        # 2. Create/Update tables based on SCHEMA_SQL
        create_tables(conn)
        print("Database schema setup/update complete.")

        # 3. Load configuration from config.yml
        print(f"Loading configuration from: {CONFIG_FILE_PATH}")
        config = load_yaml_config(CONFIG_FILE_PATH)

        if config:
            # 4. Insert/Update application_config table
            insert_or_update_config(conn, config)

            # 5. Insert/Update api_keys table
            gemini_key = config.get('gemini_api_key')
            anthropic_key = config.get('anthropic_api_key')
            # openai_key = config.get('openai_api_key') # If needed in the future

            if gemini_key:
                insert_or_update_api_key(conn, gemini_key, 'google')
            if anthropic_key:
                insert_or_update_api_key(conn, anthropic_key, 'anthropic')
            # if openai_key:
            #     insert_or_update_api_key(conn, openai_key, 'openai')

            print("Configuration data loaded into database.")

            # 6. Insert/Update model_rate_limits table (based on user request)
            print("Inserting/Updating specific model rate limits...")
            insert_or_update_rate_limit(conn, 'gemini-2.5-pro-preview-03-25', 'google', 5, 25, 'Gemini Pro Preview Rate Limit')
            insert_or_update_rate_limit(conn, 'gemini-2.5-flash-preview-04-17', 'google', 10, 500, 'Gemini Flash Preview Rate Limit')
            print("Model rate limits updated.")

        else:
            print("Skipping database update due to configuration loading failure.")

    except psycopg2.OperationalError as e:
        print(f"Database connection failed: {e}")
    except Exception as e:
        print(f"An unexpected error occurred: {e}")
    finally:
        if conn:
            conn.close()
            print("Database connection closed.")

if __name__ == "__main__":
    main()




======== src\__init__.py ========
# This file makes Python treat the directory src as a package.



======== src\app.py ========
"""
FAH-based Duck Prompt Application
This is the new main application using FAH architecture
"""
import sys
import os
import logging
from pathlib import Path
from PyQt6.QtWidgets import QApplication, QMessageBox
from PyQt6.QtCore import Qt, QTimer
from PyQt6.QtGui import QIcon, QFont

# Add parent directory to path for imports
# This is no longer strictly necessary if run via the root main.py, but good for robustness
if str(Path(__file__).parent.parent) not in sys.path:
    sys.path.insert(0, str(Path(__file__).parent.parent))

# Import UI components and the new controller
from src.ui.main_window import MainWindow
from src.ui.controllers.main_controller import MainController
from src.shared.atoms.logger import Logger
from src.ui.styles.font_config import FontConfig

# Configure logging
Logger.setup(
    level=logging.INFO,
    format_string='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


class DuckPromptApp(QApplication):
    """FAH-based Duck Prompt Application"""
    
    def __init__(self, argv):
        super().__init__(argv)
        
        # Set application metadata
        self.setApplicationName("Duck Prompt FAH")
        self.setOrganizationName("DuckPrompt")
        self.setApplicationDisplayName("Duck Prompt - FAH Edition")
        
        # Configure font settings and load malgun.ttf
        FontConfig.setup_application_fonts(self)
        
        # Set application icon
        try:
            icon_path = str(Path(__file__).parent.parent / "resources" / "icons" / "rubber_duck.ico")
            if Path(icon_path).exists():
                self.setWindowIcon(QIcon(icon_path))
        except Exception as e:
            logger.error(f"Failed to set window icon: {e}")
        
        # Initialize main window and controller
        self.main_window = None
        self.controller = None
        
        # Setup application
        self._setup_application()
    
    
    def _setup_application(self):
        """Setup the application"""
        try:
            # Suppress font warnings in Qt
            os.environ['QT_LOGGING_RULES'] = 'qt.text.font.db.warning=false'
            
            # Create main window
            self.main_window = MainWindow()
            self.main_window.setWindowTitle("Duck Prompt - FAH Edition")
            
            # Create FAH controller
            self.controller = MainController(self.main_window)
            
            # Connect UI to controller
            self._connect_ui_signals()
            
            # Show main window
            self.main_window.show()
            
            # Initialize application after GUI is shown
            QTimer.singleShot(100, self._initialize_app)
            
        except Exception as e:
            logger.critical(f"Failed to setup application: {e}", exc_info=True)
            raise
    
    def _connect_ui_signals(self):
        """Connect UI signals to the FAH controller"""
        logger.debug("Connecting UI signals to FAH controller.")

        # --- Top buttons ---
        self.main_window.select_project_btn.clicked.connect(self.controller.select_project_folder)
        self.main_window.save_current_work_btn.clicked.connect(self.controller.save_state)
        self.main_window.load_previous_work_btn.clicked.connect(self.controller.load_last_state)
        # Note: reset_program_btn is not connected as it's not part of the FAH controller logic.

        # --- Prompt building ---
        self.main_window.system_tab.textChanged.connect(
            lambda: self.controller.update_system_prompt(self.main_window.system_tab.toPlainText())
        )
        self.main_window.user_tab.textChanged.connect(
            lambda: self.controller.update_user_prompt(self.main_window.user_tab.toPlainText())
        )
        self.main_window.generate_btn.clicked.connect(self.controller.build_prompt)
        self.main_window.generate_tree_btn.clicked.connect(self.controller.generate_directory_tree)
        
        # --- File tree ---
        # Check all/uncheck all functionality
        if hasattr(self.main_window, 'check_all_btn'): # Assuming a button exists for this
            self.main_window.check_all_btn.clicked.connect(lambda: self.controller.check_all_files(True))
        if hasattr(self.main_window, 'uncheck_all_btn'):
            self.main_window.uncheck_all_btn.clicked.connect(lambda: self.controller.check_all_files(False))
        
        # Context menu refresh action
        # This is handled within MainWindow's context menu creation logic now, which calls the controller.
        
        # --- Controller signals to UI ---
        self.controller.project_folder_changed.connect(self._update_project_folder)
        self.controller.prompt_built.connect(self._update_prompt_display)
        self.controller.tokens_calculated.connect(self._update_token_display)
        self.controller.status_message.connect(self.main_window.statusBar().showMessage)
        self.controller.error_occurred.connect(self._show_error_messagebox)

    def _initialize_app(self):
        """Initialize application after GUI is ready"""
        logger.info("Initializing FAH-based Duck Prompt application...")
        # Controller's __init__ handles the initialization sequence now.
        logger.info("Application initialized successfully")
    
    def _update_project_folder(self, folder_path: str):
        """Update UI when project folder changes"""
        if hasattr(self.main_window, 'project_folder_label'):
            self.main_window.project_folder_label.setText(f"현재 프로젝트 폴더: {folder_path}")
        self.main_window.setWindowTitle(f"{Path(folder_path).name} - Duck Prompt FAH")
    
    def _update_prompt_display(self, prompt: str):
        """Update prompt display if available"""
        if hasattr(self.main_window, 'prompt_output_tab'):
            self.main_window.prompt_output_tab.setPlainText(prompt)
    
    def _update_token_display(self, token_info: dict):
        """Update token count display"""
        if hasattr(self.main_window, 'token_count_label'):
            total_tokens = token_info.get('total_tokens', 0)
            model = token_info.get('model', 'Unknown')
            self.main_window.token_count_label.setText(f"Tokens: {total_tokens:,} ({model})")

    def _show_error_messagebox(self, error_message: str):
        """Show error in a message box."""
        QMessageBox.critical(self.main_window, "Error", error_message)
    
    def cleanup(self):
        """Cleanup on application exit"""
        logger.info("Shutting down FAH application...")
        if self.controller:
            self.controller.shutdown()
        logger.info("Application shutdown complete")

def main():
    """Main entry point"""
    # Apply font fixes before creating QApplication
    FontConfig.apply_font_fixes()
    
    # Enable high DPI scaling
    QApplication.setHighDpiScaleFactorRoundingPolicy(Qt.HighDpiScaleFactorRoundingPolicy.PassThrough)
    
    # Create and run application
    app = DuckPromptApp(sys.argv)
    
    # Set global exception handler
    def handle_exception(exc_type, exc_value, exc_traceback):
        if issubclass(exc_type, KeyboardInterrupt):
            sys.__excepthook__(exc_type, exc_value, exc_traceback)
            return
        
        logger.critical("Uncaught exception", exc_info=(exc_type, exc_value, exc_traceback))
    
    sys.excepthook = handle_exception
    
    # Run application
    exit_code = app.exec()
    
    # Cleanup
    app.cleanup()
    
    sys.exit(exit_code)

if __name__ == "__main__":
    main()



======== src\config.yml ========
default_system_prompt: resources\prompts\system\unified-diff_en.md
allowed_extensions: !!set {}
excluded_dirs: !!set
  __pycache__/: null
  .gitignore: null
  dist/: null
  node_modules/: null
  .vscode/: null
  .DS_Store: null
  .idea/: null
  .git/: null
  "*.log": null
  build/: null
  .venv/: null
default_ignore_list:
  - "*.egg-info/"
  - "*.pyc"
  - .cursorrules
  - .git/
  - .gitignore
  - .idea/
  - .vscode/
  - .windsurfrules
  - __pycache__/
  - build/
  - dist/
gemini_default_model: gemini-2.5-pro-preview-03-25
claude_default_model: claude-3-7-sonnet-20250219
gpt_default_model: gpt-4o
gemini_available_models:
  - gemini-2.5-pro-preview-03-25
  - gemini-2.5-flash-preview-04-17
claude_available_models:
  - claude-3-7-sonnet-20250219
gpt_available_models:
  - gpt-4o
  - gpt-4-turbo
  - gpt-3.5-turbo
anthropic_api_key: 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
gemini_api_key: AIzaSyC5uUtef7uQnLiP2ioBM7OqIF9EaxAnGQE
gemini_temperature: 0.0
gemini_enable_thinking: false
gemini_thinking_budget: 0
gemini_enable_search: false



File Tree:
 📁 duck-prompt/
   📁 ./
   📁 docs/
     📄 Diff-match-patch(DMP) 코드 수정 방법.md (12,792 bytes)
     📄 Feature‑Atomic Hybrid(FAH) + Sub-Bus Structure.md (19,456 bytes)
   📁 src/
     📁 core/
       📁 pydantic_models/
       📁 services/
       📁 utils/
       📁 workers/
     📁 features/
       📁 attachments/
         📁 atoms/
           📄 __init__.py (0 bytes)
         📁 molecules/
           📄 __init__.py (0 bytes)
         📁 organisms/
           📄 __init__.py (0 bytes)
         📄 __init__.py (0 bytes)
         📄 commands.py (0 bytes)
         📄 handlers.py (0 bytes)
       📁 config/
         📁 atoms/
           📄 __init__.py (0 bytes)
           📄 settings_validator.py (1,639 bytes)
         📁 molecules/
           📄 __init__.py (0 bytes)
           📄 api_key_selector.py (3,013 bytes)
           📄 gitignore_manager.py (2,483 bytes)
         📁 organisms/
           📄 __init__.py (0 bytes)
           📄 config_service.py (7,351 bytes)
         📁 pydantic_models/
           📄 __init__.py (0 bytes)
           📄 config_settings.py (1,355 bytes)
         📄 __init__.py (0 bytes)
         📄 commands.py (1,339 bytes)
         📄 handlers.py (5,452 bytes)
       📁 database/
         📁 atoms/
           📄 __init__.py (0 bytes)
           📄 db_connection.py (2,190 bytes)
           📄 query_executor.py (3,023 bytes)
         📁 molecules/
           📄 __init__.py (0 bytes)
           📄 api_key_manager.py (2,460 bytes)
           📄 config_manager.py (2,598 bytes)
           📄 gemini_log_manager.py (2,544 bytes)
         📁 organisms/
           📄 __init__.py (0 bytes)
           📄 database_service.py (3,427 bytes)
         📄 __init__.py (0 bytes)
         📄 commands.py (1,997 bytes)
         📄 handlers.py (5,555 bytes)
       📁 file_management/
         📁 atoms/
           📄 __init__.py (0 bytes)
           📄 file_scanner.py (3,855 bytes)
           📄 file_watcher.py (2,661 bytes)
         📁 molecules/
           📄 __init__.py (0 bytes)
           📄 file_tree_builder.py (5,341 bytes)
           📄 gitignore_filter.py (4,146 bytes)
         📁 organisms/
           📄 __init__.py (0 bytes)
           📄 file_system_service.py (7,533 bytes)
         📄 __init__.py (0 bytes)
         📄 commands.py (1,793 bytes)
         📄 handlers.py (6,640 bytes)
       📁 gemini/
         📁 atoms/
           📄 __init__.py (0 bytes)
         📁 molecules/
           📄 __init__.py (0 bytes)
         📁 organisms/
           📄 __init__.py (0 bytes)
         📄 __init__.py (0 bytes)
         📄 commands.py (0 bytes)
         📄 handlers.py (0 bytes)
       📁 prompt_builder/
         📁 atoms/
           📄 __init__.py (0 bytes)
           📄 prompt_formatter.py (4,443 bytes)
         📁 molecules/
           📄 __init__.py (0 bytes)
           📄 prompt_validator.py (5,906 bytes)
         📁 organisms/
           📄 __init__.py (0 bytes)
           📄 prompt_service.py (8,110 bytes)
         📄 __init__.py (0 bytes)
         📄 commands.py (1,547 bytes)
         📄 handlers.py (5,316 bytes)
       📁 state/
         📁 atoms/
           📄 __init__.py (0 bytes)
         📁 molecules/
           📄 __init__.py (0 bytes)
         📁 organisms/
           📄 __init__.py (0 bytes)
         📄 __init__.py (0 bytes)
         📄 commands.py (0 bytes)
         📄 handlers.py (0 bytes)
       📁 templates/
         📁 atoms/
           📄 __init__.py (0 bytes)
         📁 molecules/
           📄 __init__.py (0 bytes)
         📁 organisms/
           📄 __init__.py (0 bytes)
         📄 __init__.py (0 bytes)
         📄 commands.py (0 bytes)
         📄 handlers.py (0 bytes)
       📁 tokens/
         📁 atoms/
           📄 __init__.py (0 bytes)
           📄 claude_tokenizer.py (3,260 bytes)
           📄 gemini_tokenizer.py (5,289 bytes)
           📄 gpt_tokenizer.py (3,569 bytes)
         📁 molecules/
           📄 __init__.py (0 bytes)
           📄 cost_calculator.py (5,499 bytes)
         📁 organisms/
           📄 __init__.py (0 bytes)
           📄 token_service.py (12,148 bytes)
         📄 __init__.py (0 bytes)
         📄 commands.py (1,352 bytes)
         📄 handlers.py (3,512 bytes)
       📁 xml_processor/
         📁 atoms/
           📄 __init__.py (0 bytes)
         📁 molecules/
           📄 __init__.py (0 bytes)
         📁 organisms/
           📄 __init__.py (0 bytes)
         📄 __init__.py (0 bytes)
         📄 commands.py (0 bytes)
         📄 handlers.py (0 bytes)
       📄 __init__.py (0 bytes)
     📁 gateway/
       📁 bus/
         📄 __init__.py (0 bytes)
         📄 _base.py (2,023 bytes)
         📄 config_command_bus.py (133 bytes)
         📄 database_command_bus.py (130 bytes)
         📄 event_bus.py (1,397 bytes)
         📄 file_management_command_bus.py (143 bytes)
         📄 prompt_builder_command_bus.py (141 bytes)
         📄 service_locator.py (3,080 bytes)
         📄 tokens_command_bus.py (137 bytes)
       📄 __init__.py (1,572 bytes)
     📁 shared/
       📁 atoms/
         📄 __init__.py (0 bytes)
         📄 file_utils.py (2,373 bytes)
         📄 logger.py (1,514 bytes)
         📄 validators.py (4,036 bytes)
       📄 __init__.py (0 bytes)
     📁 ui/
       📁 bridges/
         📄 __init__.py (61 bytes)
         📄 fah_bridge.py (7,148 bytes)
       📁 controllers/
         📄 main_controller.py (8,426 bytes)
       📁 models/
         📄 __init__.py (67 bytes)
         📄 file_system_models.py (13,421 bytes)
       📁 styles/
         📄 __init__.py (22 bytes)
         📄 font_config.py (7,788 bytes)
       📁 widgets/
         📄 __init__.py (68 bytes)
         📄 check_box_delegate.py (3,714 bytes)
         📄 custom_tab_bar.py (4,364 bytes)
         📄 custom_text_edit.py (501 bytes)
         📄 file_tree_view.py (2,439 bytes)
         📄 tab_manager.py (434 bytes)
       📄 __init__.py (63 bytes)
       📄 main_window.py (12,939 bytes)
     📁 utils/
       📄 __init__.py (320 bytes)
       📄 db_migration_script.py (5,742 bytes)
       📄 helpers.py (2,152 bytes)
       📄 notifications.py (2,983 bytes)
       📄 postgres_db_initializer.py (20,529 bytes)
     📄 __init__.py (64 bytes)
     📄 app.py (7,800 bytes)
     📄 config.yml (1,155 bytes)
   📄 CLAUDE.md (9,590 bytes)
   📄 main.py (333 bytes)
   📄 pyproject.toml (2,087 bytes)
   📄 qt.conf (47 bytes)